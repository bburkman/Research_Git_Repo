% Analysis of Results

Our ML algorithms assign to each sample (feature vector, crash person) a probability $p \in [0,1]$ that the person needs an ambulance.  The histogram below left shows the percentage of the dataset in each range of $p$, showing the percentages for the negative class (``Does not need an ambulance'') and the positive class (``Needs an ambulance'').  On the right, the Receiver Operating Characteristic (ROC) curve, and particularly the area under the curve (AUC), is a metric for how well the model separates the two classes, with $AUC=1.0$ being perfect and $AUC=0.5$ (the dashed line) being just random assignment with no insight.  

We would love to have results like in the graphs below, where the machine learning (ML) algorithm nearly perfectly separates the two classes.  There is some overlap between $p=0.6$ and $p=0.8$ with some samples the algorithm misclassifies, but the model clearly separates most samples.  Having an AUC of 0.996 would be amazing.  

[Put in \verb|BRFC_Hard_alpha_0_5_Train_Pred_Wide.pgf| once we have it.)

\begin{comment}

\noindent\begin{tabular}{@{\hspace{-6pt}}p{4.3in} @{\hspace{-6pt}}p{2.0in}}
	\vskip 0pt
	\hfil Raw Model Output
	
	\input{../Keras/Images/BRFC_Hard_Tomek_0_alpha_0_5_v1_Train_Pred_Wide.pgf}	
&
	\vskip 0pt
	\hfil ROC Curve
	
	\input{../Keras/Images/BRFC_Hard_Tomek_0_alpha_0_5_v1_Train_ROC.pgf}
	
\end{tabular}
\end{comment}

Unfortunately, our test results do not look quite that nice.  They do not separate the two classes as well.  Some distributions are clustered to one side or in the middle.  Some models give the results in $p \in [0,1]$ rounded to two decimal places so that we cannot hope for a level of detail beyond that, and one algorithm, Bagging, gives $p$ rounded to only one decimal place.  

Let us look at some examples.  In all of them, AUC is in the range $[0.7,0.8]$, so the various models separate the positive and negative classes about equally well overall, with none being dramatically better or worse.  We will later show how we investigated which models do a better job in the ranges of interest.  

\

%
\verb|BRFC_5_Fold_alpha_0_5_Hard_Test|

\

This model does not separate the negative and positive classes as well as the ideal, giving a much lower AUC (area under the ROC curve).  These results are actually from the same model as the ideal above, but the ideal are the results on the training set and below on the test set, showing overfitting.  

In these results, the 100 most frequent values comprised 93\% of the results, meaning that, while there is some noise making the distribution look continuous, it is mostly discrete to two decimal places, so we cannot hope for fine detail in tuning the decision threshold.  

\noindent\begin{tabular}{@{\hspace{-6pt}}p{4.3in} @{\hspace{-6pt}}p{2.0in}}
	\vskip 0pt
	\hfil Raw Model Output
	
	\input{../Keras/Images/BRFC_5_Fold_alpha_0_5_Hard_Test_Pred_Wide.pgf}	
&
	\vskip 0pt
	\hfil ROC Curve
	
	\input{../Keras/Images/BRFC_5_Fold_alpha_0_5_Hard_Test_ROC.pgf}
\end{tabular}

\

\

%
\verb|AdaBoost_5_Fold_Hard_Test|

\

In this model the values are clustered very tightly, but in that small range the 214,070 samples return 210,442 different values of $p$, so there is much diversity that we can't see in this representation.  


\

\verb|AdaBoost_5_Fold_Hard_Test|



\noindent\begin{tabular}{@{\hspace{-6pt}}p{4.3in} @{\hspace{-6pt}}p{2.0in}}
	\vskip 0pt
	\hfil Raw Model Output
	
	\input{../Keras/Images/AdaBoost_5_Fold_Hard_Test_Pred_Wide.pgf}	
&
	\vskip 0pt
	\hfil ROC Curve
	
	\input{../Keras/Images/AdaBoost_5_Fold_Hard_Test_ROC.pgf}
\end{tabular}


\

In this work we used two methods to give the results of different models similar distributions.  This case illustrates directly transforming the \verb|y_proba| values.  

To make a useful visualization of the results where we can see the interplay between the negative and positive classes, we can transform the data.  A transformation that preserves rank will have no effect on the ROC curve.  [Cite]  For the graph below, we mapped the smallest value in the set to 0 and the largest to 1.  

\

\verb|AdaBoost_5_Fold_Hard_Test_Transformed_100|

%
\noindent\begin{tabular}{@{\hspace{-6pt}}p{4.3in} @{\hspace{-6pt}}p{2.0in}}
	\vskip 0pt
	\hfil Raw Model Output
	
	\input{../Keras/Images/AdaBoost_5_Fold_Hard_Test_Transformed_100_Pred_Wide.pgf}	
&
	\vskip 0pt
	\hfil ROC Curve
	
	\input{../Keras/Images/AdaBoost_5_Fold_Hard_Test_Transformed_100_ROC.pgf}
\end{tabular}

The distribution has long tails, so we can make a more useful visualization by truncating the ends.  For this graph we mapped the 0.01 quantile to 0 and the 0.99 quantile to 1 leaving the center 98\% of the distribution and truncated the ends.  Our goal in clipping the tails is to make all of the models' results have approximately the same granularity when we choose the decision thresholds that give us the (politically) desired results.  


\

\verb|AdaBoost_5_Fold_Hard_Test_Transformed_98|

%
\noindent\begin{tabular}{@{\hspace{-6pt}}p{4.3in} @{\hspace{-6pt}}p{2.0in}}
	\vskip 0pt
	\hfil Raw Model Output
	
	\input{../Keras/Images/AdaBoost_5_Fold_Hard_Test_Transformed_98_Pred_Wide.pgf}	
&
	\vskip 0pt
	\hfil ROC Curve
	
	\input{../Keras/Images/AdaBoost_5_Fold_Hard_Test_Transformed_98_ROC.pgf}
\end{tabular}

\



The model below is as effective at separating the two classes ($\text{ROC}=0.778$), but the distribution is skewed to the left.  Its results were nearly continuous, with the 214,070 samples returning 210,157 unique values of $p$, so we can fine tune the decision threshold.  

\

%
\verb|KBFC_5_Fold_alpha_0_5_gamma_0_0_Hard_Test|

\

\noindent\begin{tabular}{@{\hspace{-6pt}}p{4.3in} @{\hspace{-6pt}}p{2.0in}}
	\vskip 0pt
	\hfil Raw Model Output
	
	\input{../Keras/Images/KBFC_5_Fold_alpha_0_5_gamma_0_0_Hard_Test_Pred_Wide.pgf}	
&
	\vskip 0pt
	\hfil ROC Curve
	
	\input{../Keras/Images/KBFC_5_Fold_alpha_0_5_gamma_0_0_Hard_Test_ROC.pgf}
\end{tabular}

\

The second method we will use to modify the model outputs' distribution is to employ class weights in the model building process.  Here we employed class weights proportional to the class imbalance.  The motivation behind class weights is to better separate the positive and negative classes, but note that the area under the ROC curve does not change.  We have not investigated whether the model using class weights does a better job at separating the classes in some intervals, but overall the effect is negligible.  One effect using class weights did have here is shifting the distribution.  


\

\verb|KBFC_5_Fold_alpha_balanced_gamma_0_0_Hard|



\noindent\begin{tabular}{@{\hspace{-6pt}}p{4.3in} @{\hspace{-6pt}}p{2.0in}}
	\vskip 0pt
	\hfil Raw Model Output
	
	\input{../Keras/Images/KBFC_5_Fold_alpha_balanced_gamma_0_0_Hard_Test_Pred_Wide.pgf}	
&
	\vskip 0pt
	\hfil ROC Curve
	
	\input{../Keras/Images/KBFC_5_Fold_alpha_balanced_gamma_0_0_Hard_Test_ROC.pgf}
\end{tabular}

\



%
\verb|Bagging_Hard_Tomek_0_v1_Test|

\

This model returned 217 different values, but most of them were rare.  Taking out the 5\% of the data set with the least frequent values, 95\% of the samples had only 10 values of $p$.  It may be a useful model, but we will not be able to fine tune the decision threshold.  

\noindent\begin{tabular}{@{\hspace{-6pt}}p{4.3in} @{\hspace{-6pt}}p{2.0in}}
	\vskip 0pt
	\hfil Raw Model Output
	
	\input{../Keras/Images/BalBag_5_Fold_Hard_Test_Pred_Wide.pgf}	
&
	\vskip 0pt
	\hfil ROC Curve
	
	\input{../Keras/Images/BalBag_5_Fold_Hard_Test_ROC.pgf}
\end{tabular}

\

\

Other stuff

\


%%%
\begin{comment}
If we set the discrimination threshold about $0.7$, the model would classify almost all of the samples, both positive and negative class, correctly, with about the same number of false positives (sending an ambulance when one is not needed, negative class samples with $p > 0.7$) and false negatives (not sending an ambulance when one is needed, positive class samples with $p < 0.7$).  If we (as a society) were willing to tolerate more false positives, we could set the discrimination threshold lower, and if budgets were tighter we could increase the $p$ threshold.  

The table below gives the number of true negatives (TN), false positives (FP), false negatives (FN), and true positives (TP) for the 499,496 samples in the test set, along with the precision and recall values, for different discrimination thresholds $p$.  The precision is the proportion of ambulances we sent that were needed, and the recall is the proportion of ambulances needed that we sent.  

$$\text{Precision} = \frac{TP}{FP+TP}, \qquad \text{Recall} = \frac{TP}{FN + TP}$$

\begin{center}
\begin{tabular}{rrrrrrrrrrrrrr}
\toprule
$p$ &   TN &       FP &      FN &      TP &  Precision &   Recall \\
\midrule
0.50 &  346,776 &   73,794 &       1 &  78,925 &  0.52 &  1.00       \\
0.60 &  390,335 &   30,235 &      89 &  78,837 &  0.72 &  1.00  \\
0.70 & 411,040 &    9,530 &   2,838 &  76,088 &  0.89 &  0.96 \\
0.80 & 418,739 &    1,831 &  19,174 &  59,752 &  0.97 &  0.76  \\
0.90 & 420,496 &       74 &  53,736 &  25,190 &  1.00 &  0.32 & \\
\bottomrule
\end{tabular}
\end{center}

\end{comment}
%%%



