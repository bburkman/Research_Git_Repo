%%%%%
\section{CRSS Imputing Unknown Values}
\label{sec:CRSS_Imputing}


The \acrfull{crss} is the latest iteration of \acrfull{nhtsb} datasets, and for historical consistency and backwards compatibility, the CRSS authors only imputed unknown values in some features.  The CRSS authors wrote a very useful historical and practical report on their imputation methods.  \cite{CRSS_Imputation}

%%%
\subsection{``Missing'' v/s ``Unknown''}

I will distinguish here between ``missing'' and ``unknown'' data.  In each year's CRSS spreadsheets, no cells are blank, but some (less important) features appear in one year and not another, so when I merge them I get an entire year of blank cells.  I will refer to those as ``missing.''  

When I merge the Vehicle and Person parts of each year's data, the vehicle data will be blank or \verb|nan| for some samples because the person was not in a vehicle (pedestrian, bicyclist, motorist parked on the side of the road and standing outside the vehicle...)  Those samples I have dropped for reasons described earlier.  

%%%
\subsection{Unknown within Bin v/s Unknown Unknown}

Almost all of the features are categorical, and most of them include at least one category signifying that the value is unknown.  Sometimes they are partially unknown but contain enough information for our purposes, like in the HOSPITAL feature, in the table below.  Category 6 is ``Other,'' which is undefined.  To see what kinds of severity it covers, we look at the crosstabs with injury severity (INJ\_SEV) (next table below).  Category 6 looks similar to  category 5, ``EMS Ground'' in that all of the people had some injury, and most of the injuries were minor.  (See the INJ\_SEV / HOSPITAL Crosstabs Normalized by Row table below).  Thus, we interpret ``Other'' as ``Transported to hospital by another means.''  We actually don't care how the person was transported to the hospital, just whether the person went, so we will bin 1, 2, 3, 4, 5, and 6 together.  

Categories 8 and 9 of HOSPITAL are unknown unknown.  One method of handling an unknown category is to bin it in the largest bin, but we used a more subtle method, using IVEware \cite{IVEware}.  

\hfil\begin{tabular}{clrr}
\multicolumn{2}{l}{\bf HOSPITAL} \cr\hline
\multicolumn{2}{l}{Category} & & Percentage \cr
& Meaning & Count & of Samples \cr
\hline
0 & Not Transported & 522801 & 81.15 \cr
1 & EMS Air & 2549 & 0.40 \cr
2 & Law Enforcement & 605 & 0.09 \cr
3 & EMS Unknown Mode & 30368 & 4.71 \cr
4 & Transported Unknown Source & 8926 & 1.39 \cr
5 & EMS Ground & 61162 & 9.49 \cr
6 & Other & 4341 & 0.67 \cr
8 & Not Reported & 12447 & 1.93 \cr
9 & Reported as Unknown & 1075 & 0.17 \cr
\end{tabular}

\vskip 12pt


\hfil\begin{tabular}{ll}
	\multicolumn{2}{l}{\bf INJ\_SEV:  Injury Severity} \cr\hline
	0 & No Apparent Injury \cr
	1 & Possible Injury \cr
	2 & Suspected Minor Injury \cr
	3 & Suspected Serious Injury \cr
	4 & Fatal Injury \cr
	5 & Injured, Severity Unknown \cr
	6 & Died Prior to Crash \cr
	9 & Unknown/Not Reported \cr
\end{tabular}

\vskip 12pt


\hfil\begin{tabular}{rrrrrrrrr}
\multicolumn{9}{l}{\bf INJ\_SEV / HOSPITAL Crosstabs} \cr\hline
INJ\_SEV &       0 &      1 &      2 &      3 &     4 &    5 &  6 &      9 \\
HOSPITAL &         &        &        &        &       &      &    &        \\
\hline
0        &  429574 &  52271 &  19522 &    826 &  2956 &  454 &  9 &  17189 \\
1        &       0 &    159 &    295 &   1854 &   222 &   16 &  0 &      3 \\
2        &       0 &    266 &    235 &     84 &     7 &    3 &  0 &     10 \\
3        &       0 &   9630 &  10601 &   8801 &   665 &  618 &  3 &     50 \\
4        &       0 &   3293 &   2686 &   2476 &   226 &  215 &  1 &     29 \\
5        &       0 &  22550 &  19983 &  16642 &  1315 &  470 &  6 &    196 \\
6        &       0 &   2214 &   1546 &    419 &    91 &   31 &  0 &     40 \\
8        &       0 &   5106 &   2308 &   1421 &    95 &   72 &  0 &   3445 \\
9        &       0 &    272 &    123 &     33 &    10 &    4 &  0 &    633 \\\end{tabular}

\vskip 12pt

\hfil\begin{tabular}{lrrrrrrrr}
\multicolumn{8}{l}{\bf INJ\_SEV / HOSPITAL Crosstabs Normalized by Row (\%)}\cr\hline
INJ\_SEV &      0 &      1 &      2 &      3 &     4 &     5 &     6 &      9 \\
HOSPITAL &        &        &        &        &       &       &       &        \\
\hline
0        &  82.17 &  10.00 &   3.73 &   0.16 &  0.57 &  0.09 &  0.00 &   3.29 \\
1        &   0.00 &   6.24 &  11.57 &  72.73 &  8.71 &  0.63 &  0.00 &   0.12 \\
2        &   0.00 &  43.97 &  38.84 &  13.88 &  1.16 &  0.50 &  0.00 &   1.65 \\
3        &   0.00 &  31.71 &  34.91 &  28.98 &  2.19 &  2.04 &  0.01 &   0.16 \\
4        &   0.00 &  36.89 &  30.09 &  27.74 &  2.53 &  2.41 &  0.01 &   0.32 \\
5        &   0.00 &  36.87 &  32.67 &  27.21 &  2.15 &  0.77 &  0.01 &   0.32 \\
6        &   0.00 &  51.00 &  35.61 &   9.65 &  2.10 &  0.71 &  0.00 &   0.92 \\
8        &   0.00 &  41.02 &  18.54 &  11.42 &  0.76 &  0.58 &  0.00 &  27.68 \\
9        &   0.00 &  25.30 &  11.44 &   3.07 &  0.93 &  0.37 &  0.00 &  58.88 \\
\end{tabular}

%%%
\subsection{IVEware}

The \nameref{CRSS Features} section above listed twenty features (that we want to use) whose unknown values had been imputed by the CRSS authors and another twelve features, like HOSPITAL, whose unknown values had not been imputed.  The CRSS Imputation report describes the reasons why some features were imputed and other not, mainly for historical consistency going back to 1988.  \cite{CRSS_Imputation} As best we could, we replicated their methods for the twelve features with unknown values.  

\begin{enumerate}
	\item Impute unknown values in ACCIDENT dataset
	\item Merge VEHICLE into ACCIDENT
	\item Impute unknown values in VEHICLE
	\item Merge in PERSON
	\item Impute missing values in PERSON
\end{enumerate}

The CRSS authors used \acrfull{iveware} to implement \acrfull{smri} for their first round of imputing unknown values.  \cite{IVEware} \cite{Raghunathan_2001}  They wrote a very useful report on their methods, with an historical overview and the hyperparameters they used when running IVEware.  \cite{CRSS_Imputation}  The authors followed up the SMRI with manual updates based on domain knowledge, but only of twenty-eight samples.   We will not be able to replicate that part of their method.

% Using CRSS_07_27_22_IVEware_Imputed

%%%
\subsection{IVEware Testing}

When the CRSS authors imputed unknown values for a feature, they left the unimputed feature in the dataset.  To test how close our imputation results were to theirs, we ran our imputation algorithm on some of those unimputed features and compared.  Since imputation involves randomness, we also compared two of our imputation runs to see whether the difference between our results and those of CRSS were largely due to expected random variability and not significantly due to a difference in methods.  

The tables below compare imputation results for the Lighting Conditions feature, LGT\_COND, just looking at the 2,309 samples with unknown values 8 or 9.  

The tables below are for Lighting Conditions.  The LGT\_COND feature is the original data with 2,309 unknown values.  The LGTCOND\_IM is the imputed feature in the CRSS data set, and the LGT\_COND\_IVE is one run of our imputation.  The LGT\_COND\_IVE\_2 is our imputation with the same hyperparameters but a different random seed.  The crosstabs below only show the 2,309 samples with unknown values, comparing the values to which the imputations assigned them.  

%['LGT_COND', 'LGTCON_IM', 'LGT_COND_IVE', [8, 9], 2309]

\vskip 12pt

\hfil\begin{tabular}{clr}
	\multicolumn{2}{l}{\bf LGT\_COND (Light Conditions)} \cr \hline
	Value & Meaning & Count \cr\hline
	1 & Daylight & 177,013 \cr
	2 & Dark - Not Lighted & 26,403 \cr
	3 & Dark - Lighted & 41,508 \cr
	4 & Dawn & 4,063 \cr
	5 & Dusk & 6,016 \cr
	6 & Dark - Unknown Lighting & 1,697 \cr
	7 & Other & 68 \cr
	8 & Not Reported & 1,690 \cr
	9 & Reported as Unknown & 619 \cr
\end{tabular}

\vskip 12pt

To Do:  \index{To Do!Table Totals}  Include totals for rows and columns

\vskip 12pt

\hfil\begin{tabular}{lrrrrrrr}
\multicolumn{8}{l}{\bf Comparing CRSS's Imputation with Ours} \cr\hline
LGT\_COND\_IVE &    1 &    2 &    3 &   4 &   5 &   6 &  7 \\
LGTCON\_IM &      &      &      &     &     &     &    \\
\hline
1         &  946 &   57 &   52 &  42 &  22 &   8 &  1 \\
2         &   67 &  381 &  132 &  37 &  25 &  21 &  1 \\
3         &   55 &  114 &  161 &   7 &   6 &   9 &  0 \\
4         &   25 &   15 &    6 &  11 &   0 &   1 &  0 \\
5         &   21 &   35 &   17 &   0 &   6 &   3 &  0 \\
6         &    5 &    9 &    5 &   0 &   2 &   3 &  0 \\
7         &    0 &    0 &    1 &   0 &   0 &   0 &  0 \\
\end{tabular}

\vskip 12pt

\hfil\begin{tabular}{lrrrrrrr}
\multicolumn{8}{l}{\bf Comparing Two IVEware Runs} \cr
\multicolumn{8}{l}{\bf \qquad with Different Random Seeds} \cr\hline
LGT\_COND\_IVE\_2 &    1 &    2 &    3 &   4 &   5 &   6 &  7 \\
LGT\_COND\_IVE &      &      &      &     &     &     &    \\
\hline
1            &  936 &   80 &   48 &  27 &  21 &   7 &  0 \\
2            &   72 &  364 &  108 &  24 &  21 &  21 &  1 \\
3            &   60 &  108 &  187 &   2 &  11 &   6 &  0 \\
4            &   40 &   25 &    6 &  25 &   0 &   1 &  0 \\
5            &   20 &   25 &   12 &   1 &   0 &   3 &  0 \\
6            &    9 &   26 &    6 &   2 &   1 &   1 &  0 \\
7            &    1 &    1 &    0 &   0 &   0 &   0 &  0 \\
\end{tabular}

\vskip 12pt

To Do \index{To Do!Crosstabs Metric}:  Find a metric for comparing the variability.

\vskip 12pt

The two crosstabs tables indicate that, while my recreation of the imputation method used by the CRSS authors does not give the same results, it gives similar results, and the differences are largely consistent with the differences between two runs with different random seeds.  Our imputation is not the same, but may be as similar as possible, given that we are working with unknowns and randomness.













