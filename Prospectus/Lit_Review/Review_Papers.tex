%%%%%
\section{Review Papers}

%%%
\subsection{Chawla}
Chawla \cite{CHAWLA_2004} gives an overview of the state of the field in 2004.

\begin{itemize}
	\item Data Methods
	\begin{itemize}
		\item Random Oversampling with Replacement
		\item Random Oversampling
		\item Directed Oversampling
		
		No new examples are created, but the choice of which ones to replace is informed rather than random.
		\item Directed Undersampling
		\item Oversampling with informed generation of new samples
		\item Combinations of the above
	\end{itemize}
	\item Algorithmic Methods
	\begin{itemize}
		\item Adjusting class costs
		\item Adjusting the probabilistic estimate at the tree leaf (for tree methods)
		\item Recognition-based methods (learning from one class) rather than discrimination-based.
	\end{itemize}
	\item Issues at 2000 Conference
	\begin{itemize}
		\item 
	\end{itemize}
	\item Issues at 2003 ICML Conference
	\begin{itemize}
		\item Probabilistic estimates
		\item Pruning
		\item Threshold adjusting
		\item Cost-matrix adjusting.
	\end{itemize}
	\item Interesting Topics at 2003 ICML Conference
	\begin{itemize}
		\item Selective sampling based on query learning (Abe)
	\end{itemize}
	\item Overlapping Problems
	\begin{itemize}
		\item Class Imbalance
		\item Small Disjunct Problem (?)
		\item Rare Cases
		\item Data Duplication
		\item Overlapping Classes
	\end{itemize}
\end{itemize}

By 2003, the field started to mature.  


%%%
\subsection{Chabbouh 2019}

This article \cite{CHABBOUH_2019} has a nice table classifying existing work in imbalanced classification; however, I think much of the information was old in 2019, particularly C4.5, an early decision tree base classifier that may not be used much anymore.  


%%%
\subsection{Mahmudah 2021}

This article \cite{MAHMUDAH_2021} is really a review of current methods.   They have some datasets, most public benchmark sets, and throw every combination of tools at them. The ``methods'' section is really an overview of current methods.  

Has a section on techniques for feature extraction (feature engineering?) by dimensionality reduction, not particularly related to imbalanced data.  



