{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1w1oBJveHYGJ"
   },
   "source": [
    "# Structured data classification from scratch\n",
    "\n",
    "**Author:** [fchollet](https://twitter.com/fchollet)<br>\n",
    "**Date created:** 2020/06/09<br>\n",
    "**Last modified:** 2020/06/09<br>\n",
    "**Description:** Binary classification of structured data including numerical and categorical features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CKw-ymd5HYGL"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "This example demonstrates how to do structured data classification, starting from a raw\n",
    "CSV file. Our data includes both numerical and categorical features. We will use Keras\n",
    "preprocessing layers to normalize the numerical features and vectorize the categorical\n",
    "ones.\n",
    "\n",
    "Note that this example should be run with TensorFlow 2.5 or higher.\n",
    "\n",
    "### The dataset\n",
    "\n",
    "[Our dataset](https://archive.ics.uci.edu/ml/datasets/heart+Disease) is provided by the\n",
    "Cleveland Clinic Foundation for Heart Disease.\n",
    "It's a CSV file with 303 rows. Each row contains information about a patient (a\n",
    "**sample**), and each column describes an attribute of the patient (a **feature**). We\n",
    "use the features to predict whether a patient has a heart disease (**binary\n",
    "classification**).\n",
    "\n",
    "Here's the description of each feature:\n",
    "\n",
    "Column| Description| Feature Type\n",
    "------------|--------------------|----------------------\n",
    "Age | Age in years | Numerical\n",
    "Sex | (1 = male; 0 = female) | Categorical\n",
    "CP | Chest pain type (0, 1, 2, 3, 4) | Categorical\n",
    "Trestbpd | Resting blood pressure (in mm Hg on admission) | Numerical\n",
    "Chol | Serum cholesterol in mg/dl | Numerical\n",
    "FBS | fasting blood sugar in 120 mg/dl (1 = true; 0 = false) | Categorical\n",
    "RestECG | Resting electrocardiogram results (0, 1, 2) | Categorical\n",
    "Thalach | Maximum heart rate achieved | Numerical\n",
    "Exang | Exercise induced angina (1 = yes; 0 = no) | Categorical\n",
    "Oldpeak | ST depression induced by exercise relative to rest | Numerical\n",
    "Slope | Slope of the peak exercise ST segment | Numerical\n",
    "CA | Number of major vessels (0-3) colored by fluoroscopy | Both numerical & categorical\n",
    "Thal | 3 = normal; 6 = fixed defect; 7 = reversible defect | Categorical\n",
    "Target | Diagnosis of heart disease (1 = true; 0 = false) | Target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n5s_3m54HYGM"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "V7G46Zu7HYGM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow version: 2.10.0\n",
      "NumPy version: 1.24.0\n",
      "pandas version: 1.5.2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print ('tensorflow version: {}'.format(tf.__version__))\n",
    "import numpy as np\n",
    "print ('NumPy version: {}'.format(np.__version__))\n",
    "import pandas as pd\n",
    "print ('pandas version: {}'.format(pd.__version__))\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Vu5G3JxHYGN"
   },
   "source": [
    "## Preparing the data\n",
    "\n",
    "Let's download the data and load it into a Pandas dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "1MZHzBR2HYGN"
   },
   "outputs": [],
   "source": [
    "file_url = \"http://storage.googleapis.com/download.tensorflow.org/data/heart.csv\"\n",
    "dataframe = pd.read_csv(file_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2KrYSlToHYGN"
   },
   "source": [
    "The dataset includes 303 samples with 14 columns per sample (13 features, plus the target\n",
    "label):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "IDEUsCtVHYGN"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(303, 14)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IxCH4oE2HYGO"
   },
   "source": [
    "Here's a preview of a few samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "aX7h33cnHYGO"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>fixed</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>160</td>\n",
       "      <td>286</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>normal</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>120</td>\n",
       "      <td>229</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>reversible</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   1       145   233    1        2      150      0      2.3      3   \n",
       "1   67    1   4       160   286    0        2      108      1      1.5      2   \n",
       "2   67    1   4       120   229    0        2      129      1      2.6      2   \n",
       "3   37    1   3       130   250    0        0      187      0      3.5      3   \n",
       "4   41    0   2       130   204    0        2      172      0      1.4      1   \n",
       "\n",
       "   ca        thal  target  \n",
       "0   0       fixed       0  \n",
       "1   3      normal       1  \n",
       "2   2  reversible       0  \n",
       "3   0      normal       0  \n",
       "4   0      normal       0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wxMGTU4wHYGO"
   },
   "source": [
    "The last column, \"target\", indicates whether the patient has a heart disease (1) or not\n",
    "(0).\n",
    "\n",
    "Let's split the data into a training and validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "AT7aGKHgHYGO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 242 samples for training and 61 for validation\n"
     ]
    }
   ],
   "source": [
    "val_dataframe = dataframe.sample(frac=0.2, random_state=1337)\n",
    "train_dataframe = dataframe.drop(val_dataframe.index)\n",
    "\n",
    "print(\n",
    "    \"Using %d samples for training and %d for validation\"\n",
    "    % (len(train_dataframe), len(val_dataframe))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BukQjMfjHYGO"
   },
   "source": [
    "Let's generate `tf.data.Dataset` objects for each dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "t399S5xqHYGO"
   },
   "outputs": [],
   "source": [
    "\n",
    "def dataframe_to_dataset(dataframe):\n",
    "    dataframe = dataframe.copy()\n",
    "    labels = dataframe.pop(\"target\")\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "    return ds\n",
    "\n",
    "\n",
    "train_ds = dataframe_to_dataset(train_dataframe)\n",
    "val_ds = dataframe_to_dataset(val_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sy3-k6BCHYGP"
   },
   "source": [
    "Each `Dataset` yields a tuple `(input, target)` where `input` is a dictionary of features\n",
    "and `target` is the value `0` or `1`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "L1ASbxlrHYGP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: {'age': <tf.Tensor: shape=(), dtype=int64, numpy=48>, 'sex': <tf.Tensor: shape=(), dtype=int64, numpy=1>, 'cp': <tf.Tensor: shape=(), dtype=int64, numpy=4>, 'trestbps': <tf.Tensor: shape=(), dtype=int64, numpy=122>, 'chol': <tf.Tensor: shape=(), dtype=int64, numpy=222>, 'fbs': <tf.Tensor: shape=(), dtype=int64, numpy=0>, 'restecg': <tf.Tensor: shape=(), dtype=int64, numpy=2>, 'thalach': <tf.Tensor: shape=(), dtype=int64, numpy=186>, 'exang': <tf.Tensor: shape=(), dtype=int64, numpy=0>, 'oldpeak': <tf.Tensor: shape=(), dtype=float64, numpy=0.0>, 'slope': <tf.Tensor: shape=(), dtype=int64, numpy=1>, 'ca': <tf.Tensor: shape=(), dtype=int64, numpy=0>, 'thal': <tf.Tensor: shape=(), dtype=string, numpy=b'normal'>}\n",
      "Target: tf.Tensor(0, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_ds.take(1):\n",
    "    print(\"Input:\", x)\n",
    "    print(\"Target:\", y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u87zepxEHYGP"
   },
   "source": [
    "Let's batch the datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "N-QiyIUAHYGP"
   },
   "outputs": [],
   "source": [
    "train_ds = train_ds.batch(32)\n",
    "val_ds = val_ds.batch(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mNHvJcJJHYGP"
   },
   "source": [
    "## Feature preprocessing with Keras layers\n",
    "\n",
    "\n",
    "The following features are categorical features encoded as integers:\n",
    "\n",
    "- `sex`\n",
    "- `cp`\n",
    "- `fbs`\n",
    "- `restecg`\n",
    "- `exang`\n",
    "- `ca`\n",
    "\n",
    "We will encode these features using **one-hot encoding**. We have two options\n",
    "here:\n",
    "\n",
    " - Use `CategoryEncoding()`, which requires knowing the range of input values\n",
    " and will error on input outside the range.\n",
    " - Use `IntegerLookup()` which will build a lookup table for inputs and reserve\n",
    " an output index for unkown input values.\n",
    "\n",
    "For this example, we want a simple solution that will handle out of range inputs\n",
    "at inference, so we will use `IntegerLookup()`.\n",
    "\n",
    "We also have a categorical feature encoded as a string: `thal`. We will create an\n",
    "index of all possible features and encode output using the `StringLookup()` layer.\n",
    "\n",
    "Finally, the following feature are continuous numerical features:\n",
    "\n",
    "- `age`\n",
    "- `trestbps`\n",
    "- `chol`\n",
    "- `thalach`\n",
    "- `oldpeak`\n",
    "- `slope`\n",
    "\n",
    "For each of these features, we will use a `Normalization()` layer to make sure the mean\n",
    "of each feature is 0 and its standard deviation is 1.\n",
    "\n",
    "Below, we define 3 utility functions to do the operations:\n",
    "\n",
    "- `encode_numerical_feature` to apply featurewise normalization to numerical features.\n",
    "- `encode_string_categorical_feature` to first turn string inputs into integer indices,\n",
    "then one-hot encode these integer indices.\n",
    "- `encode_integer_categorical_feature` to one-hot encode integer categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "HKtfnn19HYGP"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import IntegerLookup\n",
    "from tensorflow.keras.layers import Normalization\n",
    "from tensorflow.keras.layers import StringLookup\n",
    "\n",
    "\n",
    "def encode_numerical_feature(feature, name, dataset):\n",
    "    # Create a Normalization layer for our feature\n",
    "    normalizer = Normalization()\n",
    "\n",
    "    # Prepare a Dataset that only yields our feature\n",
    "    feature_ds = dataset.map(lambda x, y: x[name])\n",
    "    feature_ds = feature_ds.map(lambda x: tf.expand_dims(x, -1))\n",
    "\n",
    "    # Learn the statistics of the data\n",
    "    normalizer.adapt(feature_ds)\n",
    "\n",
    "    # Normalize the input feature\n",
    "    encoded_feature = normalizer(feature)\n",
    "    return encoded_feature\n",
    "\n",
    "\n",
    "def encode_categorical_feature(feature, name, dataset, is_string):\n",
    "    lookup_class = StringLookup if is_string else IntegerLookup\n",
    "    # Create a lookup layer which will turn strings into integer indices\n",
    "    lookup = lookup_class(output_mode=\"binary\")\n",
    "\n",
    "    # Prepare a Dataset that only yields our feature\n",
    "    feature_ds = dataset.map(lambda x, y: x[name])\n",
    "    feature_ds = feature_ds.map(lambda x: tf.expand_dims(x, -1))\n",
    "\n",
    "    # Learn the set of possible string values and assign them a fixed integer index\n",
    "    lookup.adapt(feature_ds)\n",
    "\n",
    "    # Turn the string input into integer indices\n",
    "    encoded_feature = lookup(feature)\n",
    "    return encoded_feature\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "07HF1H1HHYGQ"
   },
   "source": [
    "## Build a model\n",
    "\n",
    "With this done, we can create our end-to-end model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "hKasqXA3HYGQ"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'KerasTensor' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 73\u001b[0m\n\u001b[1;32m     55\u001b[0m all_features \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mconcatenate(\n\u001b[1;32m     56\u001b[0m     [\n\u001b[1;32m     57\u001b[0m         sex_encoded,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m     ]\n\u001b[1;32m     71\u001b[0m )\n\u001b[1;32m     72\u001b[0m x \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m32\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m\"\u001b[39m)(all_features)\n\u001b[0;32m---> 73\u001b[0m display(\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhead\u001b[49m())\n\u001b[1;32m     74\u001b[0m x \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mDropout(\u001b[38;5;241m0.5\u001b[39m)(x)\n\u001b[1;32m     75\u001b[0m output \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m1\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m\"\u001b[39m)(x)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KerasTensor' object has no attribute 'head'"
     ]
    }
   ],
   "source": [
    "# Categorical features encoded as integers\n",
    "sex = keras.Input(shape=(1,), name=\"sex\", dtype=\"int64\")\n",
    "cp = keras.Input(shape=(1,), name=\"cp\", dtype=\"int64\")\n",
    "fbs = keras.Input(shape=(1,), name=\"fbs\", dtype=\"int64\")\n",
    "restecg = keras.Input(shape=(1,), name=\"restecg\", dtype=\"int64\")\n",
    "exang = keras.Input(shape=(1,), name=\"exang\", dtype=\"int64\")\n",
    "ca = keras.Input(shape=(1,), name=\"ca\", dtype=\"int64\")\n",
    "\n",
    "# Categorical feature encoded as string\n",
    "thal = keras.Input(shape=(1,), name=\"thal\", dtype=\"string\")\n",
    "\n",
    "# Numerical features\n",
    "age = keras.Input(shape=(1,), name=\"age\")\n",
    "trestbps = keras.Input(shape=(1,), name=\"trestbps\")\n",
    "chol = keras.Input(shape=(1,), name=\"chol\")\n",
    "thalach = keras.Input(shape=(1,), name=\"thalach\")\n",
    "oldpeak = keras.Input(shape=(1,), name=\"oldpeak\")\n",
    "slope = keras.Input(shape=(1,), name=\"slope\")\n",
    "\n",
    "all_inputs = [\n",
    "    sex,\n",
    "    cp,\n",
    "    fbs,\n",
    "    restecg,\n",
    "    exang,\n",
    "    ca,\n",
    "    thal,\n",
    "    age,\n",
    "    trestbps,\n",
    "    chol,\n",
    "    thalach,\n",
    "    oldpeak,\n",
    "    slope,\n",
    "]\n",
    "\n",
    "# Integer categorical features\n",
    "sex_encoded = encode_categorical_feature(sex, \"sex\", train_ds, False)\n",
    "cp_encoded = encode_categorical_feature(cp, \"cp\", train_ds, False)\n",
    "fbs_encoded = encode_categorical_feature(fbs, \"fbs\", train_ds, False)\n",
    "restecg_encoded = encode_categorical_feature(restecg, \"restecg\", train_ds, False)\n",
    "exang_encoded = encode_categorical_feature(exang, \"exang\", train_ds, False)\n",
    "ca_encoded = encode_categorical_feature(ca, \"ca\", train_ds, False)\n",
    "\n",
    "# String categorical features\n",
    "thal_encoded = encode_categorical_feature(thal, \"thal\", train_ds, True)\n",
    "\n",
    "# Numerical features\n",
    "age_encoded = encode_numerical_feature(age, \"age\", train_ds)\n",
    "trestbps_encoded = encode_numerical_feature(trestbps, \"trestbps\", train_ds)\n",
    "chol_encoded = encode_numerical_feature(chol, \"chol\", train_ds)\n",
    "thalach_encoded = encode_numerical_feature(thalach, \"thalach\", train_ds)\n",
    "oldpeak_encoded = encode_numerical_feature(oldpeak, \"oldpeak\", train_ds)\n",
    "slope_encoded = encode_numerical_feature(slope, \"slope\", train_ds)\n",
    "\n",
    "all_features = layers.concatenate(\n",
    "    [\n",
    "        sex_encoded,\n",
    "        cp_encoded,\n",
    "        fbs_encoded,\n",
    "        restecg_encoded,\n",
    "        exang_encoded,\n",
    "        slope_encoded,\n",
    "        ca_encoded,\n",
    "        thal_encoded,\n",
    "        age_encoded,\n",
    "        trestbps_encoded,\n",
    "        chol_encoded,\n",
    "        thalach_encoded,\n",
    "        oldpeak_encoded,\n",
    "    ]\n",
    ")\n",
    "x = layers.Dense(32, activation=\"relu\")(all_features)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "output = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(all_inputs, output)\n",
    "model.compile(\"adam\", \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "display(model.summary())\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fi4Gh2COHYGQ"
   },
   "source": [
    "Let's visualize our connectivity graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "zMddP5fkHYGQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "# `rankdir='LR'` is to make the graph horizontal.\n",
    "keras.utils.plot_model(model, show_shapes=True, rankdir=\"LR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lWZhuWRwHYGQ"
   },
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "H0117sdLHYGR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.6220 - accuracy: 0.6860 - val_loss: 0.5155 - val_accuracy: 0.7705\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5880 - accuracy: 0.6860 - val_loss: 0.4905 - val_accuracy: 0.7705\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5578 - accuracy: 0.7066 - val_loss: 0.4715 - val_accuracy: 0.7705\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5801 - accuracy: 0.7025 - val_loss: 0.4547 - val_accuracy: 0.7705\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5434 - accuracy: 0.7025 - val_loss: 0.4410 - val_accuracy: 0.7869\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4855 - accuracy: 0.7562 - val_loss: 0.4287 - val_accuracy: 0.7869\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4727 - accuracy: 0.7521 - val_loss: 0.4190 - val_accuracy: 0.7869\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4439 - accuracy: 0.7893 - val_loss: 0.4110 - val_accuracy: 0.7705\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4326 - accuracy: 0.7810 - val_loss: 0.4039 - val_accuracy: 0.7377\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4241 - accuracy: 0.7645 - val_loss: 0.3977 - val_accuracy: 0.7705\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4142 - accuracy: 0.8058 - val_loss: 0.3926 - val_accuracy: 0.7705\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4125 - accuracy: 0.7851 - val_loss: 0.3885 - val_accuracy: 0.7869\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3857 - accuracy: 0.8182 - val_loss: 0.3861 - val_accuracy: 0.8033\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4135 - accuracy: 0.7934 - val_loss: 0.3840 - val_accuracy: 0.8033\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3863 - accuracy: 0.7934 - val_loss: 0.3820 - val_accuracy: 0.8197\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3641 - accuracy: 0.8306 - val_loss: 0.3803 - val_accuracy: 0.8197\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3632 - accuracy: 0.8471 - val_loss: 0.3797 - val_accuracy: 0.8361\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3797 - accuracy: 0.8264 - val_loss: 0.3789 - val_accuracy: 0.8361\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3513 - accuracy: 0.8471 - val_loss: 0.3785 - val_accuracy: 0.8361\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3712 - accuracy: 0.8140 - val_loss: 0.3787 - val_accuracy: 0.8361\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3308 - accuracy: 0.8636 - val_loss: 0.3786 - val_accuracy: 0.8361\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3346 - accuracy: 0.8802 - val_loss: 0.3784 - val_accuracy: 0.8361\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3300 - accuracy: 0.8471 - val_loss: 0.3779 - val_accuracy: 0.8361\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3352 - accuracy: 0.8512 - val_loss: 0.3781 - val_accuracy: 0.8361\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3109 - accuracy: 0.8802 - val_loss: 0.3781 - val_accuracy: 0.8197\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3273 - accuracy: 0.8802 - val_loss: 0.3791 - val_accuracy: 0.8197\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3152 - accuracy: 0.8802 - val_loss: 0.3795 - val_accuracy: 0.8197\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3027 - accuracy: 0.8760 - val_loss: 0.3802 - val_accuracy: 0.8197\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3226 - accuracy: 0.8471 - val_loss: 0.3814 - val_accuracy: 0.8197\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3092 - accuracy: 0.8719 - val_loss: 0.3823 - val_accuracy: 0.8197\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3051 - accuracy: 0.8636 - val_loss: 0.3833 - val_accuracy: 0.8197\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2934 - accuracy: 0.8802 - val_loss: 0.3837 - val_accuracy: 0.8197\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3115 - accuracy: 0.8884 - val_loss: 0.3833 - val_accuracy: 0.8197\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3054 - accuracy: 0.8760 - val_loss: 0.3837 - val_accuracy: 0.8197\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3008 - accuracy: 0.8512 - val_loss: 0.3845 - val_accuracy: 0.8197\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2741 - accuracy: 0.8802 - val_loss: 0.3852 - val_accuracy: 0.8197\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2958 - accuracy: 0.8843 - val_loss: 0.3865 - val_accuracy: 0.8197\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2869 - accuracy: 0.8760 - val_loss: 0.3873 - val_accuracy: 0.8197\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2756 - accuracy: 0.8802 - val_loss: 0.3873 - val_accuracy: 0.8197\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2686 - accuracy: 0.8802 - val_loss: 0.3884 - val_accuracy: 0.8197\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3087 - accuracy: 0.8678 - val_loss: 0.3894 - val_accuracy: 0.8197\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2877 - accuracy: 0.8719 - val_loss: 0.3898 - val_accuracy: 0.8197\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2685 - accuracy: 0.8802 - val_loss: 0.3903 - val_accuracy: 0.8197\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2872 - accuracy: 0.8843 - val_loss: 0.3912 - val_accuracy: 0.8197\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2931 - accuracy: 0.8926 - val_loss: 0.3913 - val_accuracy: 0.8197\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2918 - accuracy: 0.8802 - val_loss: 0.3918 - val_accuracy: 0.8197\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2749 - accuracy: 0.9050 - val_loss: 0.3919 - val_accuracy: 0.8197\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2585 - accuracy: 0.8843 - val_loss: 0.3924 - val_accuracy: 0.8197\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2649 - accuracy: 0.8802 - val_loss: 0.3934 - val_accuracy: 0.8197\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2596 - accuracy: 0.9050 - val_loss: 0.3942 - val_accuracy: 0.8197\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1699ed870>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_ds, epochs=50, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NkKBw1i7HYGR"
   },
   "source": [
    "We quickly get to 80% validation accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4JJZAuqZHYGR"
   },
   "source": [
    "## Inference on new data\n",
    "\n",
    "To get a prediction for a new sample, you can simply call `model.predict()`. There are\n",
    "just two things you need to do:\n",
    "\n",
    "1. wrap scalars into a list so as to have a batch dimension (models only process batches\n",
    "of data, not single samples)\n",
    "2. Call `convert_to_tensor` on each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "yJnu2tJrHYGR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 110ms/step\n",
      "This particular patient had a 20.6 percent probability of having a heart disease, as evaluated by our model.\n"
     ]
    }
   ],
   "source": [
    "sample = {\n",
    "    \"age\": 60,\n",
    "    \"sex\": 1,\n",
    "    \"cp\": 1,\n",
    "    \"trestbps\": 145,\n",
    "    \"chol\": 233,\n",
    "    \"fbs\": 1,\n",
    "    \"restecg\": 2,\n",
    "    \"thalach\": 150,\n",
    "    \"exang\": 0,\n",
    "    \"oldpeak\": 2.3,\n",
    "    \"slope\": 3,\n",
    "    \"ca\": 0,\n",
    "    \"thal\": \"fixed\",\n",
    "}\n",
    "\n",
    "input_dict = {name: tf.convert_to_tensor([value]) for name, value in sample.items()}\n",
    "predictions = model.predict(input_dict)\n",
    "\n",
    "print(\n",
    "    \"This particular patient had a %.1f percent probability \"\n",
    "    \"of having a heart disease, as evaluated by our model.\" % (100 * predictions[0][0],)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "structured_data_classification_from_scratch",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
