{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "767154e6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\tableofcontents\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\\tableofcontents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97e1d2b",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd7d47d",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "122b4fa5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Install Packages\n",
      "Python version: 3.10.9 | packaged by conda-forge | (main, Feb  2 2023, 20:26:08) [Clang 14.0.6 ]\n",
      "NumPy version: 1.24.2\n",
      "SciPy version:  1.7.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bburkman/miniforge3/envs/Tensorflow_2_11/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version:  2.11.0\n",
      "Keras version:  2.11.0\n",
      "Pandas version:  1.5.3\n",
      "SciKit-Learn version: 1.2.2\n",
      "Imbalanced-Learn version: 0.10.1\n",
      "Finished Installing Packages\n"
     ]
    }
   ],
   "source": [
    "print ('Install Packages')\n",
    "\n",
    "import sys, copy, math, time, os\n",
    "\n",
    "print ('Python version: {}'.format(sys.version))\n",
    "\n",
    "#from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "print ('NumPy version: {}'.format(np.__version__))\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "import scipy as sc\n",
    "print ('SciPy version:  {}'.format(sc.__version__))\n",
    "\n",
    "import tensorflow as tf\n",
    "print ('TensorFlow version:  {}'.format(tf.__version__))\n",
    "tf.config.run_functions_eagerly(True)\n",
    "tf.data.experimental.enable_debug_mode()\n",
    "\n",
    "from tensorflow import keras\n",
    "print ('Keras version:  {}'.format(keras.__version__))\n",
    "\n",
    "from keras import layers\n",
    "import keras.backend as K\n",
    "from keras.layers import IntegerLookup\n",
    "from keras.layers import Normalization\n",
    "from keras.layers import StringLookup\n",
    "from keras.utils import get_custom_objects\n",
    "from keras.utils import tf_utils\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "#from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "import pandas as pd\n",
    "print ('Pandas version:  {}'.format(pd.__version__))\n",
    "pd.set_option('display.max_rows', 500)\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use(\"pgf\")\n",
    "matplotlib.rcParams.update({\n",
    "#    \"pgf.texsystem\": \"pdflatex\",\n",
    "    'font.family': 'serif',\n",
    "    'text.usetex': True,\n",
    "    'pgf.rcfonts': False,\n",
    "})\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Library for reading Microsoft Access files\n",
    "#import pandas_access as mdb\n",
    "\n",
    "import sklearn\n",
    "print ('SciKit-Learn version: {}'.format(sklearn.__version__))\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import imblearn\n",
    "print ('Imbalanced-Learn version: {}'.format(imblearn.__version__))\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from imblearn.under_sampling import CondensedNearestNeighbour\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from imblearn.ensemble import RUSBoostClassifier\n",
    "from imblearn.ensemble import EasyEnsembleClassifier\n",
    "\n",
    "#!pip install pydot\n",
    "\n",
    "# Set Randomness.  Copied from https://www.kaggle.com/code/abazdyrev/keras-nn-focal-loss-experiments\n",
    "import random\n",
    "#np.random.seed(42) # NumPy\n",
    "#random.seed(42) # Python\n",
    "#tf.random.set_seed(42) # Tensorflow\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print ('Finished Installing Packages')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0437f109",
   "metadata": {},
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "919fb2db",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def Get_Data():\n",
    "    print ('Get_Data()')\n",
    "    data = pd.read_csv(\n",
    "        '../../Big_Files/CRSS_Imputed_All_05_19_23.csv',\n",
    "        low_memory=False\n",
    "    )\n",
    "    print ('data.shape: ', data.shape)\n",
    "    \n",
    "    print ('End Get_Data()')\n",
    "    print ()\n",
    "    return data\n",
    "\n",
    "def Test_Get_Data():\n",
    "    data = Get_Data()\n",
    "    display (data.head())\n",
    "    \n",
    "#Test_Get_Data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d540640",
   "metadata": {},
   "source": [
    "# Remove_Pedestrian_Crashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac62df2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Remove_Pedestrian_Crashes(data):\n",
    "    print ('Remove_Pedestrian_Crashes()')\n",
    "    display(data.PEDS.value_counts())\n",
    "    n = len(data[data.PEDS>0])\n",
    "    print ('Removing %d crashes that involve a pedestrian.' % n)\n",
    "    data = data[data.PEDS==0]\n",
    "    return data\n",
    "\n",
    "def Test_Remove_Pedestrian_Crashes():\n",
    "    data = Get_Data()\n",
    "    print (len(data))\n",
    "    data = Remove_Pedestrian_Crashes(data)\n",
    "    print (len(data))\n",
    "\n",
    "#Test_Remove_Pedestrian_Crashes()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adb9dce",
   "metadata": {},
   "source": [
    "## Engineer Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e85fa858",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Feature_Engineering_Cross_Two(data):\n",
    "    print ('Feature_Engineering_Cross_Two')\n",
    "    Pairs = [\n",
    "        ['AGE', 'SEX', 'AGE_x_SEX'],\n",
    "        ['AGE', 'SCH_BUS', 'AGE_x_SCH_BUS']\n",
    "    ]\n",
    "    for P in Pairs:\n",
    "        data[P[2]] = data[P[0]].map(str) + '_x_' + data[P[1]].map(str)\n",
    "    \n",
    "    print ()\n",
    "    return data\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b900000",
   "metadata": {},
   "source": [
    "## Thin Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86a0c76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Thin_Features(data):\n",
    "    print ('Thin_Features()')\n",
    "\n",
    "    Merge = [\n",
    "        'CASENUM',\n",
    "        'VEH_NO',\n",
    "        'PER_NO',        \n",
    "    ]\n",
    "\n",
    "    Accident = [\n",
    "        'DAY_WEEK',\n",
    "        'HOUR',\n",
    "        'INT_HWY',\n",
    "        'LGT_COND',\n",
    "        'MONTH',\n",
    "#        'PEDS',\n",
    "        'PERMVIT',\n",
    "        'PERNOTMVIT',\n",
    "        'PJ',\n",
    "        'PSU',\n",
    "        'PVH_INVL',\n",
    "        'REGION',\n",
    "        'REL_ROAD',\n",
    "        'RELJCT1',\n",
    "        'RELJCT2',\n",
    "        'SCH_BUS',\n",
    "        'TYP_INT',\n",
    "        'URBANICITY',\n",
    "        'VE_FORMS',\n",
    "        'VE_TOTAL',\n",
    "        'WEATHER',\n",
    "        'WRK_ZONE',\n",
    "        'YEAR',\n",
    "    ]\n",
    "    \n",
    "    Vehicle = [\n",
    "        'BODY_TYP',\n",
    "        'BUS_USE',\n",
    "        'EMER_USE',\n",
    "        'MAKE',\n",
    "#        'MOD_YEAR',\n",
    "        'MODEL',\n",
    "        'NUMOCCS',\n",
    "        'VALIGN',\n",
    "        'VNUM_LAN',\n",
    "        'VPROFILE',\n",
    "        'VSPD_LIM',\n",
    "#        'VSURCOND',\n",
    "        'VTRAFCON',\n",
    "        'VTRAFWAY',\n",
    "    ]\n",
    "    \n",
    "    Person = [\n",
    "        'AGE',\n",
    "        'LOCATION',\n",
    "        'PER_TYP',\n",
    "        'SEX',\n",
    "        'HOSPITAL',    \n",
    "    ]\n",
    "\n",
    "    Engineered = [\n",
    "        'VEH_AGE',\n",
    "        'AGE_x_SEX',\n",
    "        'AGE_x_SCH_BUS'\n",
    "    ]\n",
    "    \n",
    "    # Put features in alphabetical order\n",
    "    Features = Accident + Vehicle + Person + Engineered\n",
    "    Features = sorted(Features)\n",
    "#    Features = Merge + Features\n",
    "    \n",
    "    data = data.filter(Features, axis=1)\n",
    "    \n",
    "    print ('data.shape: ', data.shape)\n",
    "    \n",
    "    print ('End Thin_Features()')\n",
    "    print ()\n",
    "        \n",
    "    return data\n",
    "\n",
    "def Test_Thin_Features():\n",
    "    data = Get_Data()\n",
    "    data = Thin_Features(data)\n",
    "    for feature in data:\n",
    "        display(data[feature].value_counts())\n",
    "        \n",
    "#Test_Thin_Features()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e759eda",
   "metadata": {},
   "source": [
    "## Really Thin Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4202cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Really_Thin_Features(data):\n",
    "    print ('Really_Thin_Features()')\n",
    "\n",
    "    Merge = [\n",
    "        'CASENUM',\n",
    "        'VEH_NO',\n",
    "        'PER_NO',        \n",
    "    ]\n",
    "\n",
    "    Accident = [\n",
    "        'DAY_WEEK',\n",
    "        'HOUR',\n",
    "        'INT_HWY',\n",
    "#        'LGT_COND',\n",
    "        'MONTH',\n",
    "#        'PEDS',\n",
    "#        'PERMVIT',\n",
    "#        'PERNOTMVIT',\n",
    "        'PJ',\n",
    "        'PSU',\n",
    "#        'PVH_INVL',\n",
    "        'REGION',\n",
    "        'REL_ROAD',\n",
    "        'RELJCT1',\n",
    "#        'RELJCT2',\n",
    "#        'SCH_BUS',\n",
    "        'TYP_INT',\n",
    "        'URBANICITY',\n",
    "#        'VE_FORMS',\n",
    "#        'VE_TOTAL',\n",
    "        'WEATHER',\n",
    "#        'WRK_ZONE',\n",
    "        'YEAR',\n",
    "    ]\n",
    "    \n",
    "    Vehicle = [\n",
    "#        'BODY_TYP',\n",
    "#        'BUS_USE',\n",
    "#        'EMER_USE',\n",
    "#        'MAKE',\n",
    "#        'MOD_YEAR',\n",
    "#        'MODEL',\n",
    "#        'NUMOCCS',\n",
    "        'VALIGN',\n",
    "        'VNUM_LAN',\n",
    "        'VPROFILE',\n",
    "        'VSPD_LIM',\n",
    "#        'VSURCOND',\n",
    "        'VTRAFCON',\n",
    "        'VTRAFWAY',\n",
    "    ]\n",
    "    \n",
    "    Person = [\n",
    "        'AGE',\n",
    "#        'LOCATION',\n",
    "#        'PER_TYP',\n",
    "        'SEX',\n",
    "        'HOSPITAL',    \n",
    "    ]\n",
    "\n",
    "    Engineered = [\n",
    "#        'VEH_AGE',\n",
    "        'AGE_x_SEX',\n",
    "#        'AGE_x_SCH_BUS'\n",
    "    ]\n",
    "    \n",
    "    # Put features in alphabetical order\n",
    "    Features = Accident + Vehicle + Person + Engineered\n",
    "    Features = sorted(Features)\n",
    "#    Features = Merge + Features\n",
    "    \n",
    "    data = data.filter(Features, axis=1)\n",
    "    \n",
    "    print ('data.shape: ', data.shape)\n",
    "    \n",
    "    print ('End Thin_Features()')\n",
    "    print ()\n",
    "        \n",
    "    return data\n",
    "\n",
    "def Test_Really_Thin_Features():\n",
    "    data = Get_Data()\n",
    "    data = Really_Thin_Features(data)\n",
    "    for feature in data:\n",
    "        display(data[feature].value_counts())\n",
    "        \n",
    "#Test_Really_Thin_Features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11264ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Thin_to_Minimal_Features(data):\n",
    "    print ('Thin_to_Minimal_Features()')\n",
    "\n",
    "    Accident = [\n",
    "        'DAY_WEEK',\n",
    "        'HOUR',\n",
    "#        'INT_HWY',\n",
    "#        'LGT_COND',\n",
    "        'MONTH',\n",
    "#        'PEDS',\n",
    "#        'PERMVIT',\n",
    "#        'PERNOTMVIT',\n",
    "        'PJ',\n",
    "        'PSU',\n",
    "#        'PVH_INVL',\n",
    "        'REGION',\n",
    "#        'REL_ROAD',\n",
    "#        'RELJCT1',\n",
    "#        'RELJCT2',\n",
    "#        'SCH_BUS',\n",
    "#        'TYP_INT',\n",
    "        'URBANICITY',\n",
    "#        'VE_FORMS',\n",
    "#        'VE_TOTAL',\n",
    "        'WEATHER',\n",
    "#        'WRK_ZONE',\n",
    "        'YEAR',\n",
    "    ]\n",
    "    \n",
    "    Vehicle = [\n",
    "#        'BODY_TYP',\n",
    "#        'BUS_USE',\n",
    "#        'EMER_USE',\n",
    "#        'MAKE',\n",
    "#        'MOD_YEAR',\n",
    "#        'MODEL',\n",
    "#        'NUMOCCS',\n",
    "#        'VALIGN',\n",
    "#        'VNUM_LAN',\n",
    "#        'VPROFILE',\n",
    "#        'VSPD_LIM',\n",
    "#        'VSURCOND',\n",
    "#        'VTRAFCON',\n",
    "#        'VTRAFWAY',\n",
    "    ]\n",
    "    \n",
    "    Person = [\n",
    "#        'AGE',\n",
    "#        'LOCATION',\n",
    "#        'PER_TYP',\n",
    "#        'SEX',\n",
    "        'HOSPITAL',    \n",
    "    ]\n",
    "\n",
    "    Engineered = [\n",
    "#        'VEH_AGE',\n",
    "#        'AGE_x_SEX',\n",
    "#        'AGE_x_SCH_BUS'\n",
    "    ]\n",
    "    \n",
    "    # Put features in alphabetical order\n",
    "    Features = Accident + Vehicle + Person + Engineered\n",
    "    Features = sorted(Features)\n",
    "#    Features = Merge + Features\n",
    "    \n",
    "    data = data.filter(Features, axis=1)\n",
    "    \n",
    "    print ('data.shape: ', data.shape)\n",
    "    \n",
    "    print ('End Thin_Features()')\n",
    "    print ()\n",
    "        \n",
    "    return data\n",
    "\n",
    "def Test_Thin_to_Minimal_Features():\n",
    "    data = Get_Data()\n",
    "    data = Thin_to_Minimal_Features(data)\n",
    "    for feature in data:\n",
    "        display(data[feature].value_counts())\n",
    "        \n",
    "#Test_Thin_to_Minimal_Features()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52366e1a",
   "metadata": {},
   "source": [
    "## Get Dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47cefa1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_Dummies(data, target):\n",
    "    print ('Get_Dummies')\n",
    "    data = data.astype('category')\n",
    "    Target = data.pop(target)\n",
    "    data_Dummies = pd.get_dummies(data, prefix = data.columns)\n",
    "    data_Dummies = data_Dummies.join(Target)\n",
    "#    for feature in data_Dummies:\n",
    "#        print (feature)\n",
    "    print ()\n",
    "\n",
    "    return data_Dummies\n",
    "\n",
    "def Test_Get_Dummies():\n",
    "    print ('Test_Get_Dummies')\n",
    "    A = pd.DataFrame({\n",
    "        'A': ['a', 'b', 'a'], \n",
    "        'B': ['b', 'a', 'c'], \n",
    "        'C': [1, 2, 3]})\n",
    "    C = Get_Dummies(A, 'C')\n",
    "    display(C)\n",
    "    print ()\n",
    "\n",
    "#Test_Get_Dummies()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d43d6e",
   "metadata": {},
   "source": [
    "## Test-Train Split\n",
    "- We're using sklearn's train_test_split rather than Pandas's sample because the former has a 'stratify' option that will put the same proportion of HOSPITAL==1 into each set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "490cfcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Split_Data(data, target, test_size):\n",
    "    print ('Split_Data()')\n",
    "    X = data.drop(columns=[target])\n",
    "    y = data[target]\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        X, y, stratify=y, test_size=test_size, \n",
    "        #random_state=42\n",
    "    )\n",
    "    \n",
    "    a = y_train[y_train==1].shape[0]\n",
    "    b = y_test[y_test==1].shape[0]\n",
    "    print (\n",
    "        x_train.shape, \n",
    "        y_train.shape, a, round((a/(a+b)*100),2), '%')\n",
    "    print (\n",
    "        x_test.shape, \n",
    "        y_test.shape, b, round((b/(a+b)*100),2), '%'\n",
    "    )\n",
    "    print ()\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7b22f0",
   "metadata": {},
   "source": [
    "# Imbalanced Data Resampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e984f24a",
   "metadata": {},
   "source": [
    "## Tomek Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5a61c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Tomek_Links(X_train, y_train):\n",
    "    print ('Tomek_Links()')\n",
    "    M = len(y_train)\n",
    "    N = len(y_train)\n",
    "    n = len(y_train[y_train==1])\n",
    "    p = (N-n)/n\n",
    "    print ('Before Tomek Links:')\n",
    "    print ('%d samples, %d hospitalized, %d not hospitalized' % (N, n, N-n))\n",
    "    print ('%f percent of samples hospitalized' % (n/N*100))\n",
    "    print ('There are %f negative samples for each positive.' % ((N-n)/n))\n",
    "    print ()\n",
    "\n",
    "    X_train, y_train = TomekLinks().fit_resample(X_train, y_train)\n",
    "    N = len(y_train)\n",
    "    n = len(y_train[y_train==1])\n",
    "    p = (N-n)/n\n",
    "    print ('After Tomek Links:')\n",
    "    print ('%d samples, %d hospitalized, %d not hospitalized' % (N, n, N-n))\n",
    "    print ('%f percent of samples hospitalized' % (n/N*100))\n",
    "    print ('There are %f negative samples for each positive.' % ((N-n)/n))\n",
    "    print ('Removed %d samples, or %.2f%% of the set.' % (M-N, (M-N)/M*100))\n",
    "    print ()\n",
    "    \n",
    "    return X_train, y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ce9a6e",
   "metadata": {},
   "source": [
    "## Condensed Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05cfb8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Condensed_Nearest_Neighbour(X_train, y_train):\n",
    "    print ('Condensed_Nearest_Neighbour()')\n",
    "    N = X_train.shape[0]\n",
    "    print ('X_train.shape before = ', X_train.shape)\n",
    "    print ('y_train.shape before = ', y_train.shape)\n",
    "    print ()\n",
    "    cnn = CondensedNearestNeighbour(n_neighbors=None)\n",
    "    X_train, y_train = cnn.fit_resample(X_train, y_train)\n",
    "    n = X_train.shape[0]\n",
    "    print ('X_train.shape after = ', X_train.shape)\n",
    "    print ('y_train.shape after = ', y_train.shape)\n",
    "    print ()\n",
    "    print ('Removed %d samples, or %.2f%% of the set.' % (N-n, (N-n)/N*100))\n",
    "    print ()\n",
    "    \n",
    "    return X_train, y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bdd5a1",
   "metadata": {},
   "source": [
    "# Undersample Data\n",
    "- These functions take the three versions of the dataset, which correspond to these names in the paper:\n",
    "    - Thin (Hard)\n",
    "    - Really_Thin (Medium)\n",
    "    - Thin_to_Minimum (Easy)\n",
    "- runs Tomek Links on them once, then again, and saves the results to file.\n",
    "- Each of the three sets takes about 90 minutes to run on my laptop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8628b43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 µs, sys: 0 ns, total: 4 µs\n",
      "Wall time: 5.96 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def Undersample_Data_Thin(round_text):\n",
    "    print ('Undersample_Data_Thin()')\n",
    "    data = Get_Data()\n",
    "    data = data.astype('int64')\n",
    "    target = 'HOSPITAL'\n",
    "    data = Remove_Pedestrian_Crashes(data)\n",
    "    data = Feature_Engineering_Cross_Two(data)\n",
    "    data = Thin_Features(data)\n",
    "    data = Get_Dummies(data, target)\n",
    "\n",
    "    # Decrease set size, for debugging\n",
    "#    X_train, X_test, y_train, y_test = Split_Data(data, target, 0.80)\n",
    "#    data = X_train\n",
    "#    data[target] = y_train\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = Split_Data(data, target, 0.30)\n",
    "\n",
    "    # CNN took 6 minutes at 99% decreased set size.  \n",
    "#    X_train, y_train = Condensed_Nearest_Neighbour(X_train, y_train)\n",
    "\n",
    "    # 413,913 samples before Tomek\n",
    "    X_train.to_csv('../../Big_Files/X_train_Thin_before_Tomek' + round_text + '.csv', index=False)\n",
    "    y_train.to_csv('../../Big_Files/y_train_Thin_before_Tomek' + round_text + '.csv', index=False)\n",
    "    X_test.to_csv('../../Big_Files/X_test_Thin_before_Tomek' + round_text + '.csv', index=False)\n",
    "    y_test.to_csv('../../Big_Files/y_test_Thin_before_Tomek' + round_text + '.csv', index=False)\n",
    "\n",
    "    # Two rounds of Tomek took one hour 30 minutes\n",
    "    X_train, y_train = Tomek_Links(X_train, y_train)\n",
    "    # Write to csv and read back in, \n",
    "    #    so we can play with the stuff later without having to redo the Tomek Links, \n",
    "    #    which can take a long time.\n",
    "    \n",
    "    # 399,515 samples after Tomek, v1\n",
    "    # 399,714  v2\n",
    "    X_train.to_csv('../../Big_Files/X_train_Thin_after_Tomek' + round_text + '.csv', index=False)\n",
    "    y_train.to_csv('../../Big_Files/y_train_Thin_after_Tomek' + round_text + '.csv', index=False)\n",
    "    X_test.to_csv('../../Big_Files/X_test_Thin_after_Tomek' + round_text + '.csv', index=False)\n",
    "    y_test.to_csv('../../Big_Files/y_test_Thin_after_Tomek' + round_text + '.csv', index=False)\n",
    "\n",
    "    \n",
    "    X_train, y_train = Tomek_Links(X_train, y_train)\n",
    "    # 396,511 after Tomek twice v1\n",
    "    # 396,718 v2\n",
    "    X_train.to_csv('../../Big_Files/X_train_Thin_after_Tomek_Twice' + round_text + '.csv', index=False)\n",
    "    y_train.to_csv('../../Big_Files/y_train_Thin_after_Tomek_Twice' + round_text + '.csv', index=False)\n",
    "    X_test.to_csv('../../Big_Files/X_test_Thin_after_Tomek_Twice' + round_text + '.csv', index=False)\n",
    "    y_test.to_csv('../../Big_Files/y_test_Thin_after_Tomek_Twice' + round_text + '.csv', index=False)\n",
    "    print ()\n",
    "    \n",
    "def Undersample_Data_Really_Thin(round_text):\n",
    "    print ('Undersample_Data_Really_Thin()')\n",
    "\n",
    "    data = Get_Data()\n",
    "    data = data.astype('int64')\n",
    "    target = 'HOSPITAL'\n",
    "    data = Remove_Pedestrian_Crashes(data)\n",
    "    data = Feature_Engineering_Cross_Two(data)\n",
    "    data = Really_Thin_Features(data)\n",
    "    data = Get_Dummies(data, target)\n",
    "\n",
    "    # Decrease set size, for debugging\n",
    "#    X_train, X_test, y_train, y_test = Split_Data(data, target, 0.80)\n",
    "#    data = X_train\n",
    "#    data[target] = y_train\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = Split_Data(data, target, 0.30)\n",
    "\n",
    "    # CNN took 6 minutes at 99% decreased set size.  \n",
    "#    X_train, y_train = Condensed_Nearest_Neighbour(X_train, y_train)\n",
    "\n",
    "    # 413,913 Samples\n",
    "\n",
    "    X_train.to_csv('../../Big_Files/X_train_Really_Thin_before_Tomek' + round_text + '.csv', index=False)\n",
    "    y_train.to_csv('../../Big_Files/y_train_Really_Thin_before_Tomek' + round_text + '.csv', index=False)\n",
    "    X_test.to_csv('../../Big_Files/X_test_Really_Thin_before_Tomek' + round_text + '.csv', index=False)\n",
    "    y_test.to_csv('../../Big_Files/y_test_Really_Thin_before_Tomek' + round_text + '.csv', index=False)\n",
    "\n",
    "    # Two rounds of Tomek took one hour 30 minutes\n",
    "    X_train, y_train = Tomek_Links(X_train, y_train)\n",
    "    # Write to csv and read back in, \n",
    "    #    so we can play with the stuff later without having to redo the Tomek Links, \n",
    "    #    which can take a long time.\n",
    "    \n",
    "    # 406,691 Samples v1\n",
    "    # 406,781 v2\n",
    "    X_train.to_csv('../../Big_Files/X_train_Really_Thin_after_Tomek' + round_text + '.csv', index=False)\n",
    "    y_train.to_csv('../../Big_Files/y_train_Really_Thin_after_Tomek' + round_text + '.csv', index=False)\n",
    "    X_test.to_csv('../../Big_Files/X_test_Really_Thin_after_Tomek' + round_text + '.csv', index=False)\n",
    "    y_test.to_csv('../../Big_Files/y_test_Really_Thin_after_Tomek' + round_text + '.csv', index=False)\n",
    "    \n",
    "    # 405,288 Samples v1\n",
    "    # 405,368 v2\n",
    "\n",
    "    X_train, y_train = Tomek_Links(X_train, y_train)\n",
    "    X_train.to_csv('../../Big_Files/X_train_Really_Thin_after_Tomek_Twice' + round_text + '.csv', index=False)\n",
    "    y_train.to_csv('../../Big_Files/y_train_Really_Thin_after_Tomek_Twice' + round_text + '.csv', index=False)\n",
    "    X_test.to_csv('../../Big_Files/X_test_Really_Thin_after_Tomek_Twice' + round_text + '.csv', index=False)\n",
    "    y_test.to_csv('../../Big_Files/y_test_Really_Thin_after_Tomek_Twice' + round_text + '.csv', index=False)\n",
    "    print ()\n",
    "    \n",
    "def Undersample_Data_Thin_to_Minimal(round_text):\n",
    "    print ('Undersample_Data_Thin_to_Minimal()')\n",
    "\n",
    "    data = Get_Data()\n",
    "    data = data.astype('int64')\n",
    "    target = 'HOSPITAL'\n",
    "    data = Remove_Pedestrian_Crashes(data)\n",
    "    data = Feature_Engineering_Cross_Two(data)\n",
    "    data = Thin_to_Minimal_Features(data)\n",
    "    data = Get_Dummies(data, target)\n",
    "\n",
    "    # Decrease set size, for debugging\n",
    "#    X_train, X_test, y_train, y_test = Split_Data(data, target, 0.80)\n",
    "#    data = X_train\n",
    "#    data[target] = y_train\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = Split_Data(data, target, 0.30)\n",
    "\n",
    "    # CNN took 6 minutes at 99% decreased set size.  \n",
    "#    X_train, y_train = Condensed_Nearest_Neighbour(X_train, y_train)\n",
    "    X_train.to_csv('../../Big_Files/X_train_Thin_to_Minimal_before_Tomek' + round_text + '.csv', index=False)\n",
    "    y_train.to_csv('../../Big_Files/y_train_Thin_to_Minimal_before_Tomek' + round_text + '.csv', index=False)\n",
    "    X_test.to_csv('../../Big_Files/X_test_Thin_to_Minimal_before_Tomek' + round_text + '.csv', index=False)\n",
    "    y_test.to_csv('../../Big_Files/y_test_Thin_to_Minimal_before_Tomek' + round_text + '.csv', index=False)\n",
    "\n",
    "\n",
    "    # Two rounds of Tomek took one hour 30 minutes\n",
    "    X_train, y_train = Tomek_Links(X_train, y_train)\n",
    "    # Write to csv and read back in, \n",
    "    #    so we can play with the stuff later without having to redo the Tomek Links, \n",
    "    #    which can take a long time.\n",
    "    X_train.to_csv('../../Big_Files/X_train_Thin_to_Minimal_after_Tomek' + round_text + '.csv', index=False)\n",
    "    y_train.to_csv('../../Big_Files/y_train_Thin_to_Minimal_after_Tomek' + round_text + '.csv', index=False)\n",
    "    X_test.to_csv('../../Big_Files/X_test_Thin_to_Minimal_after_Tomek' + round_text + '.csv', index=False)\n",
    "    y_test.to_csv('../../Big_Files/y_test_Thin_to_Minimal_after_Tomek' + round_text + '.csv', index=False)\n",
    "\n",
    "\n",
    "    X_train, y_train = Tomek_Links(X_train, y_train)\n",
    "    X_train.to_csv('../../Big_Files/X_train_Thin_to_Minimal_after_Tomek_Twice' + round_text + '.csv', index=False)\n",
    "    y_train.to_csv('../../Big_Files/y_train_Thin_to_Minimal_after_Tomek_Twice' + round_text + '.csv', index=False)\n",
    "    X_test.to_csv('../../Big_Files/X_test_Thin_to_Minimal_after_Tomek_Twice' + round_text + '.csv', index=False)\n",
    "    y_test.to_csv('../../Big_Files/y_test_Thin_to_Minimal_after_Tomek_Twice' + round_text + '.csv', index=False)\n",
    "    print ()\n",
    "    \n",
    "#Undersample_Data_Thin('_v1')\n",
    "#Undersample_Data_Really_Thin('_v1')\n",
    "#Undersample_Data_Thin_to_Minimal('_v1')\n",
    "\n",
    "#Undersample_Data_Thin('_v2')\n",
    "#Undersample_Data_Really_Thin('_v2')\n",
    "#Undersample_Data_Thin_to_Minimal('_v2')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d577bab5",
   "metadata": {},
   "source": [
    "## Undersampling Results\n",
    "- Start with 747,342 samples\n",
    "- Remove 33,776 samples iwth pedestrians to get 713,566 samples\n",
    "- Split 70/30 to have 499,496 samples in training set, 214,070 in test set\n",
    "- In training set, 499,496 samples, 78,926 hospitalized, 420,570 not hospitalized\n",
    "\n",
    "\n",
    "| Feature Set | Random Seed | Tomek Round | # Samples Removed | % Samples Removed |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| Hard | 1 | 1 | 17,851 | 3.57 |\n",
    "| Hard | 2 | 1 | 7,794 | 3.56 |\n",
    "| Hard | 1 | 2 | 3,664 | 0.76 |\n",
    "| Hard | 2 | 2 | 3,751 | 0.78 |\n",
    "| Medium | 1 | 1 | 8,839 | 1.77 |\n",
    "| Medium | 2 | 1 | 8.825 | 1.77 |\n",
    "| Medium | 1 | 2 | 1,736 | 0.35 |\n",
    "| Medium | 2 | 2 | 1,656 | 0.34 |\n",
    "| Easy | 1 | 1 | 6 | 0.00 |\n",
    "| Easy | 2 | 1 | 3 | 0.00 |\n",
    "| Easy | 1 | 2 | 0 | 0.00 |\n",
    "| Easy | 2 | 2 | 0 | 0.00 |\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93129c5b",
   "metadata": {},
   "source": [
    "# Custom Metrics\n",
    "https://keras.io/api/metrics/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28552cd",
   "metadata": {},
   "source": [
    "## Balanced Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0cc2410",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Balanced_Accuracy(y_true, y_pred):\n",
    "    return K.mean(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80d7ecc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://aakashgoel12.medium.com/how-to-add-user-defined-function-get-f1-score-in-keras-metrics-3013f979ce0d\n",
    "def get_f1(y_true, y_pred): #taken from old keras source code\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "    return f1_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ae44b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://neptune.ai/blog/implementing-the-macro-f1-score-in-keras\n",
    "### Define F1 measures: F1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "def custom_f1(y_true, y_pred):\n",
    "    def recall_m(y_true, y_pred):\n",
    "        TP = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        Positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "\n",
    "        recall = TP / (Positives+K.epsilon())\n",
    "        return recall\n",
    "\n",
    "\n",
    "    def precision_m(y_true, y_pred):\n",
    "        TP = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        Pred_Positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "\n",
    "        precision = TP / (Pred_Positives+K.epsilon())\n",
    "        return precision\n",
    "\n",
    "    precision, recall = precision_m(y_true, y_pred), recall_m(y_true, y_pred)\n",
    "\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "146c67d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_metric(y_true, y_pred):\n",
    "    y_true = tf.dtypes.cast(y_true, tf.float64)\n",
    "    y_pred = tf.dtypes.cast(y_pred, tf.float64)\n",
    "    P = K.sum(y_true)\n",
    "    N = K.sum(1 - y_true)\n",
    "    # Note that Tensorflow and Keras round using \"banker's rounding,\"\n",
    "    # where halves round to the nearest even integer, so\n",
    "    # round(0.5) = 0, but round (1.5) = 2\n",
    "    Discrete_y_pred = K.round(y_pred)\n",
    "    TRUE = K.equal(y_true, Discrete_y_pred)\n",
    "    TRUE = tf.dtypes.cast(TRUE, tf.float64)\n",
    "    FALSE = 1-TRUE\n",
    "    Discrete_TP = Discrete_y_pred * TRUE\n",
    "    TP = K.sum(Discrete_TP)\n",
    "    FN = P - TP\n",
    "    Discrete_TN = (1 - Discrete_y_pred) * TRUE\n",
    "    TN = K.sum(Discrete_TN)\n",
    "    FP = N - TN    \n",
    "\n",
    "#    CM = confusion_matrix(y_true, y_pred)\n",
    "#    print (CM)\n",
    "#    P = CM[1][0] + CM[1][1]\n",
    "#    N = CM[0][0] + CM[0][1]\n",
    "#    TN = CM[0][0]\n",
    "#    FP = CM[0][1]\n",
    "#    FN = CM[1][0]\n",
    "#    TP = CM[1][1]\n",
    "#    print ('TP = ', TP, ' FN = ', FN, ' FP = ', FP, ' TN = ', TN)\n",
    "    \n",
    "    return P, N, TP, FN, TN, FP\n",
    "\n",
    "def Test_Custom_Metric():\n",
    "    y_true = [0.0,1.0,0.0,1.0]\n",
    "    y_proba = [0.2, 0.49, 0.75, 0.9]\n",
    "    y_pred = [round(x) for x in y_proba]\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_true = tf.convert_to_tensor(y_true)\n",
    "    y_pred = tf.convert_to_tensor(y_pred)\n",
    "    print (y_true)\n",
    "    print (y_pred)\n",
    "    P, N, TP, FN, TN, FP = custom_metric(y_true, y_pred)\n",
    "    print ('TP = ', TP, ' FN = ', FN, ' FP = ', FP, ' TN = ', TN)\n",
    "    \n",
    "#Test_Custom_Metric()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7527cec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Accuracy_Metric(y_true, y_pred):\n",
    "    P, N, TP, FN, TN, FP = custom_metric(y_true, y_pred)\n",
    "    metric = (TP+TN)/(TP + FN + FP + TN + K.epsilon())\n",
    "    return metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a24413b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Precision_Metric(y_true, y_pred):\n",
    "    P, N, TP, FN, TN, FP = custom_metric(y_true, y_pred)\n",
    "    metric = TP/(TP + FP + K.epsilon())\n",
    "    return metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8c8c0e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Recall_Metric(y_true, y_pred):\n",
    "    P, N, TP, FN, TN, FP = custom_metric(y_true, y_pred)\n",
    "    metric = TP/(TP + FN + K.epsilon())\n",
    "    return metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0defac89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Balanced_Accuracy_Metric(y_true, y_pred):\n",
    "    P, N, TP, FN, TN, FP = custom_metric(y_true, y_pred)\n",
    "    metric = ( TN/(2*(TN + FP + K.epsilon())) + TP/(2*(FN + TP + K.epsilon())))\n",
    "    return metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9afe9e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def F1_Metric(y_true, y_pred):\n",
    "    precision = Precision_Metric(y_true, y_pred)\n",
    "    recall = Recall_Metric(y_true, y_pred)\n",
    "    metric = 2/(1/(precision + K.epsilon()) + 1/(recall + K.epsilon()))\n",
    "    return metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "604a0833",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gmean_Metric(y_true, y_pred):\n",
    "    P, N, TP, FN, TN, FP = custom_metric(y_true, y_pred)\n",
    "    precision = TP/(TP + FP + K.epsilon())\n",
    "    specificity = TN/(TN + FP + K.epsilon())\n",
    "    metric = K.sqrt(precision * specificity)\n",
    "    return metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7d911f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Balanced_Precision_Metric(y_true, y_pred):\n",
    "    P, N, TP, FN, TN, FP = custom_metric(y_true, y_pred)\n",
    "    metric = (TP * N)/(TP * N + FP * P + K.epsilon())\n",
    "    return metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b1f07d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Balanced_F1_Metric(y_true, y_pred):\n",
    "    precision = Balanced_Precision_Metric(y_true, y_pred)\n",
    "    recall = Recall_Metric(y_true, y_pred)\n",
    "    metric = 2/(1/(precision + K.epsilon()) + 1/(recall + K.epsilon()))\n",
    "    return metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88dcfd4d",
   "metadata": {},
   "source": [
    "# Loss Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7cf4a61",
   "metadata": {},
   "source": [
    "## Alpha Weighted Binary Crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a639e7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_weighted_binary_crossentropy_with_parameter(alpha = 0.5):\n",
    "    def alpha_weighted_binary_crossentropy(y_true, y_pred):\n",
    "        y_true = tf.cast(y_true, dtype=y_pred.dtype)\n",
    "\n",
    "        binary_crossentropy = keras.backend.binary_crossentropy(y_true, y_pred)\n",
    "        weights = tf.where(tf.equal(y_true,1),alpha, 1-alpha)\n",
    "        product = tf.multiply(binary_crossentropy, weights)\n",
    "        loss = keras.backend.mean(product)\n",
    "        return loss\n",
    "    return alpha_weighted_binary_crossentropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "51fa3b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_weighted_binary_crossentropy_with_class_weight_parameters(weight_0 = 1.0, weight_1 = 1.0):\n",
    "    # Weights for each class = (nSamples Total)/(2* (nSamples in Class))\n",
    "    def alpha_weighted_binary_crossentropy(y_true, y_pred):\n",
    "        y_true = tf.cast(y_true, dtype=y_pred.dtype)\n",
    "        binary_crossentropy = keras.backend.binary_crossentropy(y_true, y_pred, from_logits=False)\n",
    "        weights = tf.where(tf.equal(y_true,1),weight_1, weight_0)\n",
    "        product = tf.multiply(binary_crossentropy, weights)\n",
    "        loss = keras.backend.mean(product)\n",
    "        return loss\n",
    "    return alpha_weighted_binary_crossentropy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74dedab",
   "metadata": {},
   "source": [
    "## Focal Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f61cb331",
   "metadata": {},
   "outputs": [],
   "source": [
    "def focal_loss(y_true, y_pred):\n",
    "    # The dataset has  259077  elements.\n",
    "    # The target group has  31891  elements.\n",
    "    # Our target is  12.3095 % of the dataset.\n",
    "    # There are  8.12  negative elements for each positive.    \n",
    "#    p = 8.12\n",
    "    p = 5.94\n",
    "\n",
    "    alpha = (p/(p+1))*1.0\n",
    "\n",
    "    gamma_1 = 0.0 # Must be float for the tf.math.pow() function to work.\n",
    "    gamma_2 = 0.0\n",
    "    y_true = tf.cast(y_true, dtype=y_pred.dtype)\n",
    "    binary_crossentropy = keras.backend.binary_crossentropy(y_true, y_pred)\n",
    "#    print (binary_crossentropy.numpy())\n",
    "    weights = tf.where(tf.equal(y_true,1),alpha, 1-alpha)\n",
    "#    print (weights.numpy())\n",
    "    focal = tf.where(tf.equal(y_true,1), (1.0-y_pred), (y_pred))\n",
    "    power = tf.where(tf.equal(y_true,1), gamma_1, gamma_2)\n",
    "    focal_power = tf.math.pow(focal,power)\n",
    "#    print (focal.numpy())\n",
    "#    print (power.numpy())\n",
    "#    print (focal_power.numpy())\n",
    "    product = tf.multiply(binary_crossentropy, weights)\n",
    "    focal_power_product = tf.multiply(product, focal_power)\n",
    "#    print (focal_power_product.numpy())\n",
    "    loss = keras.backend.mean(focal_power_product)\n",
    "#    print (loss.numpy())\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efaef565",
   "metadata": {},
   "source": [
    "## Focal Loss with Parameters\n",
    "- Adapted from https://www.kaggle.com/code/abazdyrev/keras-nn-focal-loss-experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c48a20f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def focal_loss_with_parameters(alpha = 0.5, gamma_0=0.0, gamma_1=0.0):\n",
    "    def focal_loss(y_true, y_pred):\n",
    "        y_true = tf.cast(y_true, dtype=y_pred.dtype)\n",
    "#        tf.clip_by_value(y_pred, 0.00001, 0.99999) # Make sure we don't blow up the logarithm\n",
    "        binary_crossentropy = keras.backend.binary_crossentropy(y_true, y_pred)\n",
    "        weights = tf.where(tf.equal(y_true,1),alpha, 1.0-alpha)\n",
    "        focal = tf.where(tf.equal(y_true,1), (1.0-y_pred), (y_pred))\n",
    "        power = tf.where(tf.equal(y_true,0), gamma_0, gamma_1)\n",
    "        focal_power = tf.math.pow(focal,power)\n",
    "        product = tf.multiply(binary_crossentropy, weights)\n",
    "        focal_power_product = tf.multiply(product, focal_power)\n",
    "#        tf.clip_by_value(focal_power_product, 0.00001, 0.99999)\n",
    "        loss = keras.backend.mean(focal_power_product)\n",
    "        if math.isnan(loss):\n",
    "            print ('loss is nan')\n",
    "        return loss\n",
    "    \n",
    "    return focal_loss\n",
    "\n",
    "get_custom_objects().update({'focal_loss_with_parameters': focal_loss_with_parameters()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1224812d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def focal_loss_with_parameters_2(alpha=.25, gamma=2.0):\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
    "        pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
    "        return -K.mean(alpha * K.pow(1. - pt_1, gamma) * K.log(K.epsilon()+pt_1))-K.mean((1-alpha) * K.pow( pt_0, gamma) * K.log(1. - pt_0 + K.epsilon()))\n",
    "    return focal_loss_fixed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0c9b6f",
   "metadata": {},
   "source": [
    "## Test Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0b909c30",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def Test_Loss_Functions():\n",
    "    \n",
    "    ### Data as list y_test and y_prob\n",
    "    y_test = [0.0]*500 + [1.0]*500\n",
    "    y_test_binary = [0]*500 + [1]*500\n",
    "#    y_test = [0.0, 1.0]*5\n",
    "#    y_test_binary = [0,1]*5\n",
    "#    y_prob = [0.0001, 0.001, 0.01, 0.1, 0.3, 0.5, 0.7, 0.9, 0.99, 0.999]\n",
    "    y_prob = [random.random() for x in range (1000)]\n",
    "#    print (y_prob)\n",
    "    \n",
    "    ### Data as tensors y_true and y_pred\n",
    "    y_true = np.array(y_test, dtype=np.float32)\n",
    "    y_true = tf.convert_to_tensor(y_true)\n",
    "    y_pred = np.array(y_prob, dtype=np.float32)\n",
    "    y_pred = tf.convert_to_tensor(y_pred)\n",
    "\n",
    "    ####################################################\n",
    "    print ('Test with p==1.0, alpha = 0.5, gamma = 0.0')\n",
    "\n",
    "    ### Calculate binary crossentropy by hand\n",
    "    BCE = [-(y_test[i] * math.log(y_prob[i]) + (1 - y_test[i]) * math.log(1 - y_prob[i])) for i in range (10)]\n",
    "    Class_Weights = [1.0,1.0]\n",
    "    Weights = [Class_Weights[y_test_binary[i]] for i in range(10)]\n",
    "    Product = [BCE[i] * Weights[i] for i in range (10)]\n",
    "    loss = sum(Product)/len(Product)\n",
    "    print (loss, \"  Hand-calculated BCE loss\")\n",
    "    \n",
    "    ### Calculate binary crossentropy like I did in my custom loss functions\n",
    "    binary_crossentropy = keras.backend.binary_crossentropy(y_true, y_pred, from_logits=False)\n",
    "#    display(binary_crossentropy.numpy())\n",
    "    loss = keras.backend.mean(binary_crossentropy).numpy()\n",
    "    print (loss, \"  My custom AWBCE function's no-alpha backend\")\n",
    "    \n",
    "    ### Calculate binary crossentropy using my custom loss function\n",
    "    loss_function = alpha_weighted_binary_crossentropy_with_parameter(alpha = 0.5)\n",
    "    loss = loss_function(y_true, y_pred).numpy()\n",
    "    print (loss, '  My custom one-parameter AWBCE function')\n",
    "    \n",
    "    ### Calculate binary crossentropy using my custom loss function\n",
    "    # Weights for each class = (nSamples Total)/(2* (nSamples in Class))\n",
    "    loss_function = alpha_weighted_binary_crossentropy_with_class_weight_parameters(weight_0 = 1.0, weight_1 = 1.0)\n",
    "    loss = loss_function(y_true, y_pred).numpy()\n",
    "    print (loss, '  My custom two-parameter AWBCE function')\n",
    "    \n",
    "    ### Calculate binary crossentropy using Keras's loss function\n",
    "    bce = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "    loss = bce(y_true, y_pred).numpy()\n",
    "    print (loss, \"  Keras's BCE function\")\n",
    "    \n",
    "    ### Calculate the same value using the BinaryFocalCrossentropy function\n",
    "    loss_function = tf.keras.losses.BinaryFocalCrossentropy(\n",
    "        apply_class_balancing = True, \n",
    "        alpha = 0.5,\n",
    "        gamma = 0.0, \n",
    "        from_logits=False\n",
    "    )\n",
    "    loss = loss_function(y_true, y_pred).numpy()\n",
    "    print (loss, \"  Keras's BFC function\")\n",
    "    \n",
    "    ### Calculate focal loss using my custom loss function\n",
    "    loss_function = focal_loss_with_parameters(0.5, 0.0, 0.0)\n",
    "    loss = loss_function(y_true, y_pred).numpy()\n",
    "    print (loss, '  My BFC function with gamma=0.0')\n",
    "    \n",
    "    ####################################################\n",
    "    print ()\n",
    "    print ('Test with p = 3.0, alpha = 0.75, gamma = 0.0')\n",
    "    \n",
    "    ### Calculate binary crossentropy using my custom loss function\n",
    "    loss_function = alpha_weighted_binary_crossentropy_with_parameter(alpha = 0.75)\n",
    "    loss = loss_function(y_true, y_pred).numpy()\n",
    "    print (loss, '  My custom one-parameter AWBCE function')\n",
    "    \n",
    "    ### Calculate binary crossentropy using my custom loss function\n",
    "    # Weights for each class = (nSamples Total)/(2* (nSamples in Class))\n",
    "    loss_function = alpha_weighted_binary_crossentropy_with_class_weight_parameters(weight_0 = 2.0/3.0, weight_1 = 2.0)\n",
    "    loss = loss_function(y_true, y_pred).numpy()\n",
    "    print (loss, '  My custom two-parameter AWBCE function')\n",
    "    \n",
    "    ### Calculate the same value using the BinaryFocalCrossentropy function\n",
    "    loss_function = tf.keras.losses.BinaryFocalCrossentropy(\n",
    "        apply_class_balancing = True, \n",
    "        alpha = 0.75,\n",
    "        gamma = 0.0, \n",
    "        from_logits=False\n",
    "    )\n",
    "    loss = loss_function(y_true, y_pred).numpy()\n",
    "    print (loss, \"  Keras's BFC function\")\n",
    "    \n",
    "    ### Calculate focal loss using my custom loss function\n",
    "    loss_function = focal_loss_with_parameters(0.75, 0.0, 0.0)\n",
    "    loss = loss_function(y_true, y_pred).numpy()\n",
    "    print (loss, '  My BFC function with gamma=0.0')\n",
    "    \n",
    "    ####################################################\n",
    "    print ()\n",
    "    print ('Test with alpha = 0.8, gamma = 0.0')\n",
    "    \n",
    "    ### Calculate the same value using the BinaryFocalCrossentropy function\n",
    "    loss_function = tf.keras.losses.BinaryFocalCrossentropy(\n",
    "        apply_class_balancing = True, \n",
    "        alpha = 0.8,\n",
    "        gamma = 0.0, \n",
    "#        from_logits=False\n",
    "    )\n",
    "    loss = loss_function(y_true, y_pred).numpy()\n",
    "    print (loss, \"  Keras's BFC function\")\n",
    "    \n",
    "    ### Calculate focal loss using my custom loss function\n",
    "    loss_function = focal_loss_with_parameters(0.8, 0.0, 0.0)\n",
    "    loss = loss_function(y_true, y_pred).numpy()\n",
    "    print (loss, '  My BFC function')\n",
    "\n",
    "    ####################################################\n",
    "    print ()\n",
    "    print ('Test with alpha = 0.8, gamma = 2.0')\n",
    "    \n",
    "    ### Calculate the same value using the BinaryFocalCrossentropy function\n",
    "    loss_function = tf.keras.losses.BinaryFocalCrossentropy(\n",
    "        apply_class_balancing = True, \n",
    "        alpha = 0.8,\n",
    "        gamma = 2.0, \n",
    "#        from_logits=False\n",
    "    )\n",
    "    loss = loss_function(y_true, y_pred).numpy()\n",
    "    print (loss, \"  Keras's BFC function\")\n",
    "    \n",
    "    ### Calculate focal loss using my custom loss function\n",
    "    loss_function = focal_loss_with_parameters(0.8, 2.0, 2.0)\n",
    "    loss = loss_function(y_true, y_pred).numpy()\n",
    "    print (loss, '  My BFC function with gamma=2.0')\n",
    "\n",
    "    ####################################################\n",
    "    print ()\n",
    "    print ('Test with p = 1.0, alpha = 0.5, gamma = 2.0')\n",
    "    \n",
    "    ### Calculate the same value using the BinaryFocalCrossentropy function\n",
    "    loss_function = tf.keras.losses.BinaryFocalCrossentropy(\n",
    "        apply_class_balancing = True, \n",
    "        alpha = 0.5,\n",
    "        gamma = 2.0, \n",
    "#        from_logits=False\n",
    "    )\n",
    "    loss = loss_function(y_true, y_pred).numpy()\n",
    "    print (loss, \"  Keras's BFC function\")\n",
    "    \n",
    "    ### Calculate focal loss using my custom loss function\n",
    "    loss_function = focal_loss_with_parameters(0.5, 2.0, 2.0)\n",
    "    loss = loss_function(y_true, y_pred).numpy()\n",
    "    print (loss, '  My BFC function with gamma=2.0')\n",
    "\n",
    "    ##################################################################\n",
    "    print ()\n",
    "    print (\"Test Keras's BFC Function with different values of alpha\")\n",
    "    \n",
    "    ### Calculate the same value using the BinaryFocalCrossentropy function\n",
    "    loss_function = tf.keras.losses.BinaryFocalCrossentropy(\n",
    "        apply_class_balancing = True, \n",
    "        alpha = 0.1,\n",
    "        gamma = 0.0, \n",
    "#        from_logits=False\n",
    "    )\n",
    "    loss = loss_function(y_true, y_pred).numpy()\n",
    "    print (loss, \"  Keras's BFC function\")\n",
    "    \n",
    "    ### Calculate the same value using the BinaryFocalCrossentropy function\n",
    "    loss_function = tf.keras.losses.BinaryFocalCrossentropy(\n",
    "        apply_class_balancing = True, \n",
    "        alpha = 0.5,\n",
    "        gamma = 0.0, \n",
    "        from_logits=False\n",
    "    )\n",
    "    loss = loss_function(y_true, y_pred).numpy()\n",
    "    print (loss, \"  Keras's BFC function\")\n",
    "    \n",
    "    ### Calculate the same value using the BinaryFocalCrossentropy function\n",
    "    loss_function = tf.keras.losses.BinaryFocalCrossentropy(\n",
    "        apply_class_balancing = True, \n",
    "        alpha = 0.9,\n",
    "        gamma = 0.0, \n",
    "        from_logits=False\n",
    "    )\n",
    "    loss = loss_function(y_true, y_pred).numpy()\n",
    "    print (loss, \"  Keras's BFC function\")\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "#Test_Loss_Functions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c65a77",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a36e3f",
   "metadata": {},
   "source": [
    "## Simple Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3635b98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Make_Simple_Model(X_train):\n",
    "    print ('Make_Model()')\n",
    "    model = keras.Sequential(\n",
    "        [\n",
    "            keras.layers.Dense(\n",
    "                256, activation=\"relu\", input_shape=(X_train.shape[-1],)\n",
    "            ),\n",
    "            keras.layers.Dense(256, activation=\"relu\"),\n",
    "            keras.layers.Dropout(0.3),\n",
    "            keras.layers.Dense(256, activation=\"relu\"),\n",
    "            keras.layers.Dropout(0.3),\n",
    "            keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "        ]\n",
    "    )\n",
    "#    display(model.summary())\n",
    "    print ()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "78cb5f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Train_Simple_Model (X_train, X_test, y_train, y_test, model, loss_function, r_target, filename):\n",
    "    print ('Train_Model()')\n",
    "    metrics = [\n",
    "#        keras.metrics.FalseNegatives(name=\"fn\"),\n",
    "#        keras.metrics.FalsePositives(name=\"fp\"),\n",
    "#        keras.metrics.TrueNegatives(name=\"tn\"),\n",
    "#        keras.metrics.TruePositives(name=\"tp\"),\n",
    "        keras.metrics.Precision(name=\"precision\"),\n",
    "        keras.metrics.Recall(name=\"recall\"),\n",
    "#        keras.metrics.BinaryAccuracy(name=\"accuracy\"),\n",
    "        Balanced_Accuracy_Metric,\n",
    "#        Gmean_Metric,\n",
    "        Balanced_Precision_Metric,\n",
    "#        F1_Metric,\n",
    "        Balanced_F1_Metric,\n",
    "    ]\n",
    "\n",
    "    model.compile(\n",
    "#        optimizer=keras.optimizers.Adam(), \n",
    "        optimizer=keras.optimizers.Adam(1e-7, clipnorm=0.99999), \n",
    "        loss=loss_function, \n",
    "        metrics=metrics\n",
    "    )\n",
    "\n",
    "#    class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "#    class_weight = {0: 1, 1: 1}\n",
    "    class_weight={0:(1+r_target)/(2*r_target), 1:(1+r_target)/(2*1)}\n",
    "    \n",
    "    model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        batch_size=128,\n",
    "        epochs=30,\n",
    "        verbose=0,\n",
    "#        callbacks=callbacks,\n",
    "        validation_data=(X_test, y_test),\n",
    "        class_weight=class_weight,\n",
    "    )\n",
    "    \n",
    "    # Make everything a numpy array\n",
    "    y_proba = model.predict(X_test)\n",
    "    # y_proba is a numpy array\n",
    "    y_pred = np.around(y_proba)\n",
    "    # y_test is a Pandas dataframe\n",
    "    y_test = y_test.to_numpy()\n",
    "    \n",
    "    Balance_Proba(y_test, y_proba, y_pred, r_target, filename)    \n",
    "    \n",
    "    print ()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f61f36",
   "metadata": {},
   "source": [
    "## Another Keras Binary Classification Model\n",
    "https://machinelearningmastery.com/binary-classification-tutorial-with-the-keras-deep-learning-library/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2c68709e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Keras_Binary_Focal_Crossentropy(X_train, X_test, y_train, y_test, r_target, alpha, gamma, epochs, filename, title):\n",
    "    print ('Keras_Binary_Focal_Crossentropy')\n",
    "    print ('alpha = ', alpha, ', gamma = ', gamma)\n",
    "    print ()\n",
    "    loss_function = tf.keras.losses.BinaryFocalCrossentropy(\n",
    "        apply_class_balancing=True,\n",
    "        alpha=alpha,\n",
    "        gamma=gamma,\n",
    "#        from_logits=False,\n",
    "#        label_smoothing=0.0,\n",
    "#        axis=-1,\n",
    "#        reduction=losses_utils.ReductionV2.AUTO,\n",
    "#        name='binary_focal_crossentropy'\n",
    "    )   \n",
    "    \n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(60, input_shape=(X_train.shape[-1],), activation='relu'))\n",
    "#    model.add(Dense(30, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))    \n",
    "    # Compile model\n",
    "    metrics = [\n",
    "        keras.metrics.Precision(name=\"precision\"),\n",
    "        keras.metrics.Recall(name=\"recall\"),\n",
    "        F1_Metric,\n",
    "    ]\n",
    "    model.compile(loss=loss_function, optimizer=tf.keras.optimizers.Adam(), metrics=metrics)\n",
    "    estimator = KerasClassifier(\n",
    "        model=model, \n",
    "#        random_state=42,\n",
    "        metrics=metrics,\n",
    "        batch_size=128, \n",
    "        verbose=0,\n",
    "        epochs=epochs,\n",
    "    )\n",
    "    # What does this do?\n",
    "    kfold = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "    \n",
    "    # Fit model\n",
    "    estimator.fit(\n",
    "        X_train, \n",
    "        y_train.values.ravel(),\n",
    "        class_weight={0:(1+r_target)/(2*r_target), 1:(1+r_target)/(2*1)},\n",
    "    )\n",
    "    \n",
    "    # Test for overfit\n",
    "    y_proba = estimator.predict_proba(X_train)\n",
    "    y_proba = [x[1] for x in y_proba]\n",
    "    print ('y_proba unique')\n",
    "    print (np.unique(y_proba))\n",
    "    y_pred = K.round(y_proba).numpy()\n",
    "    y_proba = np.array(y_proba)\n",
    "    Balance_Proba(y_train, y_proba, y_pred, r_target, filename + '_Train', title)\n",
    "\n",
    "    # Test model on test set\n",
    "    y_proba = estimator.predict_proba(X_test)\n",
    "    y_proba = [x[1] for x in y_proba]\n",
    "    print ('y_proba unique')\n",
    "    print (np.unique(y_proba))\n",
    "    y_pred = K.round(y_proba).numpy()\n",
    "    y_proba = np.array(y_proba)\n",
    "    Balance_Proba(y_test, y_proba, y_pred, r_target, filename + '_Test', title)\n",
    "    \n",
    "    print ()\n",
    "    return 0    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d06a6c",
   "metadata": {},
   "source": [
    "## Our Binary Focal Crossentropy Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2c65be95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Our_Binary_Focal_Crossentropy(X_train, X_test, y_train, y_test, r_target, alpha, gamma_0, gamma_1, epochs, filename, title):\n",
    "    print ('Our_Binary_Focal_Crossentropy')\n",
    "    print ('alpha = ', alpha, ' gamma_0 = ', gamma_0, ', gamma_1 = ', gamma_1)\n",
    "\n",
    "#    alpha_target = r_target/(r_target+1)\n",
    "    loss_function = focal_loss_with_parameters(alpha, gamma_0, gamma_1)\n",
    "#    loss_function = focal_loss_with_parameters_2(alpha_target, gamma)\n",
    "    \n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(60, input_shape=(X_train.shape[-1],), activation='relu'))\n",
    "#    model.add(Dense(30, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))    \n",
    "    # Compile model\n",
    "    model.compile(loss=loss_function, optimizer=tf.keras.optimizers.Adam(), metrics=['accuracy'])\n",
    "    metrics = [\n",
    "        keras.metrics.Precision(name=\"precision\"),\n",
    "        keras.metrics.Recall(name=\"recall\"),\n",
    "        F1_Metric,\n",
    "    ]\n",
    "    estimator = KerasClassifier(\n",
    "        model=model, \n",
    "#        random_state=42,\n",
    "        metrics=metrics,\n",
    "        batch_size=128, \n",
    "        verbose=0,\n",
    "        epochs=epochs,\n",
    "    )\n",
    "    # What does this do?\n",
    "    kfold = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "    \n",
    "    # Fit model\n",
    "    estimator.fit(\n",
    "        X_train, \n",
    "        y_train.values.ravel(),\n",
    "        class_weight={0:(1+r_target)/(2*r_target), 1:(1+r_target)/(2*1)},\n",
    "    )\n",
    "    y_proba = estimator.predict_proba(X_test)\n",
    "    y_proba = [x[1] for x in y_proba]\n",
    "    y_pred = K.round(y_proba).numpy()\n",
    "    y_proba = np.array(y_proba)\n",
    "\n",
    "    Balance_Proba(y_test, y_proba, y_pred, r_target, filename, title)\n",
    "    print ()\n",
    "    return 0    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91de86f",
   "metadata": {},
   "source": [
    "## AdaBoost Model\n",
    "https://stackoverflow.com/questions/39063676/how-to-boost-a-keras-based-neural-network-using-adaboost\n",
    "- model.predict_proba(X_test) returns two columns, \n",
    "    - the first the probability that the sample is in class 0, \n",
    "    - and the second the probability that the sample is in class 1.\n",
    "    - We just want the second column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "764615d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AdaBoost(X_train, X_test, y_train, y_test, r_target, filename, title):\n",
    "    print ('AdaBoost() ', filename)\n",
    "    model = AdaBoostClassifier(n_estimators=100)\n",
    "    model.fit(\n",
    "        X_train, \n",
    "        y_train.values.ravel(),\n",
    "    )\n",
    "    \n",
    "    # Test on training set for overfit\n",
    "    y_proba = model.predict_proba(X_train)\n",
    "    y_proba = [x[1] for x in y_proba]\n",
    "    y_pred = K.round(y_proba).numpy()\n",
    "    y_proba = np.array(y_proba)\n",
    "    Balance_Proba(y_train, y_proba, y_pred, r_target, filename + '_Train', title)\n",
    "    \n",
    "    y_proba = model.predict_proba(X_test)\n",
    "    y_proba = [x[1] for x in y_proba]\n",
    "    y_pred = K.round(y_proba).numpy()\n",
    "    y_proba = np.array(y_proba)\n",
    "    Balance_Proba(y_test, y_proba, y_pred, r_target, filename + '_Test', title)\n",
    "    print ()\n",
    "    return model    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14afd759",
   "metadata": {},
   "source": [
    "### Ensembles of Classifiers\n",
    "https://imbalanced-learn.org/stable/ensemble.html#bagging-classifier\n",
    "\n",
    "with arguments based on the documentation examples\n",
    "\n",
    "https://imbalanced-learn.org/stable/auto_examples/ensemble/plot_comparison_ensemble_classifier.html#sphx-glr-auto-examples-ensemble-plot-comparison-ensemble-classifier-py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5cffa9",
   "metadata": {},
   "source": [
    "## Bagging Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fe617891",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Bagging(X_train, X_test, y_train, y_test, r_target, filename, title):\n",
    "    print ('Bagging() ', filename)\n",
    "    model = BalancedBaggingClassifier(\n",
    "#        random_state=42\n",
    "    )\n",
    "    model.fit(\n",
    "        X_train, \n",
    "        y_train.values.ravel(),\n",
    "    )\n",
    "    \n",
    "    # Check for overfitting on Test set\n",
    "    y_proba = model.predict_proba(X_train)\n",
    "    y_proba = [x[1] for x in y_proba]\n",
    "    y_pred = K.round(y_proba)\n",
    "    y_proba = np.array(y_proba)\n",
    "    Balance_Proba(y_train, y_proba, y_pred, r_target, filename + '_Train', title)\n",
    "\n",
    "    # Test\n",
    "    y_proba = model.predict_proba(X_test)\n",
    "    y_proba = [x[1] for x in y_proba]\n",
    "    y_pred = K.round(y_proba)\n",
    "    y_proba = np.array(y_proba)\n",
    "    Balance_Proba(y_test, y_proba, y_pred, r_target, filename + '_Test', title)\n",
    "\n",
    "    print ()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1421ec7b",
   "metadata": {},
   "source": [
    "## Balanced Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ee95effe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Balanced_Random_Forest_Classifier(X_train, X_test, y_train, y_test, r_target, alpha, filename, title):\n",
    "    print ('Balanced Random Forest Classifier ', filename)\n",
    "    print ('alpha = ', alpha)\n",
    "    print ()\n",
    "    model = BalancedRandomForestClassifier(\n",
    "        bootstrap = True, ccp_alpha = 0.0, criterion = 'gini', \n",
    "        max_depth = None,\n",
    "#        max_depth = 40, \n",
    "        max_features = 'sqrt', \n",
    "        max_leaf_nodes = None,\n",
    "#        max_leaf_nodes = 10000,  \n",
    "        max_samples = None, \n",
    "        min_impurity_decrease = 0.0, \n",
    "        min_samples_leaf = 1, \n",
    "        min_samples_split = 2, \n",
    "        min_weight_fraction_leaf = 0.0, \n",
    "        n_estimators = 100, \n",
    "#        n_estimators = 1000, \n",
    "        n_jobs = None, \n",
    "        oob_score = False, \n",
    "        random_state = None, \n",
    "        replacement = False, \n",
    "        sampling_strategy = 'auto', \n",
    "        verbose = 0, \n",
    "        warm_start = False,\n",
    "        class_weight = {0:1-alpha, 1:alpha}\n",
    "    )\n",
    "    model.fit(\n",
    "        X_train, \n",
    "        y_train.values.ravel(),\n",
    "    )\n",
    "    print ()\n",
    "    print ('model.get_params()')\n",
    "    print (model.get_params())\n",
    "    print ()\n",
    "    \n",
    "    print ('[estimator.get_depth() for estimator in model.estimators_]')\n",
    "    print ([estimator.get_depth() for estimator in model.estimators_])\n",
    "    print ()\n",
    "    print ('[estimator.get_n_leaves() for estimator in model.estimators_]')\n",
    "    print ([estimator.get_n_leaves() for estimator in model.estimators_])\n",
    "    print ()\n",
    "    \n",
    "    # Test fit on training data, to test for underfit\n",
    "    y_proba = model.predict_proba(X_train)\n",
    "    y_proba = [x[1] for x in y_proba]\n",
    "    y_pred = K.round(y_proba)\n",
    "    y_proba = np.array(y_proba)\n",
    "#    Balance_Proba(y_train, y_proba, y_pred, r_target, filename + '_Train', title)\n",
    "    Chart_and_Plots(y_train, y_proba, y_pred, filename + '_Train', title)\n",
    "    \n",
    "    # Test fit on test data, to test for overfit.\n",
    "    y_proba = model.predict_proba(X_test)\n",
    "    y_proba = [x[1] for x in y_proba]\n",
    "    y_pred = K.round(y_proba)\n",
    "    y_proba = np.array(y_proba)\n",
    "#    Balance_Proba(y_test, y_proba, y_pred, r_target, filename + '_Test', title)\n",
    "    Chart_and_Plots(y_test, y_proba, y_pred, filename + '_Test', title)\n",
    "    \n",
    "    \n",
    "    print ()\n",
    "    return model    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8a4b47",
   "metadata": {},
   "source": [
    "## RUSBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "240eb43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RUSBoost_Classifier(X_train, X_test, y_train, y_test, estimator, r_target, filename, title):\n",
    "    print ('RUSBoost Classifier ', filename)\n",
    "    model = RUSBoostClassifier(\n",
    "        n_estimators=1000, \n",
    "        estimator=estimator,\n",
    "        algorithm='SAMME.R', \n",
    "#        random_state=42\n",
    "    )\n",
    "    model.fit(\n",
    "        X_train, \n",
    "        y_train.values.ravel(),\n",
    "    )\n",
    "    \n",
    "    # Test fit on training data, to test for underfit\n",
    "    y_proba = model.predict_proba(X_train)\n",
    "    y_proba = [x[1] for x in y_proba]\n",
    "    y_pred = K.round(y_proba)\n",
    "    y_proba = np.array(y_proba)\n",
    "    Balance_Proba(y_train, y_proba, y_pred, r_target, filename + '_Train', title)\n",
    "    \n",
    "    # Test fit on test data, to test for overfit.\n",
    "    y_proba = model.predict_proba(X_test)\n",
    "    y_proba = [x[1] for x in y_proba]\n",
    "    y_pred = K.round(y_proba)\n",
    "    y_proba = np.array(y_proba)\n",
    "    Balance_Proba(y_test, y_proba, y_pred, r_target, filename + '_Test', title)\n",
    "    print ()\n",
    "    return model    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2feb5091",
   "metadata": {},
   "source": [
    "## Easy Ensemble Classifier (Adaboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "db654cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Easy_Ensemble_Classifier(X_train, X_test, y_train, y_test, r_target, filename, title):\n",
    "    print ('Easy Ensemble Classifier ', filename)\n",
    "    estimator = AdaBoostClassifier(n_estimators=10)\n",
    "    model = EasyEnsembleClassifier(n_estimators=10, estimator=estimator)\n",
    "    model.fit(\n",
    "        X_train, \n",
    "        y_train.values.ravel(),\n",
    "    )\n",
    "\n",
    "    # Test fit on training data, to test for underfit\n",
    "    y_proba = model.predict_proba(X_train)\n",
    "    y_proba = [x[1] for x in y_proba]\n",
    "    y_pred = K.round(y_proba)\n",
    "    y_proba = np.array(y_proba)\n",
    "    Balance_Proba(y_train, y_proba, y_pred, r_target, filename + '_Train', title)\n",
    "    \n",
    "    # Test fit on test data, to test for overfit.\n",
    "    y_proba = model.predict_proba(X_test)\n",
    "    y_proba = [x[1] for x in y_proba]\n",
    "    y_pred = K.round(y_proba)\n",
    "    y_proba = np.array(y_proba)\n",
    "    Balance_Proba(y_test, y_proba, y_pred, r_target, filename + '_Test', title)\n",
    "    \n",
    "    print ()\n",
    "    return model    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6592a6f5",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9075eef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Logistic_Regression_Classifier(X_train, X_test, y_train, y_test, r_target, alpha, filename, title):\n",
    "    print ('Logistic Regression Classifier ', filename)\n",
    "    model = LogisticRegression(\n",
    "#        class_weight={0:(1+r_target)/(2*r_target), 1:(1+r_target)/(2*1)}\n",
    "        class_weight = {0:1-alpha, 1:alpha},\n",
    "        max_iter=1000,\n",
    "#        random_state=42,\n",
    "    )\n",
    "    model.fit(\n",
    "        X_train, \n",
    "        y_train.values.ravel(),\n",
    "    )\n",
    "\n",
    "    # Test fit on training data, to test for underfit\n",
    "    y_proba = model.predict_proba(X_train)\n",
    "    y_proba = [x[1] for x in y_proba]\n",
    "    y_pred = K.round(y_proba)\n",
    "    y_proba = np.array(y_proba)\n",
    "    Balance_Proba(y_train, y_proba, y_pred, r_target, filename + '_Train', title)\n",
    "    \n",
    "    # Test fit on test data, to test for overfit.\n",
    "    y_proba = model.predict_proba(X_test)\n",
    "    y_proba = [x[1] for x in y_proba]\n",
    "    y_pred = K.round(y_proba)\n",
    "    y_proba = np.array(y_proba)\n",
    "    Balance_Proba(y_test, y_proba, y_pred, r_target, filename + '_Test', title)\n",
    "    \n",
    "    print ()\n",
    "    return model    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44982302",
   "metadata": {},
   "source": [
    "# Evaluate Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f6c830",
   "metadata": {},
   "source": [
    "## Adjust Center of Probability Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6960f728",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Shift_y_proba(y_test, y_proba, y_pred, filename):\n",
    "    print ('Shift_y_proba()')\n",
    "    print ()\n",
    "    N_median = np.median(y_proba[np.array(y_test)==0])\n",
    "    P_median = np.median(y_proba[np.array(y_test)==1])\n",
    "    center = (N_median + P_median)/2\n",
    "    print ('N_median = %.3f, P_median = %.3f, center = %.3f' % (N_median, P_median, center))\n",
    "\n",
    "    y_proba = y_proba - center + 0.5\n",
    "    y_proba = np.where (y_proba < 0.0, 0.0, y_proba)\n",
    "    y_proba = np.where (y_proba > 1.0, 1.0, y_proba)\n",
    "    y_pred = K.round(y_proba)\n",
    "\n",
    "    N_median = np.median(y_proba[np.array(y_test)==0])\n",
    "    P_median = np.median(y_proba[np.array(y_test)==1])\n",
    "    center = (N_median + P_median)/2\n",
    "    print ('N_median = %.3f, P_median = %.3f, center = %.3f' % (N_median, P_median, center))\n",
    "    \n",
    "    print ()\n",
    "    \n",
    "    return y_test, y_proba, y_pred, filename\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "de890369",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Linear_Transform_y_proba(y_test, y_proba, y_pred, filename):\n",
    "    print ('Linear_Transform_y_proba()')\n",
    "    print ()\n",
    "    \n",
    "    # I considered two methods.  \n",
    "    # One was to take the medians of the negative and positive classes and transform them to 0.25 and 0.75.\n",
    "    # That didn't always work the way I wanted.  \n",
    "    # Then I tried taking the 0.05 quantile to 0.05 and the 0.95 quantile to 0.95.\n",
    "    \n",
    "#    N_median = np.median(y_proba[np.array(y_test)==0])\n",
    "#    P_median = np.median(y_proba[np.array(y_test)==1])\n",
    "#    center = (N_median + P_median)/2\n",
    "#    print ('N_median = %.3f, P_median = %.3f, center = %.3f' % (N_median, P_median, center))\n",
    "#    y_proba = 0.25/(center - N_median) * (y_proba - center) + 0.5\n",
    "\n",
    "    \n",
    "    a = np.quantile(y_proba[np.array(y_test)==0],0.05)\n",
    "    b = np.quantile(y_proba[np.array(y_test)==1],0.95)\n",
    "    print ('a = %.3f, b = %.3f' % (a, b))\n",
    "    y_proba = 0.9/(b-a) * (y_proba - a) + 0.05\n",
    "    \n",
    "    y_proba = np.where (y_proba < 0.0, 0.0, y_proba)\n",
    "    y_proba = np.where (y_proba > 1.0, 1.0, y_proba)\n",
    "    y_pred = K.round(y_proba)\n",
    "\n",
    "    print ()\n",
    "    \n",
    "    return y_test, y_proba, y_pred, filename\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "36fdedb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Linear_Transform_y_proba_p_target(y_test, y_proba, y_pred, p_target, filename):\n",
    "    print ('Linear_Transform_y_proba_p_target')\n",
    "    # Transform 0 to 0 and p_target to 0.5\n",
    "    # y = ax + b, where x is y_proba and y is y_proba_New\n",
    "    # b = 0\n",
    "    # a = 0.5 / p_target = 1/(2*p_target)\n",
    "    a = 1/(2 * p_target)\n",
    "    y_proba_New = a * y_proba\n",
    "    \n",
    "    \n",
    "    filename = filename + '_p_target_' + str(int(p_target*100))\n",
    "    \n",
    "    Plot_Prediction_Wide(y_test, y_proba, filename, '')\n",
    "    Plot_Prediction_Wide(y_test, y_proba_New, filename, '')\n",
    "    \n",
    "    ROC(y_test, y_proba_New, [], filename)    \n",
    "    Evaluate_Model(y_test, y_proba_New, y_pred, p_target, filename)    \n",
    "\n",
    "    \n",
    "    return y_test, y_proba, y_pred, p_target, filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4a5d35d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Shift_y_proba_to_FP_equals_r_TP(y_test, y_proba, r_target, filename):\n",
    "    print ('Shift_y_proba_to_FP_equals_r_TP()')\n",
    "    print ('y_test is a ', type(y_test))\n",
    "    print ('y_proba is a ', type(y_proba))\n",
    "    print ('r_target = ', r_target)\n",
    "    print ()\n",
    "    \n",
    "    \n",
    "    A = pd.DataFrame(y_proba, columns=['HOSPITAL'])\n",
    "    B = pd.DataFrame(y_test, columns=['HOSPITAL'])\n",
    "    B = B.reset_index(drop=True)\n",
    "    C = A[B['HOSPITAL']==0]\n",
    "    D = A[B['HOSPITAL']==1]\n",
    "    n = 100\n",
    "    m = np.quantile(C, 0.005)\n",
    "    M = np.quantile(D,0.995)\n",
    "    print ('Quantiles ', m, M)\n",
    "    bins = [(M-m) * (x/n) + m for x in range (0, n+1)]\n",
    "    E = pd.cut(C['HOSPITAL'], bins=bins, include_lowest=False)\n",
    "    F = pd.cut(D['HOSPITAL'], bins=bins, include_lowest=False)\n",
    "    G = E.value_counts(sort=False)\n",
    "    H = F.value_counts(sort=False)\n",
    "\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame()\n",
    "    df['TP'] = G\n",
    "    df['FP'] = H\n",
    "    roll = 10\n",
    "    df['TP_RA'] = G.rolling(roll, center=True, min_periods=1).mean()\n",
    "    df['FP_RA'] = H.rolling(roll, center=True, min_periods=1).mean()\n",
    "    df['TP/FP'] = df['TP_RA']/df['FP_RA']\n",
    "    df['TP/FP_RA'] = df['TP/FP'].rolling(roll, center=True, min_periods=1).mean()\n",
    "    df['Truncate'] = np.where(df['TP/FP_RA']>2,2,df['TP/FP_RA'])\n",
    "    df['bins'] = bins[:-1]\n",
    "    df.fillna(0, inplace=True)\n",
    "    \n",
    "    #    display(df)\n",
    "    df_closest = df.iloc[(df['TP/FP_RA'] - r_target).abs().argsort()[:1]]\n",
    "    center = df_closest['bins'].to_numpy()\n",
    "    center = center[0]\n",
    "    center_index = df.index[df['bins'] == center].tolist()\n",
    "#    print (df_closest)\n",
    "    print ('center = ', center)\n",
    "#    print (center_index)\n",
    "    print ()\n",
    "    \n",
    "    print ('Plot TP/FP')\n",
    "    x = df['bins'].to_numpy()\n",
    "    y = df['TP/FP_RA'].to_numpy()\n",
    "    fig = plt.figure(figsize=(2.4,1.8)) # Create matplotlib figure\n",
    "    ax = fig.add_subplot(111) # Create matplotlib axes\n",
    "    \n",
    "    plt.plot(x,y, label='TP/FP', color='black')\n",
    "    plt.axhline(y=2.0, color='black', linestyle='--', label='2.0')  \n",
    "    plt.plot([center], [2.0], marker=\"o\", markersize=6, markerfacecolor='black', markeredgecolor='black')\n",
    "    plt.xticks(\n",
    "        ticks = [m, center, M], \n",
    "        labels = [round(m,3), round(center, 3), round(M,3)],\n",
    "        rotation=0\n",
    "    )\n",
    "    ax.legend()\n",
    "    plt.title('$\\Delta$TP/$\\Delta$FP')\n",
    "    plt.xlabel('$p$')\n",
    "    plt.ylabel('$\\Delta$TP/$\\Delta$FP')\n",
    "    plt.savefig('./Images/' + filename + '_TP_FP.png', bbox_inches=\"tight\")\n",
    "    plt.savefig('./Images/' + filename + '_TP_FP.pgf', bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    df['FP'] = G\n",
    "    df['TP'] = H\n",
    "    roll = 10\n",
    "    df['FP_RA'] = G.rolling(roll, center=True, min_periods=1).mean()\n",
    "    df['TP_RA'] = H.rolling(roll, center=True, min_periods=1).mean()\n",
    "    df['FP/TP'] = df['FP_RA']/df['TP_RA']\n",
    "    df['FP/TP_RA'] = df['FP/TP'].rolling(roll, center=True, min_periods=1).mean()\n",
    "    df['Truncate'] = np.where(df['FP/TP_RA']>2,2,df['FP/TP_RA'])\n",
    "    df['bins'] = bins[:-1]\n",
    "    df.fillna(0, inplace=True)\n",
    "    \n",
    "    #    display(df)\n",
    "    df_closest = df.iloc[(df['FP/TP_RA'] - r_target).abs().argsort()[:1]]\n",
    "    center = df_closest['bins'].to_numpy()\n",
    "    center = center[0]\n",
    "    center_index = df.index[df['bins'] == center].tolist()\n",
    "#    print (df_closest)\n",
    "    print ('center = ', center)\n",
    "#    print (center_index)\n",
    "    print ()\n",
    "    \n",
    "    print ('Plot FP/TP')\n",
    "    x = df['bins'].to_numpy()\n",
    "    y = df['FP/TP_RA'].to_numpy()\n",
    "    fig = plt.figure(figsize=(2.0,1.5)) # Create matplotlib figure\n",
    "    ax = fig.add_subplot(111) # Create matplotlib axes\n",
    "    \n",
    "    plt.plot(x,y, label='$\\Delta FP/\\Delta TP$', color='black')\n",
    "    plt.axhline(y = r_target, color='black', linestyle='--')  \n",
    "    \n",
    "    # Update r_target here\n",
    "    plt.plot([center], [r_target], label='(%.3f,%d)' % (center, r_target), marker=\"o\", markersize=6, markerfacecolor='black', markeredgecolor='black')\n",
    "    plt.xticks(\n",
    "        ticks = [m, M], \n",
    "#        labels = [round(m,3), round(center, 3), round(M,3)],\n",
    "        labels = [round(m,3), round(M,3)],\n",
    "        rotation=0\n",
    "    )\n",
    "#    ax.annotate('data = (%.3f, %.1f)'%(center, 2.0),(center, 2.0), textcoords='data')\n",
    "#    plt.text(center,2.0,'(%.3f,%.1f)' % (center, 2.0),horizontalalignment='left', verticalalignment='bottom')\n",
    "#    plt.title('$\\Delta FP/\\Delta TP$')\n",
    "    plt.xlabel('$p$')\n",
    "    plt.ylabel('$\\Delta$FP/$\\Delta$TP')\n",
    "    ax.legend()\n",
    "    plt.savefig('./Images/' + filename + '_FP_TP.png', bbox_inches=\"tight\")\n",
    "    plt.savefig('./Images/' + filename + '_FP_TP.pgf', bbox_inches=\"tight\")\n",
    "    print ('./Images/' + filename + '_FP_TP.png')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    # Re-center the distribution\n",
    "    y_proba = y_proba - center + 0.5\n",
    "\n",
    "    # Decide which direction to dilate the distribution\n",
    "    M = np.quantile(y_proba,0.995)\n",
    "    m = np.quantile(y_proba,0.005)\n",
    "    right = M-0.5\n",
    "    left = 0.5-m\n",
    "    # If the tail to the right is longer, map M to 1 and 0.5 to itself.\n",
    "    if left < right:\n",
    "        y_proba = (1/(2*M-1))*(y_proba - 0.5) + 0.5\n",
    "    # If the tail to the left is longer, map m to 0 and 0.5 to itself.\n",
    "    if left > right:\n",
    "        y_proba = (1/(1-2*m))*(y_proba - 0.5) + 0.5\n",
    "    print ('y_proba unique = ', np.unique(y_proba))\n",
    "    y_proba = np.clip(y_proba,0,1)\n",
    "    print ('y_proba unique = ', np.unique(y_proba))\n",
    "    print ('M, m, left, right = ', M, m, left, right)\n",
    "    y_pred = K.round(y_proba).numpy()\n",
    "    \n",
    "    return y_test, y_proba, y_pred, center, filename\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7d27e7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Balance_Proba(y_test, y_proba, y_pred, r_target, filename, title):\n",
    "    print ('Balance_Proba')\n",
    "    print (filename)\n",
    "\n",
    "    Analyze_Prediction(y_test, y_proba, filename, title)\n",
    "    y_test, y_proba_New, y_pred_New, center, filename = Shift_y_proba_to_FP_equals_r_TP(y_test, y_proba, r_target, filename)\n",
    "\n",
    "    N = y_proba[np.array(y_test)==0]\n",
    "    P = y_proba[np.array(y_test)==1]\n",
    "    N_median = np.median(N)\n",
    "    P_median = np.median(P)\n",
    "\n",
    "    Plot_Prediction(y_test, y_proba, filename, title)\n",
    "    Plot_Prediction_Wide(y_test, y_proba, filename, title)\n",
    "#    ROC(y_test, y_proba, [center, N_median, P_median], filename)    \n",
    "    ROC(y_test, y_proba, [], filename)    \n",
    "    Evaluate_Model(y_test, y_proba, y_pred, center, filename)    \n",
    "    print ()\n",
    "\n",
    "    filename = filename + '_Linear_Transform'\n",
    "    title = title + ' Trans'\n",
    "\n",
    "    N = y_proba_New[np.array(y_test)==0]\n",
    "    P = y_proba_New[np.array(y_test)==1]\n",
    "    N_median = np.median(N)\n",
    "    P_median = np.median(P)\n",
    "    \n",
    "    Plot_Prediction(y_test, y_proba_New, filename, title)\n",
    "\n",
    "    Plot_Prediction_Wide(y_test, y_proba_New, filename, title)\n",
    "\n",
    "    Plot_Prediction_Zoom(y_test, y_proba_New, filename, title, 0.4, 0.6)\n",
    "#    ROC(y_test, y_proba, [center, N_median, P_median], filename)    \n",
    "    ROC(y_test, y_proba_New, [], filename)    \n",
    "    Evaluate_Model(y_test, y_proba_New, y_pred_New, center, filename)    \n",
    "    print ()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5db198",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "89d83bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Chart_and_Plots(y_test, y_proba, y_pred, filename, title):\n",
    "    Analyze_Prediction(y_test, y_proba, filename, title)\n",
    "    Plot_Prediction(y_test, y_proba, filename, title)\n",
    "    Plot_Prediction_Wide(y_test, y_proba, filename, title)\n",
    "    ROC(y_test, y_proba, [], filename)    \n",
    "    print ()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5085583e",
   "metadata": {},
   "source": [
    "## Evaluate_Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "97848247",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Evaluate_Model(y_test, y_proba, y_pred, center, filename):\n",
    "    print ('Evaluate_Model()')\n",
    "    y_test = np.array(y_test)\n",
    "    y_pred = [round(x) for x in y_proba]\n",
    "    y_pred = np.array(y_pred)\n",
    "    print ('np.unique(y_proba) = ', np.unique(y_proba))\n",
    "    print ('np.unique(y_pred) = ', np.unique(y_pred))\n",
    "    CM = confusion_matrix(y_test, y_pred)\n",
    "    print(CM)\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n",
    "    auc_value = auc(fpr, tpr)\n",
    "    \n",
    "    CSV = [[filename, CM[0][0], CM[0][1], CM[1][0], CM[1][1], center, auc_value]]\n",
    "    np.savetxt('./Confusion_Matrices/' + filename + '.csv', \n",
    "        CSV,\n",
    "        delimiter =\", \", \n",
    "        fmt ='% s'\n",
    "              )\n",
    "    print ()\n",
    "    CM = confusion_matrix(y_test, y_pred, normalize='all')\n",
    "    print(CM)\n",
    "    print ()\n",
    "\n",
    "    y_pred = y_pred.ravel()\n",
    "    y_test = tf.convert_to_tensor(y_test)\n",
    "    y_pred = tf.convert_to_tensor(y_pred)\n",
    "\n",
    "    print ('%.3f & Precision \\cr ' %  Precision_Metric(y_test, y_pred).numpy())\n",
    "    print ('%.3f & Recall \\cr ' %  Recall_Metric(y_test, y_pred).numpy())\n",
    "    print ('%.3f & F1 \\cr ' %  F1_Metric(y_test, y_pred).numpy())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf928217",
   "metadata": {},
   "source": [
    "## Plot Prediction\n",
    "\n",
    "How to insert a .pgf plot into a \\LaTeX document:\n",
    "\n",
    "\\begin{figure}\n",
    "    \\begin{center}\n",
    "        \\input{Plot.pgf}\n",
    "    \\end{center}\n",
    "    \\caption{A PGF histogram from \\texttt{matplotlib}.}\n",
    "\\end{figure}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f3496ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Plot_Prediction(y_test, y_proba, filename, title):\n",
    "    print ('Plot_Prediction()')\n",
    "    print (filename)\n",
    "    \n",
    "#    print (y_test)\n",
    "#    print (y_proba)\n",
    "#    return 0\n",
    "#    y_test = y_test.numpy()\n",
    "    A = pd.DataFrame(y_proba, columns=['HOSPITAL'])\n",
    "    B = pd.DataFrame(y_test, columns=['HOSPITAL'])\n",
    "    B = B.reset_index(drop=True)\n",
    "    C = A[B['HOSPITAL']==0]\n",
    "    D = A[B['HOSPITAL']==1]\n",
    "#    bins = [x*0.05 for x in range (21)]\n",
    "#    bins = [x*0.10 for x in range (11)]\n",
    "    n = 10\n",
    "    bins= [x/n for x in range (0, n+1)]\n",
    "    print (bins)\n",
    "    E = pd.cut(C['HOSPITAL'], bins=bins, include_lowest=False)\n",
    "    F = pd.cut(D['HOSPITAL'], bins=bins, include_lowest=False)\n",
    "    \n",
    "    G = E.value_counts(sort=False)\n",
    "    H = F.value_counts(sort=False)\n",
    "    \n",
    "    G = G/len(y_proba)*100\n",
    "    H = H/len(y_proba)*100\n",
    "\n",
    "    fig = plt.figure(figsize=(2.0,1.5)) # Create matplotlib figure\n",
    "    ax = fig.add_subplot(111) # Create matplotlib axes\n",
    "    \n",
    "    G.plot(kind='bar', fill=False, ax=ax, width=0.4, position=1)\n",
    "    H.plot(kind='bar', color='black', ax=ax, width=0.4, position=0)\n",
    "    plt.xticks(\n",
    "        ticks = [0, 2.5, 5, 7.5, 10], \n",
    "        labels = ['0.0', '0.25', '0.5', '0.75', '1.0'],\n",
    "        rotation=0\n",
    "    )\n",
    "    ax.legend(['Neg', 'Pos'])\n",
    "#    plt.title(title)\n",
    "    plt.xlabel('$p$')\n",
    "    plt.ylabel('Percent of Data Set')\n",
    "    plt.savefig('./Images/' + filename + '_Pred.png', bbox_inches=\"tight\")\n",
    "    plt.savefig('./Images/' + filename + '_Pred.pgf', bbox_inches=\"tight\")\n",
    "    print ('./Images/' + filename + '_Pred.png')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    print ()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdf5823",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9b634349",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Plot_Prediction_Zoom(y_test, y_proba, filename, title, left, right):\n",
    "    print ('Plot_Prediction()')\n",
    "    print (filename)\n",
    "    \n",
    "#    print (y_test)\n",
    "#    print (y_proba)\n",
    "#    return 0\n",
    "#    y_test = y_test.numpy()\n",
    "    A = pd.DataFrame(y_proba, columns=['HOSPITAL'])\n",
    "    B = pd.DataFrame(y_test, columns=['HOSPITAL'])\n",
    "    B = B.reset_index(drop=True)\n",
    "    B = B[A['HOSPITAL'] > left]\n",
    "    B = B[A['HOSPITAL'] < right]\n",
    "    A = A[A['HOSPITAL'] > left]\n",
    "    A = A[A['HOSPITAL'] < right]\n",
    "    C = A[B['HOSPITAL']==0]\n",
    "    D = A[B['HOSPITAL']==1]\n",
    "#    bins = [x*0.05 for x in range (21)]\n",
    "#    bins = [x*0.10 for x in range (11)]\n",
    "    n = 10\n",
    "    bins= [left + (right-left)*x/n for x in range (0, n+1)]\n",
    "    print (bins)\n",
    "    E = pd.cut(C['HOSPITAL'], bins=bins, include_lowest=False)\n",
    "    F = pd.cut(D['HOSPITAL'], bins=bins, include_lowest=False)\n",
    "    \n",
    "    G = E.value_counts(sort=False)\n",
    "    H = F.value_counts(sort=False)\n",
    "\n",
    "    G = G/len(y_proba)*100\n",
    "    H = H/len(y_proba)*100\n",
    "\n",
    "    fig = plt.figure(figsize=(2.0,1.5)) # Create matplotlib figure\n",
    "    ax = fig.add_subplot(111) # Create matplotlib axes\n",
    "    \n",
    "    G.plot(kind='bar', fill=False, ax=ax, width=0.4, position=1)\n",
    "    H.plot(kind='bar', color='black', ax=ax, width=0.4, position=0)\n",
    "\n",
    "    ticks = [0, 2.5, 5, 7.5, 10]\n",
    "    labels = [str(round(left + (right-left) * t/10,2)) for t in ticks]\n",
    "    plt.xticks(\n",
    "        ticks = ticks, \n",
    "        labels = labels,\n",
    "        rotation=0\n",
    "    )\n",
    "    ax.legend(['Neg', 'Pos'])\n",
    "#    plt.title(title)\n",
    "    plt.xlabel('$p$')\n",
    "    plt.ylabel('Percent of Data Set')\n",
    "    plt.savefig('./Images/' + filename + '_Pred_Zoom.png', bbox_inches=\"tight\")\n",
    "    plt.savefig('./Images/' + filename + '_Pred_Zoom.pgf', bbox_inches=\"tight\")\n",
    "    print ('./Images/' + filename + '_Pred_Zoom.png')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    print ()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e9eda862",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Plot_Prediction_Wide(y_test, y_proba, filename, title):\n",
    "    print ('Plot_Prediction()')\n",
    "    print (filename)\n",
    "    \n",
    "#    print (y_test)\n",
    "#    print (y_proba)\n",
    "#    return 0\n",
    "#    y_test = y_test.numpy()\n",
    "    A = pd.DataFrame(y_proba, columns=['HOSPITAL'])\n",
    "    B = pd.DataFrame(y_test, columns=['HOSPITAL'])\n",
    "    B = B.reset_index(drop=True)\n",
    "    C = A[B['HOSPITAL']==0]\n",
    "    D = A[B['HOSPITAL']==1]\n",
    "#    bins = [x*0.05 for x in range (21)]\n",
    "#    bins = [x*0.10 for x in range (11)]\n",
    "    n = 25\n",
    "    bins= [x/n for x in range (0, n+1)]\n",
    "    print (bins)\n",
    "    E = pd.cut(C['HOSPITAL'], bins=bins, include_lowest=False)\n",
    "    F = pd.cut(D['HOSPITAL'], bins=bins, include_lowest=False)\n",
    "    \n",
    "    G = E.value_counts(sort=False)\n",
    "    H = F.value_counts(sort=False)\n",
    "\n",
    "    G = G/len(y_proba)*100\n",
    "    H = H/len(y_proba)*100\n",
    "\n",
    "    fig = plt.figure(figsize=(5.0,1.5)) # Create matplotlib figure\n",
    "    ax = fig.add_subplot(111) # Create matplotlib axes\n",
    "    \n",
    "    G.plot(kind='bar', fill=False, ax=ax, width=0.4, position=1)\n",
    "    H.plot(kind='bar', color='black', ax=ax, width=0.4, position=0)\n",
    "    plt.xticks(\n",
    "        ticks = [0, 2.5, 5, 7.5, 10, 12.5, 15, 17.5, 20, 22.5, 25], \n",
    "        labels = ['0.0', '0.1', '0.2', '0.3', '0.4', '0.5', '0.6', '0.7', '0.8', '0.9', '1.0'],\n",
    "        rotation=0\n",
    "    )\n",
    "    ax.legend(['Neg', 'Pos'])\n",
    "#    plt.title(title)\n",
    "    plt.xlabel('$p$')\n",
    "    plt.ylabel('Percent of Data Set')\n",
    "    plt.savefig('./Images/' + filename + '_Pred_Wide.png', bbox_inches=\"tight\")\n",
    "    plt.savefig('./Images/' + filename + '_Pred_Wide.pgf', bbox_inches=\"tight\")\n",
    "    print ('./Images/' + filename + '_Pred_Wide.png')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    print ()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "de839f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Analyze_Prediction(y_test, y_proba, filename, title):\n",
    "    print ('Analyze_Prediction()')\n",
    "    print (filename)\n",
    "    \n",
    "#    print (y_test)\n",
    "#    print (y_proba)\n",
    "#    return 0\n",
    "#    y_test = y_test.numpy()\n",
    "    A = pd.DataFrame(y_proba, columns=['HOSPITAL'])\n",
    "    B = pd.DataFrame(y_test, columns=['HOSPITAL'])\n",
    "    B = B.reset_index(drop=True)\n",
    "    C = A[B['HOSPITAL']==0]\n",
    "    D = A[B['HOSPITAL']==1]\n",
    "    print ('print (len(A), len(C), len(D), len(C) + len(D))')\n",
    "    print (len(A), len(C), len(D), len(C) + len(D))\n",
    "\n",
    "    N = len(C)\n",
    "    P = len(D)\n",
    "    \n",
    "    ##### 20 bins\n",
    "    n = 20\n",
    "    bins= [x/n for x in range (-1, n+1)]\n",
    "    print (bins)\n",
    "    E = pd.cut(C['HOSPITAL'], bins=bins, include_lowest=True)\n",
    "    F = pd.cut(D['HOSPITAL'], bins=bins, include_lowest=True)\n",
    "    \n",
    "    G = E.value_counts(sort=False)\n",
    "    H = F.value_counts(sort=False)\n",
    "\n",
    "    Analyze = pd.DataFrame()\n",
    "    Analyze['Neg'] = G\n",
    "    Analyze['Pos'] = H\n",
    "    Analyze['p'] = bins[1:]\n",
    "    Analyze['Neg/Pos'] = Analyze['Neg']/Analyze['Pos']\n",
    "    Analyze['TN'] = Analyze['Neg'].cumsum()\n",
    "    Analyze['FP'] = N - Analyze['TN']\n",
    "    Analyze['FN'] = Analyze['Pos'].cumsum()\n",
    "    Analyze['TP'] = P - Analyze['FN']\n",
    "    Analyze['FP/TP'] = Analyze['FP']/Analyze['TP']\n",
    "#    Analyze['FP+TP'] = Analyze['FP'] + Analyze['TP']\n",
    "    Analyze['Prec.'] = Analyze['TP']/(Analyze['FP'] + Analyze['TP'])\n",
    "    Analyze['Rec.'] =  Analyze['TP']/(Analyze['FN'] + Analyze['TP'])\n",
    "    Analyze['$\\hat{p}$'] = (Analyze['TP'] + Analyze['FP'])/len(y_proba)\n",
    "\n",
    "    Analyze['Neg']=Analyze['Neg'].apply('{:,}'.format)\n",
    "    Analyze['Pos']=Analyze['Pos'].apply('{:,}'.format)\n",
    "    Analyze['TN']=Analyze['TN'].apply('{:,}'.format)\n",
    "    Analyze['FP']=Analyze['FP'].apply('{:,}'.format)\n",
    "    Analyze['FN']=Analyze['FN'].apply('{:,}'.format)\n",
    "    Analyze['TP']=Analyze['TP'].apply('{:,}'.format)\n",
    "#    Analyze['FP+TP']=Analyze['FP+TP'].apply('{:,}'.format)\n",
    "    \n",
    "    Analyze['Neg/Pos']=Analyze['Neg/Pos'].apply('{:.2f}'.format)\n",
    "    Analyze['FP/TP']=Analyze['FP/TP'].apply('{:.2f}'.format)\n",
    "    Analyze['Prec.']=Analyze['Prec.'].apply('{:.2f}'.format)\n",
    "    Analyze['Rec.']=Analyze['Rec.'].apply('{:.2f}'.format)\n",
    "    Analyze['$\\hat{p}$']=Analyze['$\\hat{p}$'].apply('{:.2f}'.format)\n",
    "        \n",
    "#    Analyze.index.name = 'p'\n",
    "    Analyze.set_index('p', inplace=True)\n",
    "    print ('./Analyze_Proba/' + filename + '_20.tex')\n",
    "    print (len(y_proba))\n",
    "    display(Analyze)\n",
    "    Analyze.to_csv('./Analyze_Proba/' + filename + '_20.csv', index=True)\n",
    "    Analyze.to_latex(\n",
    "        './Analyze_Proba/' + filename + '_20.tex', \n",
    "        index=True, \n",
    "        float_format=\"{:.2f}\".format, \n",
    "        column_format='rrrrrrrrrrrrrr',\n",
    "        escape=False\n",
    "    )\n",
    "\n",
    "    ##### 100 bins\n",
    "    n = 100\n",
    "    bins= [x/n for x in range (-1, n+1)]\n",
    "    print (bins)\n",
    "    E = pd.cut(C['HOSPITAL'], bins=bins, include_lowest=True)\n",
    "    F = pd.cut(D['HOSPITAL'], bins=bins, include_lowest=True)\n",
    "    \n",
    "    G = E.value_counts(sort=False)\n",
    "    H = F.value_counts(sort=False)\n",
    "\n",
    "    Analyze = pd.DataFrame()\n",
    "    Analyze['Neg'] = G\n",
    "    Analyze['Pos'] = H\n",
    "    Analyze['p'] = bins[1:]\n",
    "    Analyze['Neg/Pos'] = Analyze['Neg']/Analyze['Pos']\n",
    "    Analyze['TN'] = Analyze['Neg'].cumsum()\n",
    "    Analyze['FP'] = N - Analyze['TN']\n",
    "    Analyze['FN'] = Analyze['Pos'].cumsum()\n",
    "    Analyze['TP'] = P - Analyze['FN']\n",
    "    Analyze['FP/TP'] = Analyze['FP']/Analyze['TP']\n",
    "#    Analyze['FP+TP'] = Analyze['FP'] + Analyze['TP']\n",
    "    Analyze['Prec.'] = Analyze['TP']/(Analyze['FP'] + Analyze['TP'])\n",
    "    Analyze['Rec.'] =  Analyze['TP']/(Analyze['FN'] + Analyze['TP'])\n",
    "    Analyze['$\\hat{p}$'] = (Analyze['TP'] + Analyze['FP'])/len(y_proba)\n",
    "\n",
    "    Analyze['Neg']=Analyze['Neg'].apply('{:,}'.format)\n",
    "    Analyze['Pos']=Analyze['Pos'].apply('{:,}'.format)\n",
    "    Analyze['TN']=Analyze['TN'].apply('{:,}'.format)\n",
    "    Analyze['FP']=Analyze['FP'].apply('{:,}'.format)\n",
    "    Analyze['FN']=Analyze['FN'].apply('{:,}'.format)\n",
    "    Analyze['TP']=Analyze['TP'].apply('{:,}'.format)\n",
    "#    Analyze['FP+TP']=Analyze['FP+TP'].apply('{:,}'.format)\n",
    "    \n",
    "    Analyze['Neg/Pos']=Analyze['Neg/Pos'].apply('{:.2f}'.format)\n",
    "    Analyze['FP/TP']=Analyze['FP/TP'].apply('{:.2f}'.format)\n",
    "    Analyze['Prec.']=Analyze['Prec.'].apply('{:.2f}'.format)\n",
    "    Analyze['Rec.']=Analyze['Rec.'].apply('{:.2f}'.format)\n",
    "    Analyze['$\\hat{p}$']=Analyze['$\\hat{p}$'].apply('{:.2f}'.format)\n",
    "        \n",
    "#    Analyze.index.name = 'p'\n",
    "    Analyze.set_index('p', inplace=True)\n",
    "#    print ('./Analyze_Proba/' + filename + '_100.tex')\n",
    "#    print (len(y_proba))\n",
    "#    display(Analyze)\n",
    "    Analyze.to_csv('./Analyze_Proba/' + filename + '_100.csv', index=True)\n",
    "    Analyze.to_latex(\n",
    "        './Analyze_Proba/' + filename + '_100.tex', \n",
    "        index=True, \n",
    "        float_format=\"{:.2f}\".format, \n",
    "        column_format='rrrrrrrrrrrrrr',\n",
    "        escape=False\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4e092785",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def Test_Plot_Prediction_Zoom():\n",
    "    print ('Idealized_Results()')\n",
    "    # Set randomness\n",
    "    np.random.seed(42) # NumPy\n",
    "    random.seed(42) # Python\n",
    "    tf.random.set_seed(42) # Tensorflow    \n",
    "\n",
    "    shape, scale = 3.7, 0.1 # mean=4, std=2*sqrt(2)\n",
    "    a = np.random.gamma(shape, scale, 150771)\n",
    "    a = np.where(a>1.0, random.random(), a)\n",
    "    \n",
    "    shape, scale = 3.8, 0.1 # mean=4, std=2*sqrt(2)\n",
    "    b = np.random.gamma(shape, scale, 26621)    \n",
    "    b = np.where(b>1.0, random.random(), b)\n",
    "    b = 1-b\n",
    "    \n",
    "    y_proba = np.concatenate((a,b),axis=0)\n",
    "    y_pred = K.round(y_proba)\n",
    "    y_test = [0]*len(a) + [1]*len(b)  \n",
    "    \n",
    "    display(y_proba[:20])\n",
    "    display(y_pred[:20])\n",
    "    \n",
    "    Plot_Prediction(y_test, y_proba, 'Test', 'Test')    \n",
    "    Plot_Prediction_Wide(y_test, y_proba, 'Test', 'Test')    \n",
    "    Plot_Prediction_Zoom(y_test, y_proba, 'Test', 'Test', 0.45, 0.55)\n",
    "    Analyze_Prediction(y_test, y_proba, 'Test', 'Test')    \n",
    "    \n",
    "#Test_Plot_Prediction_Zoom()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a04113",
   "metadata": {},
   "source": [
    "## ROC Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7e088e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ROC(y_test, y_proba, p_values, filename):\n",
    "    print ('ROC()')\n",
    "    print (filename)\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n",
    "    \n",
    "    N_median = np.median(y_proba[np.array(y_test)==0])\n",
    "    P_median = np.median(y_proba[np.array(y_test)==1])\n",
    "#    print ('N_median, P_median = ', N_median, P_median)\n",
    "\n",
    "    m = np.quantile(y_proba,0.50)\n",
    "    p = np.quantile(y_proba,0.25)\n",
    "    q = np.quantile(y_proba,0.75)\n",
    "    \n",
    "    Y = []\n",
    "    print ('p_values = ', p_values)\n",
    "    for X in p_values:\n",
    "        difference_array = np.absolute(thresholds-X)\n",
    "        index = difference_array.argmin()\n",
    "        F = fpr[index]\n",
    "        T = tpr[index]\n",
    "        Y.append([X,str(round(X,3)),F,T])\n",
    "    \n",
    "    auc_value = auc(fpr, tpr)\n",
    "    auc_value = round(auc_value,3)\n",
    "    fig = plt.figure(figsize=(2.0,1.5)) # Create matplotlib figure\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.plot(fpr, tpr, color='black', label='AUC={:.3f}'.format(auc_value))\n",
    "    \n",
    "    for y in Y:\n",
    "#        plt.plot([y[2]], [y[3]], marker=\"o\", markersize=20, markeredgecolor=\"white\", markerfacecolor=\"white\")\n",
    "#        plt.annotate(\n",
    "#            y[1], # this is the text\n",
    "#            (y[2], y[3]), # these are the coordinates to position the label\n",
    "#            ha='center' # horizontal alignment can be left, right or center\n",
    "#        )\n",
    "        plt.text(\n",
    "            y[2], y[3], # these are the coordinates to position the label\n",
    "            y[1], # this is the text\n",
    "            backgroundcolor='white', # horizontal alignment can be left, right or center\n",
    "            bbox=dict(facecolor='white', edgecolor='none', boxstyle='square,pad=0.3')\n",
    "        )\n",
    "    plt.xlabel('False positive rate')\n",
    "    plt.ylabel('True positive rate')\n",
    "#    plt.title('ROC with AUC {:.3f}'.format(auc_value))\n",
    "    plt.legend(loc='best')\n",
    "    plt.savefig('./Images/' + filename + '_ROC.png', bbox_inches=\"tight\")\n",
    "    plt.savefig('./Images/' + filename + '_ROC.pgf', bbox_inches=\"tight\")\n",
    "    print ('./Images/' + filename + '_ROC.png')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    print ()\n",
    "    return 0\n",
    "\n",
    "def Test_ROC():\n",
    "    y_test = [0,0,0,0,0,1]*10000\n",
    "#    y_proba = [abs(0.45 - y)+round(0.45*random.random(),2) for y in y_test]\n",
    "    y_proba = [abs(0.45 - y)+round(0.45*random.normalvariate(mu=0.2, sigma=0.2),3) for y in y_test]\n",
    "#    random.normalvariate(mu=0.0, sigma=1.0)\n",
    "    y_test = np.array(y_test)\n",
    "    y_proba = np.array(y_proba)\n",
    "    print (y_test)\n",
    "    print (y_proba)\n",
    "    ROC(y_test, y_proba, [0.5], \"tmp\")\n",
    "    \n",
    "#Test_ROC()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdb935a",
   "metadata": {},
   "source": [
    "## Build Idealized Results Plots\n",
    "- The Plot_Prediciton and ROC_Curves functions take two lists (or np arrays) and a filename for saving the plots:\n",
    "    - ROC(y_test, y_proba, filename):\n",
    "    - Plot_Prediction(y_test, y_proba, filename):\n",
    "    - y_test is the {0,1} binary and \n",
    "    - y_proba is the (0,1) continuous\n",
    "- The Evaluate_Model(y_test, y_proba, y_pred, filename) takes three lists (or np arrays)\n",
    "    - y_test is the {0,1} binary ground truth,\n",
    "    - y_proba is the (0,1) continuous prediction, and\n",
    "    - y_pred is the discrete {0,1} binary version of y_proba\n",
    "- We want a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6e66bb65",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Move_Threshold(y_proba, y_test):\n",
    "    print ('Move_Threshold()')\n",
    "    n = 10\n",
    "    T = [x/n for x in range (n+1)]\n",
    "    \n",
    "    print (type(y_proba))\n",
    "    print (type(y_test))\n",
    "    y_test = np.array(y_test)\n",
    "    print (type(y_test))\n",
    "    N = y_proba[y_test==0]\n",
    "    P = y_proba[y_test==1]\n",
    "    print (len(N), len(P))\n",
    "\n",
    "    A = [['t', 'TN', 'FP', 'FN', 'TP', 'TPR', 'FPR']]\n",
    "    for t in T:\n",
    "        TN = len(N[N<t])\n",
    "        FP = len(N[N>t])\n",
    "        FN = len(P[P<t])\n",
    "        TP = len(P[P>t])\n",
    "        TPR = TP/len(P)\n",
    "        FPR = FP/len(N)\n",
    "        A.append([t, TN, FP, FN, TP, TPR, FPR])\n",
    "    display(pd.DataFrame(A))\n",
    "    \n",
    "    print ()\n",
    "\n",
    "\n",
    "def Idealized_Results():\n",
    "    print ('Idealized_Results()')\n",
    "    # Set randomness\n",
    "    np.random.seed(0) # NumPy\n",
    "    random.seed(0) # Python\n",
    "    tf.random.set_seed(0) # Tensorflow    \n",
    "\n",
    "    shape, scale = 3.7, 0.1 # mean=4, std=2*sqrt(2)\n",
    "    a = np.random.gamma(shape, scale, 150771)\n",
    "    a = np.where(a>1.0, random.random(), a)\n",
    "    \n",
    "    shape, scale = 3.8, 0.1 # mean=4, std=2*sqrt(2)\n",
    "    b = np.random.gamma(shape, scale, 26621)    \n",
    "    b = np.where(b>1.0, random.random(), b)\n",
    "    b = 1-b\n",
    "    \n",
    "    y_proba = np.concatenate((a,b),axis=0)\n",
    "    Y_PROBA = np.concatenate((a,b),axis=0)\n",
    "    y_pred = K.round(y_proba)\n",
    "    y_test = [0]*len(a) + [1]*len(b)\n",
    "    N_median = np.median(a)\n",
    "    P_median = np.median(b)\n",
    "    \n",
    "    Move_Threshold(y_proba, y_test)\n",
    "    \n",
    "    filename = 'Ideal'\n",
    "    print (filename)\n",
    "    title = 'Original Example'\n",
    "    Plot_Prediction(y_test, y_proba, filename, title)\n",
    "    ROC(y_test, y_proba, [N_median, P_median], filename)    \n",
    "    Evaluate_Model(y_test, y_proba, y_pred, 0.5, filename)    \n",
    "    print ()\n",
    "    \n",
    "    filename = 'Ideal_Left'\n",
    "    title = 'Never Ambulance'\n",
    "    print (filename)\n",
    "    y_proba = 0.5 * y_proba\n",
    "    y_pred = K.round(y_proba)\n",
    "    Plot_Prediction(y_test, y_proba, filename, title)\n",
    "    ROC(y_test, y_proba, [N_median, 0.5, P_median], filename)    \n",
    "    Evaluate_Model(y_test, y_proba, y_pred, 0.5, filename)    \n",
    "    print ()\n",
    "\n",
    "    filename = 'Ideal_Left_Shifted'\n",
    "    title = ''\n",
    "    print (filename)\n",
    "    y_test, y_proba, y_pred, filename = Shift_y_proba(y_test, y_proba, y_pred, filename)\n",
    "    Plot_Prediction(y_test, y_proba, filename, title)\n",
    "    ROC(y_test, y_proba, [], filename)    \n",
    "    Evaluate_Model(y_test, y_proba, y_pred, 0.5, filename)    \n",
    "    print ()\n",
    "    \n",
    "    filename = 'Ideal_Left_Linear_Transform'\n",
    "    title = ''\n",
    "    print (filename)\n",
    "    y_test, y_proba, y_pred, filename = Linear_Transform_y_proba(y_test, y_proba, y_pred, filename)\n",
    "    Plot_Prediction(y_test, y_proba, filename, title)\n",
    "    ROC(y_test, y_proba, [], filename)    \n",
    "    Evaluate_Model(y_test, y_proba, y_pred, 0.5, filename)    \n",
    "    print ()\n",
    "    \n",
    "    filename = 'Ideal_Right'\n",
    "    title = 'Always Ambulance'\n",
    "    print (filename)\n",
    "    y_proba = 0.5 * Y_PROBA + 0.5\n",
    "    y_pred = K.round(y_proba)\n",
    "    Plot_Prediction(y_test, y_proba, filename, title)\n",
    "    ROC(y_test, y_proba, [N_median, 0.5, P_median], filename)    \n",
    "    Evaluate_Model(y_test, y_proba, y_pred, 0.5, filename)    \n",
    "    print ()\n",
    "\n",
    "    filename = 'Ideal_Right_Shifted'\n",
    "    title = ''\n",
    "    print (filename)\n",
    "    y_test, y_proba, y_pred, filename = Shift_y_proba(y_test, y_proba, y_pred, filename)\n",
    "    Plot_Prediction(y_test, y_proba, filename, title)\n",
    "    ROC(y_test, y_proba, [], filename)    \n",
    "    Evaluate_Model(y_test, y_proba, y_pred, 0.5, filename)    \n",
    "    print ()\n",
    "    \n",
    "    filename = 'Ideal_Right_Linear_Transform'\n",
    "    title = ''\n",
    "    print (filename)\n",
    "    y_test, y_proba, y_pred, filename = Linear_Transform_y_proba(y_test, y_proba, y_pred, filename)\n",
    "    Plot_Prediction(y_test, y_proba, filename, title)\n",
    "    ROC(y_test, y_proba, [], filename)    \n",
    "    Evaluate_Model(y_test, y_proba, y_pred, 0.5, filename)    \n",
    "    print ()\n",
    "    \n",
    "    y_proba = Y_PROBA\n",
    "    y_pred = K.round(y_proba)\n",
    "    y_test = [0]*len(a) + [1]*len(b)\n",
    "    \n",
    "    filename = 'Ideal_Tight'\n",
    "    title = 'Tight'\n",
    "    print (filename)\n",
    "    y_proba = 0.2 * Y_PROBA + 0.4\n",
    "    y_pred = K.round(y_proba)\n",
    "    Plot_Prediction(y_test, y_proba, filename, title)\n",
    "    ROC(y_test, y_proba, [N_median, 0.5, P_median], filename)    \n",
    "    Evaluate_Model(y_test, y_proba, y_pred, 0.5, filename)    \n",
    "    print ()\n",
    "   \n",
    "    y_proba = Y_PROBA\n",
    "    y_pred = K.round(y_proba)\n",
    "    y_test = [0]*len(a) + [1]*len(b)\n",
    "    \n",
    "    filename = 'Ideal_Shift_to_FP_equals_r_TP'\n",
    "    title = 'Transformed'\n",
    "    print (filename)\n",
    "    Plot_Prediction_Zoom(y_test, y_proba, 'Test', 'Test', 0.53, 0.73)    \n",
    "    y_test, y_proba, y_pred, p_target, filename_tmp = Shift_y_proba_to_FP_equals_r_TP(y_test, y_proba, 2.0, filename)\n",
    "    print ('type(y_test) = ', type(y_test))\n",
    "    N = y_proba[np.array(y_test)==0]\n",
    "    P = y_proba[np.array(y_test)==1]\n",
    "    display(N)\n",
    "    N_median = np.median(N)\n",
    "    P_median = np.median(P)\n",
    "    Plot_Prediction(y_test, y_proba, filename, title)\n",
    "    Plot_Prediction_Wide(y_test, y_proba, filename, title)\n",
    "    Plot_Prediction_Zoom(y_test, y_proba, filename, title, 0.4, 0.6)\n",
    "    ROC(y_test, y_proba, [N_median, P_median], filename)    \n",
    "    Evaluate_Model(y_test, y_proba, y_pred, 0.5, filename)    \n",
    "    print ()\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "#Idealized_Results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2a285425",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Awful_Results():\n",
    "    # Set randomness\n",
    "    np.random.seed(42) # NumPy\n",
    "    random.seed(42) # Python\n",
    "    tf.random.set_seed(42) # Tensorflow    \n",
    "    \n",
    "    \n",
    "    shape, scale = 1.0, 0.5 # mean=4, std=2*sqrt(2)\n",
    "    a = np.random.random(600)   \n",
    "    \n",
    "    b = np.random.random(100)    \n",
    "    b = np.where(b>1.0, random.random(), b)\n",
    "    b = 1-b\n",
    "    \n",
    "    y_proba = np.concatenate((a,b),axis=0)\n",
    "    y_pred = K.round(y_proba)\n",
    "    y_test = [0]*len(a) + [1]*len(b)\n",
    "    \n",
    "    filename = 'Awful'\n",
    "    title = 'Awful'\n",
    "    Plot_Prediction(y_test, y_proba, filename, title)\n",
    "    ROC(y_test, y_proba, [], filename)    \n",
    "    Evaluate_Model(y_test, y_proba, y_pred, 0.5, filename)    \n",
    "    \n",
    "#Awful_Results()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c4a296",
   "metadata": {},
   "source": [
    "## Run Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "93eb0b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Run_Models(Features = 'Hard', Tomek = 0, Version = 1, r_target = 2.0):\n",
    "    alpha = r_target/(1+r_target)\n",
    "\n",
    "    \n",
    "    if Features == 'Hard':\n",
    "        read_filename_features = '_Thin'\n",
    "        write_filename_features = '_Hard'\n",
    "    if Features == 'Medium':\n",
    "        read_filename_features = '_Really_Thin'\n",
    "        write_filename_features = '_Medium'\n",
    "    if Features == 'Easy':\n",
    "        read_filename_features = '_Thin_to_Minimal'\n",
    "        write_filename_features = '_Easy'\n",
    "    if Tomek==0:\n",
    "        read_filename_tomek = '_before_Tomek'\n",
    "        write_filename_tomek = '_Tomek_0'\n",
    "    if Tomek==1:\n",
    "        read_filename_tomek = '_after_Tomek'\n",
    "        write_filename_tomek = '_Tomek_1'\n",
    "    if Tomek==2:\n",
    "        read_filename_tomek = '_after_Tomek_Twice'\n",
    "        write_filename_tomek = '_Tomek_2'\n",
    "    if Version==1:\n",
    "        filename_version = '_v1'\n",
    "        random_seed = 0\n",
    "    if Version==2:\n",
    "        filename_version = '_v2'\n",
    "        random_seed = 42\n",
    "    i, d = divmod(r_target, 1)\n",
    "    i = int(i)\n",
    "    d = int(10*d)\n",
    "    filename_r_target = '_r_target_' + str(i) + '_' + str(d)\n",
    "\n",
    "    X_train = pd.read_csv('../../Big_Files/X_train' + read_filename_features + read_filename_tomek + filename_version + '.csv')\n",
    "    y_train = pd.read_csv('../../Big_Files/y_train' + read_filename_features + read_filename_tomek + filename_version + '.csv').squeeze()\n",
    "    X_test = pd.read_csv('../../Big_Files/X_test' + read_filename_features + read_filename_tomek + filename_version + '.csv')\n",
    "    y_test = pd.read_csv('../../Big_Files/y_test' + read_filename_features + read_filename_tomek + filename_version + '.csv').squeeze()\n",
    "\n",
    "    N = len(y_train)\n",
    "    n = len(y_train[y_train==1])\n",
    "    p = (N-n)/n\n",
    "    alpha_balanced = p/(p+1)\n",
    "    print ('p = ', p)\n",
    "    print ('alpha_balanced = ', alpha_balanced)\n",
    "    \n",
    "    np.random.seed(random_seed) # NumPy\n",
    "    random.seed(random_seed) # Python\n",
    "    tf.random.set_seed(random_seed) # Tensorflow\n",
    " \n",
    "\n",
    "    \"\"\"\n",
    "    print ()\n",
    "    print ('------------------------------------------')\n",
    "    filename_model = 'KBFC'\n",
    "    filename = filename_model + write_filename_features + write_filename_tomek + '_alpha_balanced_gamma_0_0' + filename_version + filename_r_target\n",
    "    title = 'Focal $\\gamma=0.0$'\n",
    "    print (filename)\n",
    "    print ('alpha_balanced = ', alpha_balanced)\n",
    "    gamma = 0.0\n",
    "    epochs=20\n",
    "    Keras_Binary_Focal_Crossentropy(X_train, X_test, y_train, y_test, r_target, alpha_balanced, gamma, epochs, filename, title)\n",
    "\n",
    "    np.random.seed(random_seed) # NumPy\n",
    "    random.seed(random_seed) # Python\n",
    "    tf.random.set_seed(random_seed) # Tensorflow\n",
    "    \n",
    "    print ()\n",
    "    print ('------------------------------------------')\n",
    "    filename_model = 'KBFC'\n",
    "    filename = filename_model + write_filename_features + write_filename_tomek + '_alpha_target_gamma_0_0' + filename_version + filename_r_target\n",
    "    title = 'Focal $\\gamma=0.0$'\n",
    "    print (filename)\n",
    "    gamma = 0.0\n",
    "    epochs=20\n",
    "    Keras_Binary_Focal_Crossentropy(X_train, X_test, y_train, y_test, r_target, alpha, gamma, epochs, filename, title)\n",
    "\n",
    "    np.random.seed(random_seed) # NumPy\n",
    "    random.seed(random_seed) # Python\n",
    "    tf.random.set_seed(random_seed) # Tensorflow\n",
    "    \n",
    "    print ()\n",
    "    print ('------------------------------------------')\n",
    "    filename_model = 'KBFC'\n",
    "    filename = filename_model + write_filename_features + write_filename_tomek + '_alpha_0_5_gamma_0_0' + filename_version + filename_r_target\n",
    "    title = 'Focal $\\gamma=0.0$'\n",
    "    print (filename)\n",
    "    gamma = 0.0\n",
    "    epochs=20\n",
    "    Keras_Binary_Focal_Crossentropy(X_train, X_test, y_train, y_test, r_target, 0.5, gamma, epochs, filename, title)\n",
    "\n",
    "\n",
    "    np.random.seed(random_seed) # NumPy\n",
    "    random.seed(random_seed) # Python\n",
    "    tf.random.set_seed(random_seed) # Tensorflow\n",
    "    \n",
    "    print ()\n",
    "    print ('------------------------------------------')\n",
    "    filename_model = 'KBFC'\n",
    "    filename = filename_model + write_filename_features + write_filename_tomek + '_alpha_target_gamma_0_5' + filename_version + filename_r_target\n",
    "    title = 'Focal $\\gamma=0.5$'\n",
    "    print (filename)\n",
    "    gamma = 0.5\n",
    "    epochs=20\n",
    "    Keras_Binary_Focal_Crossentropy(X_train, X_test, y_train, y_test, r_target, alpha, gamma, epochs, filename, title)\n",
    "\n",
    "    np.random.seed(random_seed) # NumPy\n",
    "    random.seed(random_seed) # Python\n",
    "    tf.random.set_seed(random_seed) # Tensorflow\n",
    "    \n",
    "    print ()\n",
    "    print ('------------------------------------------')\n",
    "    filename_model = 'KBFC'\n",
    "    filename = filename_model + write_filename_features + write_filename_tomek + '_alpha_target_gamma_1_0' + filename_version + filename_r_target\n",
    "    title = 'Focal $\\gamma=1.0$'\n",
    "    print (filename)\n",
    "    gamma = 1.0\n",
    "    epochs=20\n",
    "    Keras_Binary_Focal_Crossentropy(X_train, X_test, y_train, y_test, r_target, alpha, gamma, epochs, filename, title)\n",
    "\n",
    "    np.random.seed(random_seed) # NumPy\n",
    "    random.seed(random_seed) # Python\n",
    "    tf.random.set_seed(random_seed) # Tensorflow\n",
    "    \n",
    "    print ()\n",
    "    print ('------------------------------------------')\n",
    "    filename_model = 'KBFC'\n",
    "    filename = filename_model + write_filename_features + write_filename_tomek + '_alpha_target_gamma_2_0' + filename_version + filename_r_target\n",
    "    title = 'Focal $\\gamma=2.0$'\n",
    "    print (filename)\n",
    "    gamma = 2.0\n",
    "    epochs=20\n",
    "    Keras_Binary_Focal_Crossentropy(X_train, X_test, y_train, y_test, r_target, alpha, gamma, epochs, filename, title)\n",
    "\n",
    "    np.random.seed(random_seed) # NumPy\n",
    "    random.seed(random_seed) # Python\n",
    "    tf.random.set_seed(random_seed) # Tensorflow\n",
    "    \n",
    "    print ()\n",
    "    print ('------------------------------------------')\n",
    "    filename_model = 'KBFC'\n",
    "    filename = filename_model + write_filename_features + write_filename_tomek + '_alpha_target_gamma_5_0' + filename_version + filename_r_target\n",
    "    title = 'Focal $\\gamma=5.0$'\n",
    "    print (filename)\n",
    "    gamma = 5.0\n",
    "    epochs=20\n",
    "    Keras_Binary_Focal_Crossentropy(X_train, X_test, y_train, y_test, r_target, alpha, gamma, epochs, filename, title)\n",
    "\n",
    "    np.random.seed(random_seed) # NumPy\n",
    "    random.seed(random_seed) # Python\n",
    "    tf.random.set_seed(random_seed) # Tensorflow\n",
    " \n",
    "    print ()\n",
    "    print ('------------------------------------------')\n",
    "    filename_model = 'OBFC'\n",
    "    filename = filename_model + write_filename_features + write_filename_tomek + '_alpha_target_gamma_0_0_5_gamma_1_2_0' + filename_version + filename_r_target\n",
    "    alpha = alpha_target\n",
    "    gamma_0 = 0.5\n",
    "    gamma_1 = 2.0\n",
    "    epochs = 20\n",
    "    title = 'OBFC $\\alpha = ' + \"{:.2f}\".format(alpha) + '\\gamma_0 = ' + \"{:.2f}\".format(gamma_0) + ' \\gamma_1 = ' + \"{:.2f}\".format(gamma_1) + '$'\n",
    "    Our_Binary_Focal_Crossentropy(X_train, X_test, y_train, y_test, r_target, alpha, gamma_0, gamma_1, epochs, filename, title)\n",
    "    \n",
    "\n",
    "    np.random.seed(random_seed) # NumPy\n",
    "    random.seed(random_seed) # Python\n",
    "    tf.random.set_seed(random_seed) # Tensorflow\n",
    "    \n",
    "    print ()\n",
    "    print ('------------------------------------------')\n",
    "    filename_model = 'LRC'\n",
    "    filename = filename_model + write_filename_features + write_filename_tomek + '_alpha_0_5' + filename_version + filename_r_target\n",
    "    title = 'LogReg'\n",
    "    Logistic_Regression_Classifier(X_train, X_test, y_train, y_test, r_target, 0.5, filename, title)\n",
    "\n",
    "    np.random.seed(random_seed) # NumPy\n",
    "    random.seed(random_seed) # Python\n",
    "    tf.random.set_seed(random_seed) # Tensorflow\n",
    "    \n",
    "\n",
    "    print ()\n",
    "    print ('------------------------------------------')\n",
    "    filename_model = 'LRC'\n",
    "    filename = filename_model + write_filename_features + write_filename_tomek + '_alpha_target' + filename_version + filename_r_target\n",
    "    title = 'LogReg'\n",
    "    Logistic_Regression_Classifier(X_train, X_test, y_train, y_test, r_target, alpha, filename, title)\n",
    "\n",
    "    np.random.seed(random_seed) # NumPy\n",
    "    random.seed(random_seed) # Python\n",
    "    tf.random.set_seed(random_seed) # Tensorflow\n",
    "    \n",
    "    print ()\n",
    "    print ('------------------------------------------')\n",
    "    filename_model = 'LRC'\n",
    "    filename = filename_model + write_filename_features + write_filename_tomek + '_alpha_balanced' + filename_version + filename_r_target\n",
    "    title = 'LogReg'\n",
    "    Logistic_Regression_Classifier(X_train, X_test, y_train, y_test, r_target, alpha_balanced, filename, title)\n",
    "    \n",
    "    \"\"\"\n",
    "    np.random.seed(random_seed) # NumPy\n",
    "    random.seed(random_seed) # Python\n",
    "    tf.random.set_seed(random_seed) # Tensorflow\n",
    "    \n",
    "    print ()\n",
    "    print ('------------------------------------------')\n",
    "    filename_model = 'BRFC'\n",
    "    filename = filename_model + write_filename_features + write_filename_tomek + '_alpha_0_5' + filename_version + filename_r_target\n",
    "    title = 'BRForest'\n",
    "    Balanced_Random_Forest_Classifier(X_train, X_test, y_train, y_test, r_target, 0.5, filename, title)\n",
    "\n",
    "    np.random.seed(random_seed) # NumPy\n",
    "    random.seed(random_seed) # Python\n",
    "    tf.random.set_seed(random_seed) # Tensorflow\n",
    " \n",
    "    return 0\n",
    "\n",
    "    print ()\n",
    "    print ('------------------------------------------')\n",
    "    filename_model = 'BRFC'\n",
    "    filename = filename_model + write_filename_features + write_filename_tomek + '_alpha_target' + filename_version + filename_r_target\n",
    "    title = 'BRForest'\n",
    "    Balanced_Random_Forest_Classifier(X_train, X_test, y_train, y_test, r_target, alpha, filename, title)\n",
    "\n",
    "    np.random.seed(random_seed) # NumPy\n",
    "    random.seed(random_seed) # Python\n",
    "    tf.random.set_seed(random_seed) # Tensorflow\n",
    "    \n",
    "    print ()\n",
    "    print ('------------------------------------------')\n",
    "    filename_model = 'BRFC'\n",
    "    filename = filename_model + write_filename_features + write_filename_tomek + '_alpha_balanced' + filename_version + filename_r_target\n",
    "    title = 'BRForest'\n",
    "    Balanced_Random_Forest_Classifier(X_train, X_test, y_train, y_test, r_target, alpha_balanced, filename, title)\n",
    "\n",
    "    np.random.seed(random_seed) # NumPy\n",
    "    random.seed(random_seed) # Python\n",
    "    tf.random.set_seed(random_seed) # Tensorflow\n",
    "    \n",
    "    print ()\n",
    "    print ('------------------------------------------')\n",
    "    filename_model = 'AdaBoost'\n",
    "    filename = filename_model + write_filename_features + write_filename_tomek + '' + filename_version + filename_r_target\n",
    "    title = 'AdaBoost'\n",
    "    AdaBoost(X_train, X_test, y_train, y_test, r_target, filename, title)\n",
    "    \n",
    "    np.random.seed(random_seed) # NumPy\n",
    "    random.seed(random_seed) # Python\n",
    "    tf.random.set_seed(random_seed) # Tensorflow\n",
    "    \n",
    "    print ()\n",
    "    print ('------------------------------------------')\n",
    "    filename_model = 'Bagging'\n",
    "    filename = filename_model + write_filename_features + write_filename_tomek + '' + filename_version + filename_r_target\n",
    "    title = 'BalBag'\n",
    "    Bagging(X_train, X_test, y_train, y_test, r_target, filename, title)\n",
    "\n",
    "    np.random.seed(random_seed) # NumPy\n",
    "    random.seed(random_seed) # Python\n",
    "    tf.random.set_seed(random_seed) # Tensorflow\n",
    "    \n",
    "    print ()\n",
    "    print ('------------------------------------------')\n",
    "    filename_model = 'RUSBoost'\n",
    "    filename = filename_model + write_filename_features + write_filename_tomek + '' + filename_version + filename_r_target\n",
    "    title = 'RUSBoost'\n",
    "    estimator = DecisionTreeClassifier(\n",
    "        max_depth=1,\n",
    "        class_weight={0:(1+r_target)/(2*r_target), 1:(1+r_target)/(2*1)},\n",
    "    )\n",
    "    RUSBoost_Classifier(X_train, X_test, y_train, y_test, estimator, r_target, filename, title)\n",
    "\n",
    "    np.random.seed(random_seed) # NumPy\n",
    "    random.seed(random_seed) # Python\n",
    "    tf.random.set_seed(random_seed) # Tensorflow\n",
    "    \n",
    "    print ()\n",
    "    print ('------------------------------------------')\n",
    "    filename_model = 'EEC'\n",
    "    filename = filename_model + write_filename_features + write_filename_tomek + '' + filename_version + filename_r_target\n",
    "    title = 'EasyEns'\n",
    "    Easy_Ensemble_Classifier(X_train, X_test, y_train, y_test, r_target, filename, title)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fc8e41e1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p =  5.3286622912601675\n",
      "alpha_balanced =  0.8419887246344315\n",
      "\n",
      "------------------------------------------\n",
      "Balanced Random Forest Classifier  BRFC_Hard_Tomek_0_alpha_0_5_v1_r_target_1_0\n",
      "alpha =  0.5\n",
      "\n",
      "\n",
      "model.get_params()\n",
      "{'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': {0: 0.5, 1: 0.5}, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': None, 'replacement': False, 'sampling_strategy': 'auto', 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "[estimator.get_depth() for estimator in model.estimators_]\n",
      "[50, 50, 46, 45, 48, 52, 49, 49, 48, 52, 48, 47, 49, 49, 44, 49, 43, 46, 46, 46, 49, 44, 46, 47, 48, 49, 48, 55, 55, 50, 51, 49, 47, 46, 47, 47, 46, 48, 48, 48, 47, 49, 47, 45, 45, 47, 46, 46, 48, 43, 48, 47, 46, 48, 45, 47, 49, 52, 45, 47, 49, 47, 45, 47, 47, 49, 47, 49, 42, 50, 47, 48, 44, 48, 49, 46, 45, 48, 45, 48, 48, 44, 49, 48, 43, 49, 46, 56, 48, 46, 47, 44, 47, 46, 49, 46, 47, 47, 48, 47]\n",
      "\n",
      "[estimator.get_n_leaves() for estimator in model.estimators_]\n",
      "[45313, 44807, 45223, 45227, 45003, 45195, 45234, 45342, 45274, 45148, 45267, 44997, 45319, 45157, 45512, 45430, 45127, 44961, 44750, 45234, 45045, 44906, 45107, 45098, 44693, 44777, 45145, 45015, 44829, 44953, 45039, 45224, 44774, 45306, 45333, 45305, 45023, 44634, 45159, 45179, 44767, 45183, 44828, 44844, 45042, 45334, 45229, 45391, 45218, 45234, 44829, 44539, 45348, 44712, 44932, 44320, 45467, 44889, 44828, 44753, 44790, 45009, 45627, 45326, 44568, 44908, 45160, 45115, 45239, 44920, 44875, 44608, 45143, 45085, 44983, 44574, 44980, 44747, 45159, 45291, 44357, 44818, 44974, 45273, 44896, 44887, 44998, 44854, 45195, 45120, 44835, 44749, 45232, 45398, 45220, 45499, 45039, 45143, 45173, 44945]\n",
      "\n",
      "Analyze_Prediction()\n",
      "BRFC_Hard_Tomek_0_alpha_0_5_v1_r_target_1_0_Train\n",
      "print (len(A), len(C), len(D), len(C) + len(D))\n",
      "499496 420570 78926 499496\n",
      "[-0.05, 0.0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1.0]\n",
      "./Analyze_Proba/BRFC_Hard_Tomek_0_alpha_0_5_v1_r_target_1_0_Train_20.tex\n",
      "499496\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Neg</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Neg/Pos</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP/TP</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>Rec.</th>\n",
       "      <th>$\\hat{p}$</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.00</th>\n",
       "      <td>317</td>\n",
       "      <td>0</td>\n",
       "      <td>inf</td>\n",
       "      <td>317</td>\n",
       "      <td>420,253</td>\n",
       "      <td>0</td>\n",
       "      <td>78,926</td>\n",
       "      <td>5.32</td>\n",
       "      <td>0.16</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.05</th>\n",
       "      <td>6,792</td>\n",
       "      <td>0</td>\n",
       "      <td>inf</td>\n",
       "      <td>7,109</td>\n",
       "      <td>413,461</td>\n",
       "      <td>0</td>\n",
       "      <td>78,926</td>\n",
       "      <td>5.24</td>\n",
       "      <td>0.16</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.10</th>\n",
       "      <td>19,088</td>\n",
       "      <td>0</td>\n",
       "      <td>inf</td>\n",
       "      <td>26,197</td>\n",
       "      <td>394,373</td>\n",
       "      <td>0</td>\n",
       "      <td>78,926</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.15</th>\n",
       "      <td>30,204</td>\n",
       "      <td>0</td>\n",
       "      <td>inf</td>\n",
       "      <td>56,401</td>\n",
       "      <td>364,169</td>\n",
       "      <td>0</td>\n",
       "      <td>78,926</td>\n",
       "      <td>4.61</td>\n",
       "      <td>0.18</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.20</th>\n",
       "      <td>38,838</td>\n",
       "      <td>0</td>\n",
       "      <td>inf</td>\n",
       "      <td>95,239</td>\n",
       "      <td>325,331</td>\n",
       "      <td>0</td>\n",
       "      <td>78,926</td>\n",
       "      <td>4.12</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.25</th>\n",
       "      <td>44,195</td>\n",
       "      <td>0</td>\n",
       "      <td>inf</td>\n",
       "      <td>139,434</td>\n",
       "      <td>281,136</td>\n",
       "      <td>0</td>\n",
       "      <td>78,926</td>\n",
       "      <td>3.56</td>\n",
       "      <td>0.22</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.30</th>\n",
       "      <td>46,960</td>\n",
       "      <td>0</td>\n",
       "      <td>inf</td>\n",
       "      <td>186,394</td>\n",
       "      <td>234,176</td>\n",
       "      <td>0</td>\n",
       "      <td>78,926</td>\n",
       "      <td>2.97</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.35</th>\n",
       "      <td>46,194</td>\n",
       "      <td>0</td>\n",
       "      <td>inf</td>\n",
       "      <td>232,588</td>\n",
       "      <td>187,982</td>\n",
       "      <td>0</td>\n",
       "      <td>78,926</td>\n",
       "      <td>2.38</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.40</th>\n",
       "      <td>43,487</td>\n",
       "      <td>0</td>\n",
       "      <td>inf</td>\n",
       "      <td>276,075</td>\n",
       "      <td>144,495</td>\n",
       "      <td>0</td>\n",
       "      <td>78,926</td>\n",
       "      <td>1.83</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.45</th>\n",
       "      <td>38,603</td>\n",
       "      <td>0</td>\n",
       "      <td>inf</td>\n",
       "      <td>314,678</td>\n",
       "      <td>105,892</td>\n",
       "      <td>0</td>\n",
       "      <td>78,926</td>\n",
       "      <td>1.34</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.50</th>\n",
       "      <td>32,098</td>\n",
       "      <td>1</td>\n",
       "      <td>32098.00</td>\n",
       "      <td>346,776</td>\n",
       "      <td>73,794</td>\n",
       "      <td>1</td>\n",
       "      <td>78,925</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.55</th>\n",
       "      <td>25,069</td>\n",
       "      <td>11</td>\n",
       "      <td>2279.00</td>\n",
       "      <td>371,845</td>\n",
       "      <td>48,725</td>\n",
       "      <td>12</td>\n",
       "      <td>78,914</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.60</th>\n",
       "      <td>18,490</td>\n",
       "      <td>77</td>\n",
       "      <td>240.13</td>\n",
       "      <td>390,335</td>\n",
       "      <td>30,235</td>\n",
       "      <td>89</td>\n",
       "      <td>78,837</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.72</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.65</th>\n",
       "      <td>12,600</td>\n",
       "      <td>566</td>\n",
       "      <td>22.26</td>\n",
       "      <td>402,935</td>\n",
       "      <td>17,635</td>\n",
       "      <td>655</td>\n",
       "      <td>78,271</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.70</th>\n",
       "      <td>8,105</td>\n",
       "      <td>2,183</td>\n",
       "      <td>3.71</td>\n",
       "      <td>411,040</td>\n",
       "      <td>9,530</td>\n",
       "      <td>2,838</td>\n",
       "      <td>76,088</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.75</th>\n",
       "      <td>4,926</td>\n",
       "      <td>5,593</td>\n",
       "      <td>0.88</td>\n",
       "      <td>415,966</td>\n",
       "      <td>4,604</td>\n",
       "      <td>8,431</td>\n",
       "      <td>70,495</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.80</th>\n",
       "      <td>2,773</td>\n",
       "      <td>10,743</td>\n",
       "      <td>0.26</td>\n",
       "      <td>418,739</td>\n",
       "      <td>1,831</td>\n",
       "      <td>19,174</td>\n",
       "      <td>59,752</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.85</th>\n",
       "      <td>1,387</td>\n",
       "      <td>16,279</td>\n",
       "      <td>0.09</td>\n",
       "      <td>420,126</td>\n",
       "      <td>444</td>\n",
       "      <td>35,453</td>\n",
       "      <td>43,473</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.90</th>\n",
       "      <td>370</td>\n",
       "      <td>18,283</td>\n",
       "      <td>0.02</td>\n",
       "      <td>420,496</td>\n",
       "      <td>74</td>\n",
       "      <td>53,736</td>\n",
       "      <td>25,190</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.95</th>\n",
       "      <td>64</td>\n",
       "      <td>16,144</td>\n",
       "      <td>0.00</td>\n",
       "      <td>420,560</td>\n",
       "      <td>10</td>\n",
       "      <td>69,880</td>\n",
       "      <td>9,046</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.00</th>\n",
       "      <td>10</td>\n",
       "      <td>9,046</td>\n",
       "      <td>0.00</td>\n",
       "      <td>420,570</td>\n",
       "      <td>0</td>\n",
       "      <td>78,926</td>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Neg     Pos   Neg/Pos       TN       FP      FN      TP FP/TP Prec.  \\\n",
       "p                                                                              \n",
       "0.00     317       0       inf      317  420,253       0  78,926  5.32  0.16   \n",
       "0.05   6,792       0       inf    7,109  413,461       0  78,926  5.24  0.16   \n",
       "0.10  19,088       0       inf   26,197  394,373       0  78,926  5.00  0.17   \n",
       "0.15  30,204       0       inf   56,401  364,169       0  78,926  4.61  0.18   \n",
       "0.20  38,838       0       inf   95,239  325,331       0  78,926  4.12  0.20   \n",
       "0.25  44,195       0       inf  139,434  281,136       0  78,926  3.56  0.22   \n",
       "0.30  46,960       0       inf  186,394  234,176       0  78,926  2.97  0.25   \n",
       "0.35  46,194       0       inf  232,588  187,982       0  78,926  2.38  0.30   \n",
       "0.40  43,487       0       inf  276,075  144,495       0  78,926  1.83  0.35   \n",
       "0.45  38,603       0       inf  314,678  105,892       0  78,926  1.34  0.43   \n",
       "0.50  32,098       1  32098.00  346,776   73,794       1  78,925  0.93  0.52   \n",
       "0.55  25,069      11   2279.00  371,845   48,725      12  78,914  0.62  0.62   \n",
       "0.60  18,490      77    240.13  390,335   30,235      89  78,837  0.38  0.72   \n",
       "0.65  12,600     566     22.26  402,935   17,635     655  78,271  0.23  0.82   \n",
       "0.70   8,105   2,183      3.71  411,040    9,530   2,838  76,088  0.13  0.89   \n",
       "0.75   4,926   5,593      0.88  415,966    4,604   8,431  70,495  0.07  0.94   \n",
       "0.80   2,773  10,743      0.26  418,739    1,831  19,174  59,752  0.03  0.97   \n",
       "0.85   1,387  16,279      0.09  420,126      444  35,453  43,473  0.01  0.99   \n",
       "0.90     370  18,283      0.02  420,496       74  53,736  25,190  0.00  1.00   \n",
       "0.95      64  16,144      0.00  420,560       10  69,880   9,046  0.00  1.00   \n",
       "1.00      10   9,046      0.00  420,570        0  78,926       0   nan   nan   \n",
       "\n",
       "      Rec. $\\hat{p}$  \n",
       "p                     \n",
       "0.00  1.00      1.00  \n",
       "0.05  1.00      0.99  \n",
       "0.10  1.00      0.95  \n",
       "0.15  1.00      0.89  \n",
       "0.20  1.00      0.81  \n",
       "0.25  1.00      0.72  \n",
       "0.30  1.00      0.63  \n",
       "0.35  1.00      0.53  \n",
       "0.40  1.00      0.45  \n",
       "0.45  1.00      0.37  \n",
       "0.50  1.00      0.31  \n",
       "0.55  1.00      0.26  \n",
       "0.60  1.00      0.22  \n",
       "0.65  0.99      0.19  \n",
       "0.70  0.96      0.17  \n",
       "0.75  0.89      0.15  \n",
       "0.80  0.76      0.12  \n",
       "0.85  0.55      0.09  \n",
       "0.90  0.32      0.05  \n",
       "0.95  0.11      0.02  \n",
       "1.00  0.00      0.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.01, 0.0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.2, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.4, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.5, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.6, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.7, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.8, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, 0.9, 0.91, 0.92, 0.93, 0.94, 0.95, 0.96, 0.97, 0.98, 0.99, 1.0]\n",
      "Plot_Prediction()\n",
      "BRFC_Hard_Tomek_0_alpha_0_5_v1_r_target_1_0_Train\n",
      "[0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
      "./Images/BRFC_Hard_Tomek_0_alpha_0_5_v1_r_target_1_0_Train_Pred.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x150 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Plot_Prediction()\n",
      "BRFC_Hard_Tomek_0_alpha_0_5_v1_r_target_1_0_Train\n",
      "[0.0, 0.04, 0.08, 0.12, 0.16, 0.2, 0.24, 0.28, 0.32, 0.36, 0.4, 0.44, 0.48, 0.52, 0.56, 0.6, 0.64, 0.68, 0.72, 0.76, 0.8, 0.84, 0.88, 0.92, 0.96, 1.0]\n",
      "./Images/BRFC_Hard_Tomek_0_alpha_0_5_v1_r_target_1_0_Train_Pred_Wide.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x150 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ROC()\n",
      "BRFC_Hard_Tomek_0_alpha_0_5_v1_r_target_1_0_Train\n",
      "p_values =  []\n",
      "./Images/BRFC_Hard_Tomek_0_alpha_0_5_v1_r_target_1_0_Train_ROC.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x150 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Analyze_Prediction()\n",
      "BRFC_Hard_Tomek_0_alpha_0_5_v1_r_target_1_0_Test\n",
      "print (len(A), len(C), len(D), len(C) + len(D))\n",
      "214070 180245 33825 214070\n",
      "[-0.05, 0.0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1.0]\n",
      "./Analyze_Proba/BRFC_Hard_Tomek_0_alpha_0_5_v1_r_target_1_0_Test_20.tex\n",
      "214070\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Neg</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Neg/Pos</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP/TP</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>Rec.</th>\n",
       "      <th>$\\hat{p}$</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.00</th>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>inf</td>\n",
       "      <td>107</td>\n",
       "      <td>180,138</td>\n",
       "      <td>0</td>\n",
       "      <td>33,825</td>\n",
       "      <td>5.33</td>\n",
       "      <td>0.16</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.05</th>\n",
       "      <td>2,287</td>\n",
       "      <td>20</td>\n",
       "      <td>114.35</td>\n",
       "      <td>2,394</td>\n",
       "      <td>177,851</td>\n",
       "      <td>20</td>\n",
       "      <td>33,805</td>\n",
       "      <td>5.26</td>\n",
       "      <td>0.16</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.10</th>\n",
       "      <td>6,177</td>\n",
       "      <td>62</td>\n",
       "      <td>99.63</td>\n",
       "      <td>8,571</td>\n",
       "      <td>171,674</td>\n",
       "      <td>82</td>\n",
       "      <td>33,743</td>\n",
       "      <td>5.09</td>\n",
       "      <td>0.16</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.15</th>\n",
       "      <td>10,435</td>\n",
       "      <td>188</td>\n",
       "      <td>55.51</td>\n",
       "      <td>19,006</td>\n",
       "      <td>161,239</td>\n",
       "      <td>270</td>\n",
       "      <td>33,555</td>\n",
       "      <td>4.81</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.20</th>\n",
       "      <td>13,424</td>\n",
       "      <td>388</td>\n",
       "      <td>34.60</td>\n",
       "      <td>32,430</td>\n",
       "      <td>147,815</td>\n",
       "      <td>658</td>\n",
       "      <td>33,167</td>\n",
       "      <td>4.46</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.25</th>\n",
       "      <td>15,746</td>\n",
       "      <td>619</td>\n",
       "      <td>25.44</td>\n",
       "      <td>48,176</td>\n",
       "      <td>132,069</td>\n",
       "      <td>1,277</td>\n",
       "      <td>32,548</td>\n",
       "      <td>4.06</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.30</th>\n",
       "      <td>17,256</td>\n",
       "      <td>923</td>\n",
       "      <td>18.70</td>\n",
       "      <td>65,432</td>\n",
       "      <td>114,813</td>\n",
       "      <td>2,200</td>\n",
       "      <td>31,625</td>\n",
       "      <td>3.63</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.35</th>\n",
       "      <td>17,841</td>\n",
       "      <td>1,320</td>\n",
       "      <td>13.52</td>\n",
       "      <td>83,273</td>\n",
       "      <td>96,972</td>\n",
       "      <td>3,520</td>\n",
       "      <td>30,305</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.40</th>\n",
       "      <td>17,355</td>\n",
       "      <td>1,690</td>\n",
       "      <td>10.27</td>\n",
       "      <td>100,628</td>\n",
       "      <td>79,617</td>\n",
       "      <td>5,210</td>\n",
       "      <td>28,615</td>\n",
       "      <td>2.78</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.45</th>\n",
       "      <td>16,597</td>\n",
       "      <td>2,042</td>\n",
       "      <td>8.13</td>\n",
       "      <td>117,225</td>\n",
       "      <td>63,020</td>\n",
       "      <td>7,252</td>\n",
       "      <td>26,573</td>\n",
       "      <td>2.37</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.50</th>\n",
       "      <td>14,984</td>\n",
       "      <td>2,470</td>\n",
       "      <td>6.07</td>\n",
       "      <td>132,209</td>\n",
       "      <td>48,036</td>\n",
       "      <td>9,722</td>\n",
       "      <td>24,103</td>\n",
       "      <td>1.99</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.55</th>\n",
       "      <td>12,810</td>\n",
       "      <td>2,725</td>\n",
       "      <td>4.70</td>\n",
       "      <td>145,019</td>\n",
       "      <td>35,226</td>\n",
       "      <td>12,447</td>\n",
       "      <td>21,378</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.60</th>\n",
       "      <td>10,493</td>\n",
       "      <td>2,972</td>\n",
       "      <td>3.53</td>\n",
       "      <td>155,512</td>\n",
       "      <td>24,733</td>\n",
       "      <td>15,419</td>\n",
       "      <td>18,406</td>\n",
       "      <td>1.34</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.65</th>\n",
       "      <td>8,062</td>\n",
       "      <td>3,037</td>\n",
       "      <td>2.65</td>\n",
       "      <td>163,574</td>\n",
       "      <td>16,671</td>\n",
       "      <td>18,456</td>\n",
       "      <td>15,369</td>\n",
       "      <td>1.08</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.70</th>\n",
       "      <td>6,040</td>\n",
       "      <td>2,953</td>\n",
       "      <td>2.05</td>\n",
       "      <td>169,614</td>\n",
       "      <td>10,631</td>\n",
       "      <td>21,409</td>\n",
       "      <td>12,416</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.75</th>\n",
       "      <td>4,144</td>\n",
       "      <td>2,893</td>\n",
       "      <td>1.43</td>\n",
       "      <td>173,758</td>\n",
       "      <td>6,487</td>\n",
       "      <td>24,302</td>\n",
       "      <td>9,523</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.80</th>\n",
       "      <td>2,902</td>\n",
       "      <td>2,627</td>\n",
       "      <td>1.10</td>\n",
       "      <td>176,660</td>\n",
       "      <td>3,585</td>\n",
       "      <td>26,929</td>\n",
       "      <td>6,896</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.85</th>\n",
       "      <td>1,801</td>\n",
       "      <td>2,530</td>\n",
       "      <td>0.71</td>\n",
       "      <td>178,461</td>\n",
       "      <td>1,784</td>\n",
       "      <td>29,459</td>\n",
       "      <td>4,366</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.90</th>\n",
       "      <td>1,043</td>\n",
       "      <td>2,166</td>\n",
       "      <td>0.48</td>\n",
       "      <td>179,504</td>\n",
       "      <td>741</td>\n",
       "      <td>31,625</td>\n",
       "      <td>2,200</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.95</th>\n",
       "      <td>587</td>\n",
       "      <td>1,597</td>\n",
       "      <td>0.37</td>\n",
       "      <td>180,091</td>\n",
       "      <td>154</td>\n",
       "      <td>33,222</td>\n",
       "      <td>603</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.00</th>\n",
       "      <td>154</td>\n",
       "      <td>603</td>\n",
       "      <td>0.26</td>\n",
       "      <td>180,245</td>\n",
       "      <td>0</td>\n",
       "      <td>33,825</td>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Neg    Pos Neg/Pos       TN       FP      FN      TP FP/TP Prec.  \\\n",
       "p                                                                           \n",
       "0.00     107      0     inf      107  180,138       0  33,825  5.33  0.16   \n",
       "0.05   2,287     20  114.35    2,394  177,851      20  33,805  5.26  0.16   \n",
       "0.10   6,177     62   99.63    8,571  171,674      82  33,743  5.09  0.16   \n",
       "0.15  10,435    188   55.51   19,006  161,239     270  33,555  4.81  0.17   \n",
       "0.20  13,424    388   34.60   32,430  147,815     658  33,167  4.46  0.18   \n",
       "0.25  15,746    619   25.44   48,176  132,069   1,277  32,548  4.06  0.20   \n",
       "0.30  17,256    923   18.70   65,432  114,813   2,200  31,625  3.63  0.22   \n",
       "0.35  17,841  1,320   13.52   83,273   96,972   3,520  30,305  3.20  0.24   \n",
       "0.40  17,355  1,690   10.27  100,628   79,617   5,210  28,615  2.78  0.26   \n",
       "0.45  16,597  2,042    8.13  117,225   63,020   7,252  26,573  2.37  0.30   \n",
       "0.50  14,984  2,470    6.07  132,209   48,036   9,722  24,103  1.99  0.33   \n",
       "0.55  12,810  2,725    4.70  145,019   35,226  12,447  21,378  1.65  0.38   \n",
       "0.60  10,493  2,972    3.53  155,512   24,733  15,419  18,406  1.34  0.43   \n",
       "0.65   8,062  3,037    2.65  163,574   16,671  18,456  15,369  1.08  0.48   \n",
       "0.70   6,040  2,953    2.05  169,614   10,631  21,409  12,416  0.86  0.54   \n",
       "0.75   4,144  2,893    1.43  173,758    6,487  24,302   9,523  0.68  0.59   \n",
       "0.80   2,902  2,627    1.10  176,660    3,585  26,929   6,896  0.52  0.66   \n",
       "0.85   1,801  2,530    0.71  178,461    1,784  29,459   4,366  0.41  0.71   \n",
       "0.90   1,043  2,166    0.48  179,504      741  31,625   2,200  0.34  0.75   \n",
       "0.95     587  1,597    0.37  180,091      154  33,222     603  0.26  0.80   \n",
       "1.00     154    603    0.26  180,245        0  33,825       0   nan   nan   \n",
       "\n",
       "      Rec. $\\hat{p}$  \n",
       "p                     \n",
       "0.00  1.00      1.00  \n",
       "0.05  1.00      0.99  \n",
       "0.10  1.00      0.96  \n",
       "0.15  0.99      0.91  \n",
       "0.20  0.98      0.85  \n",
       "0.25  0.96      0.77  \n",
       "0.30  0.93      0.68  \n",
       "0.35  0.90      0.59  \n",
       "0.40  0.85      0.51  \n",
       "0.45  0.79      0.42  \n",
       "0.50  0.71      0.34  \n",
       "0.55  0.63      0.26  \n",
       "0.60  0.54      0.20  \n",
       "0.65  0.45      0.15  \n",
       "0.70  0.37      0.11  \n",
       "0.75  0.28      0.07  \n",
       "0.80  0.20      0.05  \n",
       "0.85  0.13      0.03  \n",
       "0.90  0.07      0.01  \n",
       "0.95  0.02      0.00  \n",
       "1.00  0.00      0.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.01, 0.0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.2, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.4, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.5, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.6, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.7, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.8, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, 0.9, 0.91, 0.92, 0.93, 0.94, 0.95, 0.96, 0.97, 0.98, 0.99, 1.0]\n",
      "Plot_Prediction()\n",
      "BRFC_Hard_Tomek_0_alpha_0_5_v1_r_target_1_0_Test\n",
      "[0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
      "./Images/BRFC_Hard_Tomek_0_alpha_0_5_v1_r_target_1_0_Test_Pred.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x150 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Plot_Prediction()\n",
      "BRFC_Hard_Tomek_0_alpha_0_5_v1_r_target_1_0_Test\n",
      "[0.0, 0.04, 0.08, 0.12, 0.16, 0.2, 0.24, 0.28, 0.32, 0.36, 0.4, 0.44, 0.48, 0.52, 0.56, 0.6, 0.64, 0.68, 0.72, 0.76, 0.8, 0.84, 0.88, 0.92, 0.96, 1.0]\n",
      "./Images/BRFC_Hard_Tomek_0_alpha_0_5_v1_r_target_1_0_Test_Pred_Wide.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x150 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ROC()\n",
      "BRFC_Hard_Tomek_0_alpha_0_5_v1_r_target_1_0_Test\n",
      "p_values =  []\n",
      "./Images/BRFC_Hard_Tomek_0_alpha_0_5_v1_r_target_1_0_Test_ROC.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x150 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "CPU times: user 1min 18s, sys: 3.87 s, total: 1min 22s\n",
      "Wall time: 1min 24s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "Run_Models(Features = 'Hard', Tomek = 0, Version = 1, r_target = 1.0)\n",
    "#Run_Models(Features = 'Hard', Tomek = 0, Version = 1, r_target = 2.0)\n",
    "#Run_Models(Features = 'Hard', Tomek = 0, Version = 1, r_target = 3.0)\n",
    "#Run_Models(Features = 'Hard', Tomek = 1, Version = 1)\n",
    "#Run_Models(Features = 'Hard', Tomek = 2, Version = 1)\n",
    "#Run_Models(Features = 'Medium', Tomek = 0, Version = 1)\n",
    "#Run_Models(Features = 'Medium', Tomek = 1, Version = 1)\n",
    "#Run_Models(Features = 'Medium', Tomek = 2, Version = 1)\n",
    "#Run_Models(Features = 'Easy', Tomek = 0, Version = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a7b79ffa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1e+03 ns, sys: 4 µs, total: 5 µs\n",
      "Wall time: 6.91 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Run_Models(Features = 'Hard', Tomek = 0, Version = 2)\n",
    "#Run_Models(Features = 'Hard', Tomek = 1, Version = 2)\n",
    "#Run_Models(Features = 'Hard', Tomek = 2, Version = 2)\n",
    "#Run_Models(Features = 'Medium', Tomek = 0, Version = 2)\n",
    "#Run_Models(Features = 'Medium', Tomek = 1, Version = 2)\n",
    "#Run_Models(Features = 'Medium', Tomek = 2, Version = 2)\n",
    "#Run_Models(Features = 'Easy', Tomek = 0, Version = 2)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2658775",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "99d03591",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Henry_Run_Models(Features = 'Hard', Tomek = 0, Version = 1):\n",
    "    r_target = 3.0\n",
    "    alpha_target = r_target/(1+r_target)\n",
    "\n",
    "    if Features == 'Hard':\n",
    "        read_filename_features = '_Thin'\n",
    "        write_filename_features = '_Hard'\n",
    "    if Features == 'Medium':\n",
    "        read_filename_features = '_Really_Thin'\n",
    "        write_filename_features = '_Medium'\n",
    "    if Features == 'Easy':\n",
    "        read_filename_features = '_Thin_to_Minimal'\n",
    "        write_filename_features = '_Easy'\n",
    "    if Tomek==0:\n",
    "        read_filename_tomek = '_before_Tomek'\n",
    "        write_filename_tomek = '_Tomek_0'\n",
    "    if Tomek==1:\n",
    "        read_filename_tomek = '_after_Tomek'\n",
    "        write_filename_tomek = '_Tomek_1'\n",
    "    if Tomek==2:\n",
    "        read_filename_tomek = '_after_Tomek_Twice'\n",
    "        write_filename_tomek = '_Tomek_2'\n",
    "    if Version==1:\n",
    "        filename_version = '_v1'\n",
    "        random_seed = 0\n",
    "    if Version==2:\n",
    "        filename_version = '_v2'\n",
    "        random_seed = 42\n",
    "\n",
    "    X_train = pd.read_csv('../../Big_Files/X_train' + read_filename_features + read_filename_tomek + filename_version + '.csv')\n",
    "    y_train = pd.read_csv('../../Big_Files/y_train' + read_filename_features + read_filename_tomek + filename_version + '.csv').squeeze()\n",
    "    X_test = pd.read_csv('../../Big_Files/X_test' + read_filename_features + read_filename_tomek + filename_version + '.csv')\n",
    "    y_test = pd.read_csv('../../Big_Files/y_test' + read_filename_features + read_filename_tomek + filename_version + '.csv').squeeze()\n",
    "\n",
    "    N = len(y_train)\n",
    "    n = len(y_train[y_train==1])\n",
    "    p = (N-n)/n\n",
    "    alpha_balanced = p/(p+1)\n",
    "    print ('p = ', p)\n",
    "    print ('alpha_balanced = ', alpha_balanced)\n",
    "    \n",
    "\n",
    "    np.random.seed(random_seed) # NumPy\n",
    "    random.seed(random_seed) # Python\n",
    "    tf.random.set_seed(random_seed) # Tensorflow\n",
    "\n",
    "    print ()\n",
    "    print ('------------------------------------------')\n",
    "    filename_model = 'BRFC'\n",
    "    filename = filename_model + write_filename_features + write_filename_tomek + '_alpha_0_5' + filename_version + '_r_target_3'\n",
    "    title = 'BRForest'\n",
    "    Balanced_Random_Forest_Classifier(X_train, X_test, y_train, y_test, r_target, 0.5, filename, title)\n",
    "\n",
    "    np.random.seed(random_seed) # NumPy\n",
    "    random.seed(random_seed) # Python\n",
    "    tf.random.set_seed(random_seed) # Tensorflow\n",
    "    \n",
    "    print ()\n",
    "    print ('------------------------------------------')\n",
    "    filename_model = 'BRFC'\n",
    "    filename = filename_model + write_filename_features + write_filename_tomek + '_alpha_target' + filename_version + '_r_target_3'\n",
    "    title = 'BRForest'\n",
    "    Balanced_Random_Forest_Classifier(X_train, X_test, y_train, y_test, r_target, alpha_target, filename, title)\n",
    "\n",
    "    np.random.seed(random_seed) # NumPy\n",
    "    random.seed(random_seed) # Python\n",
    "    tf.random.set_seed(random_seed) # Tensorflow\n",
    "    \n",
    "    print ()\n",
    "    print ('------------------------------------------')\n",
    "    filename_model = 'BRFC'\n",
    "    filename = filename_model + write_filename_features + write_filename_tomek + '_alpha_balanced' + filename_version + '_r_target_3'\n",
    "    title = 'BRForest'\n",
    "    Balanced_Random_Forest_Classifier(X_train, X_test, y_train, y_test, r_target, alpha_balanced, filename, title)\n",
    "\n",
    "\n",
    "\n",
    "#Henry_Run_Models(Features = 'Hard', Tomek = 0, Version = 1)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8d5ea7d5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72178501",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow_2_11",
   "language": "python",
   "name": "tensorflow_2_11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
