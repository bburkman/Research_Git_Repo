{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c261718",
   "metadata": {},
   "source": [
    "- I tried to use Tensorflow, but \n",
    "    - I didn't understand how to access what was happening under the hood.  I like to run my fingers through the numbers, and I couldn't see them, so I think I had problems but couldn't find them, and\n",
    "    - I think Tensors make the operation too complicated for some of my imbalanced data techniques.\n",
    "- This attempt is really basic, an adaptation of the Keras example for structured data, \"Imbalanced Data: Credit Card Fraud Detection\" example at \n",
    "https://keras.io/examples/structured_data/imbalanced_classification/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "767154e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\tableofcontents\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\\tableofcontents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97e1d2b",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd7d47d",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "122b4fa5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Install Packages\n",
      "Python version: 3.10.9 | packaged by conda-forge | (main, Feb  2 2023, 20:26:08) [Clang 14.0.6 ]\n",
      "NumPy version: 1.24.2\n",
      "SciPy version:  1.7.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bburkman/miniforge3/envs/Tensorflow_2_11/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version:  2.11.0\n",
      "Keras version:  2.11.0\n",
      "Pandas version:  1.5.3\n",
      "SciKit-Learn version: 1.2.2\n",
      "Imbalanced-Learn version: 0.10.1\n",
      "Finished Installing Packages\n"
     ]
    }
   ],
   "source": [
    "print ('Install Packages')\n",
    "\n",
    "import sys, copy, math, time, os\n",
    "\n",
    "print ('Python version: {}'.format(sys.version))\n",
    "\n",
    "#from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "print ('NumPy version: {}'.format(np.__version__))\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "import scipy as sc\n",
    "print ('SciPy version:  {}'.format(sc.__version__))\n",
    "\n",
    "import tensorflow as tf\n",
    "print ('TensorFlow version:  {}'.format(tf.__version__))\n",
    "tf.config.run_functions_eagerly(True)\n",
    "tf.data.experimental.enable_debug_mode()\n",
    "\n",
    "from tensorflow import keras\n",
    "print ('Keras version:  {}'.format(keras.__version__))\n",
    "\n",
    "from keras import layers\n",
    "import keras.backend as K\n",
    "from keras.layers import IntegerLookup\n",
    "from keras.layers import Normalization\n",
    "from keras.layers import StringLookup\n",
    "from keras.utils import get_custom_objects\n",
    "from keras.utils import tf_utils\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "#from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "import pandas as pd\n",
    "print ('Pandas version:  {}'.format(pd.__version__))\n",
    "pd.set_option('display.max_rows', 500)\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use(\"pgf\")\n",
    "matplotlib.rcParams.update({\n",
    "#    \"pgf.texsystem\": \"pdflatex\",\n",
    "    'font.family': 'serif',\n",
    "    'text.usetex': True,\n",
    "    'pgf.rcfonts': False,\n",
    "})\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Library for reading Microsoft Access files\n",
    "#import pandas_access as mdb\n",
    "\n",
    "import sklearn\n",
    "print ('SciKit-Learn version: {}'.format(sklearn.__version__))\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import imblearn\n",
    "print ('Imbalanced-Learn version: {}'.format(imblearn.__version__))\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from imblearn.under_sampling import CondensedNearestNeighbour\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from imblearn.ensemble import RUSBoostClassifier\n",
    "from imblearn.ensemble import EasyEnsembleClassifier\n",
    "\n",
    "#!pip install pydot\n",
    "\n",
    "# Set Randomness.  Copied from https://www.kaggle.com/code/abazdyrev/keras-nn-focal-loss-experiments\n",
    "import random\n",
    "#np.random.seed(42) # NumPy\n",
    "#random.seed(42) # Python\n",
    "#tf.random.set_seed(42) # Tensorflow\n",
    "\n",
    "print ('Finished Installing Packages')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0437f109",
   "metadata": {},
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "919fb2db",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get_Data()\n",
      "data.shape:  (619027, 82)\n",
      "End Get_Data()\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CASENUM</th>\n",
       "      <th>INT_HWY</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>PEDS</th>\n",
       "      <th>PERMVIT</th>\n",
       "      <th>REL_ROAD</th>\n",
       "      <th>SCH_BUS</th>\n",
       "      <th>URBANICITY</th>\n",
       "      <th>VE_TOTAL</th>\n",
       "      <th>DAY_WEEK</th>\n",
       "      <th>...</th>\n",
       "      <th>RELJCT2</th>\n",
       "      <th>REST_USE</th>\n",
       "      <th>AIR_BAG</th>\n",
       "      <th>TYP_INT</th>\n",
       "      <th>VSPD_LIM</th>\n",
       "      <th>VPROFILE</th>\n",
       "      <th>ALC_RES</th>\n",
       "      <th>ALC_STATUS</th>\n",
       "      <th>VEH_ALCH</th>\n",
       "      <th>VTRAFWAY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201701219525</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201800450781</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201901811861</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201701360851</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201901343065</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CASENUM  INT_HWY  MONTH  PEDS  PERMVIT  REL_ROAD  SCH_BUS  URBANICITY  \\\n",
       "0  201701219525        0      0     0        1         1        0           1   \n",
       "1  201800450781        0      0     0        0         0        0           2   \n",
       "2  201901811861        0      2     0        0         2        0           1   \n",
       "3  201701360851        0      1     0        1         1        0           1   \n",
       "4  201901343065        0      0     0        1         1        0           1   \n",
       "\n",
       "   VE_TOTAL  DAY_WEEK  ...  RELJCT2  REST_USE  AIR_BAG  TYP_INT  VSPD_LIM  \\\n",
       "0         2         1  ...        1         1        1        1         2   \n",
       "1         1         1  ...        1         1        1        1         7   \n",
       "2         2         1  ...        1         1        1        1         7   \n",
       "3         2         0  ...        1         1        1        1         2   \n",
       "4         2         0  ...        1         1        1        1         2   \n",
       "\n",
       "   VPROFILE  ALC_RES  ALC_STATUS  VEH_ALCH  VTRAFWAY  \n",
       "0         1        0           1         1         0  \n",
       "1         1        0           1         1         0  \n",
       "2         1        0           1         1         0  \n",
       "3         1        0           1         1         0  \n",
       "4         1        0           1         1         0  \n",
       "\n",
       "[5 rows x 82 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def Get_Data():\n",
    "    print ('Get_Data()')\n",
    "    data = pd.read_csv(\n",
    "        '../../Big_Files/CRSS_Imputed_All_12_22_22.csv',\n",
    "        low_memory=False\n",
    "    )\n",
    "    print ('data.shape: ', data.shape)\n",
    "    \n",
    "    print ('End Get_Data()')\n",
    "    print ()\n",
    "    return data\n",
    "\n",
    "def Test_Get_Data():\n",
    "    data = Get_Data()\n",
    "    display (data.head())\n",
    "    \n",
    "Test_Get_Data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d540640",
   "metadata": {},
   "source": [
    "# Remove_Pedestrian_Crashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac62df2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Remove_Pedestrian_Crashes(data):\n",
    "    print ('Remove_Pedestrian_Crashes()')\n",
    "    display(data.PEDS.value_counts())\n",
    "    n = len(data[data.PEDS>0])\n",
    "    print ('Removing %d crashes that involve a pedestrian.' % n)\n",
    "    data = data[data.PEDS==0]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adb9dce",
   "metadata": {},
   "source": [
    "## Engineer Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e85fa858",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Feature_Engineering_Cross_Two(data):\n",
    "    print ('Feature_Engineering_Cross_Two')\n",
    "    Pairs = [\n",
    "        ['AGE', 'SEX', 'AGE_x_SEX'],\n",
    "        ['AGE', 'SCH_BUS', 'AGE_x_SCH_BUS']\n",
    "    ]\n",
    "    for P in Pairs:\n",
    "        data[P[2]] = data[P[0]].map(str) + '_x_' + data[P[1]].map(str)\n",
    "    \n",
    "    print ()\n",
    "    return data\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b900000",
   "metadata": {},
   "source": [
    "## Thin Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86a0c76b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get_Data()\n",
      "data.shape:  (619027, 82)\n",
      "End Get_Data()\n",
      "\n",
      "Thin_Features()\n",
      "data.shape:  (619027, 38)\n",
      "End Thin_Features()\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2    395203\n",
       "3    111949\n",
       "0     47951\n",
       "1     42134\n",
       "4     21790\n",
       "Name: AGE, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1    221301\n",
       "5    153085\n",
       "3     92952\n",
       "2     59376\n",
       "0     46961\n",
       "4     45352\n",
       "Name: BODY_TYP, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1    616201\n",
       "2      2699\n",
       "0       127\n",
       "Name: BUS_USE, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1    465260\n",
       "0    153767\n",
       "Name: DAY_WEEK, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1    617091\n",
       "0      1186\n",
       "2       750\n",
       "Name: EMER_USE, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    529840\n",
       "1     89187\n",
       "Name: HOSPITAL, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "3    165476\n",
       "2    150963\n",
       "1    106547\n",
       "4     73637\n",
       "5     59088\n",
       "6     40804\n",
       "0     22512\n",
       "Name: HOUR, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    555566\n",
       "1     63461\n",
       "Name: INT_HWY, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "3    445496\n",
       "1    108465\n",
       "0     50350\n",
       "2     14716\n",
       "Name: LGT_COND, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "8    135069\n",
       "0    121558\n",
       "1     86857\n",
       "6     81273\n",
       "2     76578\n",
       "4     71217\n",
       "7     24997\n",
       "3     12328\n",
       "5      9150\n",
       "Name: MAKE, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1    145569\n",
       "4    136958\n",
       "3    122451\n",
       "2    112129\n",
       "0    101920\n",
       "Name: MODEL, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2    216711\n",
       "1    208215\n",
       "0    194101\n",
       "Name: MONTH, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "3    348269\n",
       "1    147867\n",
       "5     62203\n",
       "6     51666\n",
       "2      6974\n",
       "0      1565\n",
       "4       483\n",
       "Name: NUMOCCS, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2    348822\n",
       "1    200622\n",
       "0     69583\n",
       "Name: PERMVIT, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    589234\n",
       "1     29793\n",
       "Name: PERNOTMVIT, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2    456292\n",
       "1    162609\n",
       "0       126\n",
       "Name: PER_TYP, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "4    126842\n",
       "2    124293\n",
       "1    124066\n",
       "3    123780\n",
       "0    120046\n",
       "Name: PJ, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "3    134421\n",
       "4    132084\n",
       "0    118700\n",
       "2    118444\n",
       "1    115378\n",
       "Name: PSU, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    603745\n",
       "1     15282\n",
       "Name: PVH_INVL, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "3    336845\n",
       "2    109989\n",
       "4    102472\n",
       "1     69721\n",
       "Name: REGION, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    437984\n",
       "8    161319\n",
       "1     19460\n",
       "9       264\n",
       "Name: RELJCT1, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1    251423\n",
       "0    168063\n",
       "3    146673\n",
       "2     52868\n",
       "Name: RELJCT2, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1    549305\n",
       "0     60920\n",
       "2      8802\n",
       "Name: REL_ROAD, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    615928\n",
       "1      3099\n",
       "Name: SCH_BUS, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1    345482\n",
       "0    273545\n",
       "Name: SEX, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1    343683\n",
       "2    204623\n",
       "0     66083\n",
       "3      4638\n",
       "Name: TYP_INT, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1    481918\n",
       "2    137109\n",
       "Name: URBANICITY, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1    555113\n",
       "0     48321\n",
       "2     15593\n",
       "Name: VALIGN, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.0    199282\n",
       "1.0    155216\n",
       "2.0    132304\n",
       "3.0     90266\n",
       "4.0     41959\n",
       "Name: VEH_AGE, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2    423804\n",
       "1    107796\n",
       "3     65694\n",
       "4     21733\n",
       "Name: VE_FORMS, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2    431474\n",
       "1     95724\n",
       "3     68682\n",
       "4     23147\n",
       "Name: VE_TOTAL, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1    528304\n",
       "2     58774\n",
       "0     31949\n",
       "Name: VPROFILE, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2    170164\n",
       "7    134614\n",
       "5    102842\n",
       "1     81817\n",
       "4     60440\n",
       "0     58578\n",
       "3     10572\n",
       "Name: VSPD_LIM, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1    400366\n",
       "2    144639\n",
       "3     62181\n",
       "0     11841\n",
       "Name: VTRAFCON, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    336731\n",
       "3    122470\n",
       "1     87216\n",
       "4     43374\n",
       "2     29236\n",
       "Name: VTRAFWAY, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1    461159\n",
       "3     89628\n",
       "2     54953\n",
       "4     10500\n",
       "0      2787\n",
       "Name: WEATHER, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    606925\n",
       "1     11193\n",
       "2       750\n",
       "3       159\n",
       "Name: WRK_ZONE, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2017    133408\n",
       "2019    129980\n",
       "2020    126460\n",
       "2018    115774\n",
       "2016    113405\n",
       "Name: YEAR, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def Thin_Features(data):\n",
    "    print ('Thin_Features()')\n",
    "\n",
    "    Merge = [\n",
    "        'CASENUM',\n",
    "        'VEH_NO',\n",
    "        'PER_NO',        \n",
    "    ]\n",
    "\n",
    "    Accident = [\n",
    "        'DAY_WEEK',\n",
    "        'HOUR',\n",
    "        'INT_HWY',\n",
    "        'LGT_COND',\n",
    "        'MONTH',\n",
    "#        'PEDS',\n",
    "        'PERMVIT',\n",
    "        'PERNOTMVIT',\n",
    "        'PJ',\n",
    "        'PSU',\n",
    "        'PVH_INVL',\n",
    "        'REGION',\n",
    "        'REL_ROAD',\n",
    "        'RELJCT1',\n",
    "        'RELJCT2',\n",
    "        'SCH_BUS',\n",
    "        'TYP_INT',\n",
    "        'URBANICITY',\n",
    "        'VE_FORMS',\n",
    "        'VE_TOTAL',\n",
    "        'WEATHER',\n",
    "        'WRK_ZONE',\n",
    "        'YEAR',\n",
    "    ]\n",
    "    \n",
    "    Vehicle = [\n",
    "        'BODY_TYP',\n",
    "        'BUS_USE',\n",
    "        'EMER_USE',\n",
    "        'MAKE',\n",
    "#        'MOD_YEAR',\n",
    "        'MODEL',\n",
    "        'NUMOCCS',\n",
    "        'VALIGN',\n",
    "        'VNUM_LAN',\n",
    "        'VPROFILE',\n",
    "        'VSPD_LIM',\n",
    "#        'VSURCOND',\n",
    "        'VTRAFCON',\n",
    "        'VTRAFWAY',\n",
    "    ]\n",
    "    \n",
    "    Person = [\n",
    "        'AGE',\n",
    "        'LOCATION',\n",
    "        'PER_TYP',\n",
    "        'SEX',\n",
    "        'HOSPITAL',    \n",
    "    ]\n",
    "\n",
    "    Engineered = [\n",
    "        'VEH_AGE',\n",
    "        'AGE_x_SEX',\n",
    "        'AGE_x_SCH_BUS'\n",
    "    ]\n",
    "    \n",
    "    # Put features in alphabetical order\n",
    "    Features = Accident + Vehicle + Person + Engineered\n",
    "    Features = sorted(Features)\n",
    "#    Features = Merge + Features\n",
    "    \n",
    "    data = data.filter(Features, axis=1)\n",
    "    \n",
    "    print ('data.shape: ', data.shape)\n",
    "    \n",
    "    print ('End Thin_Features()')\n",
    "    print ()\n",
    "        \n",
    "    return data\n",
    "\n",
    "def Test_Thin_Features():\n",
    "    data = Get_Data()\n",
    "    data = Thin_Features(data)\n",
    "    for feature in data:\n",
    "        display(data[feature].value_counts())\n",
    "        \n",
    "Test_Thin_Features()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e759eda",
   "metadata": {},
   "source": [
    "## Really Thin Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4202cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get_Data()\n",
      "data.shape:  (619027, 82)\n",
      "End Get_Data()\n",
      "\n",
      "Thin_Features()\n",
      "data.shape:  (619027, 38)\n",
      "End Thin_Features()\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2    395203\n",
       "3    111949\n",
       "0     47951\n",
       "1     42134\n",
       "4     21790\n",
       "Name: AGE, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1    221301\n",
       "5    153085\n",
       "3     92952\n",
       "2     59376\n",
       "0     46961\n",
       "4     45352\n",
       "Name: BODY_TYP, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1    616201\n",
       "2      2699\n",
       "0       127\n",
       "Name: BUS_USE, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1    465260\n",
       "0    153767\n",
       "Name: DAY_WEEK, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1    617091\n",
       "0      1186\n",
       "2       750\n",
       "Name: EMER_USE, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    529840\n",
       "1     89187\n",
       "Name: HOSPITAL, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "3    165476\n",
       "2    150963\n",
       "1    106547\n",
       "4     73637\n",
       "5     59088\n",
       "6     40804\n",
       "0     22512\n",
       "Name: HOUR, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    555566\n",
       "1     63461\n",
       "Name: INT_HWY, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "3    445496\n",
       "1    108465\n",
       "0     50350\n",
       "2     14716\n",
       "Name: LGT_COND, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "8    135069\n",
       "0    121558\n",
       "1     86857\n",
       "6     81273\n",
       "2     76578\n",
       "4     71217\n",
       "7     24997\n",
       "3     12328\n",
       "5      9150\n",
       "Name: MAKE, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1    145569\n",
       "4    136958\n",
       "3    122451\n",
       "2    112129\n",
       "0    101920\n",
       "Name: MODEL, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2    216711\n",
       "1    208215\n",
       "0    194101\n",
       "Name: MONTH, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "3    348269\n",
       "1    147867\n",
       "5     62203\n",
       "6     51666\n",
       "2      6974\n",
       "0      1565\n",
       "4       483\n",
       "Name: NUMOCCS, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2    348822\n",
       "1    200622\n",
       "0     69583\n",
       "Name: PERMVIT, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    589234\n",
       "1     29793\n",
       "Name: PERNOTMVIT, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2    456292\n",
       "1    162609\n",
       "0       126\n",
       "Name: PER_TYP, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "4    126842\n",
       "2    124293\n",
       "1    124066\n",
       "3    123780\n",
       "0    120046\n",
       "Name: PJ, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "3    134421\n",
       "4    132084\n",
       "0    118700\n",
       "2    118444\n",
       "1    115378\n",
       "Name: PSU, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    603745\n",
       "1     15282\n",
       "Name: PVH_INVL, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "3    336845\n",
       "2    109989\n",
       "4    102472\n",
       "1     69721\n",
       "Name: REGION, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    437984\n",
       "8    161319\n",
       "1     19460\n",
       "9       264\n",
       "Name: RELJCT1, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1    251423\n",
       "0    168063\n",
       "3    146673\n",
       "2     52868\n",
       "Name: RELJCT2, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1    549305\n",
       "0     60920\n",
       "2      8802\n",
       "Name: REL_ROAD, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    615928\n",
       "1      3099\n",
       "Name: SCH_BUS, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1    345482\n",
       "0    273545\n",
       "Name: SEX, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1    343683\n",
       "2    204623\n",
       "0     66083\n",
       "3      4638\n",
       "Name: TYP_INT, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1    481918\n",
       "2    137109\n",
       "Name: URBANICITY, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1    555113\n",
       "0     48321\n",
       "2     15593\n",
       "Name: VALIGN, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.0    199282\n",
       "1.0    155216\n",
       "2.0    132304\n",
       "3.0     90266\n",
       "4.0     41959\n",
       "Name: VEH_AGE, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2    423804\n",
       "1    107796\n",
       "3     65694\n",
       "4     21733\n",
       "Name: VE_FORMS, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2    431474\n",
       "1     95724\n",
       "3     68682\n",
       "4     23147\n",
       "Name: VE_TOTAL, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1    528304\n",
       "2     58774\n",
       "0     31949\n",
       "Name: VPROFILE, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2    170164\n",
       "7    134614\n",
       "5    102842\n",
       "1     81817\n",
       "4     60440\n",
       "0     58578\n",
       "3     10572\n",
       "Name: VSPD_LIM, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1    400366\n",
       "2    144639\n",
       "3     62181\n",
       "0     11841\n",
       "Name: VTRAFCON, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    336731\n",
       "3    122470\n",
       "1     87216\n",
       "4     43374\n",
       "2     29236\n",
       "Name: VTRAFWAY, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1    461159\n",
       "3     89628\n",
       "2     54953\n",
       "4     10500\n",
       "0      2787\n",
       "Name: WEATHER, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    606925\n",
       "1     11193\n",
       "2       750\n",
       "3       159\n",
       "Name: WRK_ZONE, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2017    133408\n",
       "2019    129980\n",
       "2020    126460\n",
       "2018    115774\n",
       "2016    113405\n",
       "Name: YEAR, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def Really_Thin_Features(data):\n",
    "    print ('Really_Thin_Features()')\n",
    "\n",
    "    Merge = [\n",
    "        'CASENUM',\n",
    "        'VEH_NO',\n",
    "        'PER_NO',        \n",
    "    ]\n",
    "\n",
    "    Accident = [\n",
    "        'DAY_WEEK',\n",
    "        'HOUR',\n",
    "        'INT_HWY',\n",
    "#        'LGT_COND',\n",
    "        'MONTH',\n",
    "#        'PEDS',\n",
    "#        'PERMVIT',\n",
    "#        'PERNOTMVIT',\n",
    "        'PJ',\n",
    "        'PSU',\n",
    "#        'PVH_INVL',\n",
    "        'REGION',\n",
    "        'REL_ROAD',\n",
    "        'RELJCT1',\n",
    "#        'RELJCT2',\n",
    "#        'SCH_BUS',\n",
    "        'TYP_INT',\n",
    "        'URBANICITY',\n",
    "#        'VE_FORMS',\n",
    "#        'VE_TOTAL',\n",
    "        'WEATHER',\n",
    "#        'WRK_ZONE',\n",
    "        'YEAR',\n",
    "    ]\n",
    "    \n",
    "    Vehicle = [\n",
    "#        'BODY_TYP',\n",
    "#        'BUS_USE',\n",
    "#        'EMER_USE',\n",
    "#        'MAKE',\n",
    "#        'MOD_YEAR',\n",
    "#        'MODEL',\n",
    "#        'NUMOCCS',\n",
    "        'VALIGN',\n",
    "        'VNUM_LAN',\n",
    "        'VPROFILE',\n",
    "        'VSPD_LIM',\n",
    "#        'VSURCOND',\n",
    "        'VTRAFCON',\n",
    "        'VTRAFWAY',\n",
    "    ]\n",
    "    \n",
    "    Person = [\n",
    "        'AGE',\n",
    "#        'LOCATION',\n",
    "#        'PER_TYP',\n",
    "        'SEX',\n",
    "        'HOSPITAL',    \n",
    "    ]\n",
    "\n",
    "    Engineered = [\n",
    "#        'VEH_AGE',\n",
    "        'AGE_x_SEX',\n",
    "#        'AGE_x_SCH_BUS'\n",
    "    ]\n",
    "    \n",
    "    # Put features in alphabetical order\n",
    "    Features = Accident + Vehicle + Person + Engineered\n",
    "    Features = sorted(Features)\n",
    "#    Features = Merge + Features\n",
    "    \n",
    "    data = data.filter(Features, axis=1)\n",
    "    \n",
    "    print ('data.shape: ', data.shape)\n",
    "    \n",
    "    print ('End Thin_Features()')\n",
    "    print ()\n",
    "        \n",
    "    return data\n",
    "\n",
    "def Test_Really_Thin_Features():\n",
    "    data = Get_Data()\n",
    "    data = Really_Thin_Features(data)\n",
    "    for feature in data:\n",
    "        display(data[feature].value_counts())\n",
    "        \n",
    "Test_Thin_Features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11264ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get_Data()\n",
      "data.shape:  (619027, 82)\n",
      "End Get_Data()\n",
      "\n",
      "Thin_to_Minimal_Features()\n",
      "data.shape:  (619027, 10)\n",
      "End Thin_Features()\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    465260\n",
       "0    153767\n",
       "Name: DAY_WEEK, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    529840\n",
       "1     89187\n",
       "Name: HOSPITAL, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "3    165476\n",
       "2    150963\n",
       "1    106547\n",
       "4     73637\n",
       "5     59088\n",
       "6     40804\n",
       "0     22512\n",
       "Name: HOUR, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2    216711\n",
       "1    208215\n",
       "0    194101\n",
       "Name: MONTH, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "4    126842\n",
       "2    124293\n",
       "1    124066\n",
       "3    123780\n",
       "0    120046\n",
       "Name: PJ, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "3    134421\n",
       "4    132084\n",
       "0    118700\n",
       "2    118444\n",
       "1    115378\n",
       "Name: PSU, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "3    336845\n",
       "2    109989\n",
       "4    102472\n",
       "1     69721\n",
       "Name: REGION, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1    481918\n",
       "2    137109\n",
       "Name: URBANICITY, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1    461159\n",
       "3     89628\n",
       "2     54953\n",
       "4     10500\n",
       "0      2787\n",
       "Name: WEATHER, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2017    133408\n",
       "2019    129980\n",
       "2020    126460\n",
       "2018    115774\n",
       "2016    113405\n",
       "Name: YEAR, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def Thin_to_Minimal_Features(data):\n",
    "    print ('Thin_to_Minimal_Features()')\n",
    "\n",
    "    Accident = [\n",
    "        'DAY_WEEK',\n",
    "        'HOUR',\n",
    "#        'INT_HWY',\n",
    "#        'LGT_COND',\n",
    "        'MONTH',\n",
    "#        'PEDS',\n",
    "#        'PERMVIT',\n",
    "#        'PERNOTMVIT',\n",
    "        'PJ',\n",
    "        'PSU',\n",
    "#        'PVH_INVL',\n",
    "        'REGION',\n",
    "#        'REL_ROAD',\n",
    "#        'RELJCT1',\n",
    "#        'RELJCT2',\n",
    "#        'SCH_BUS',\n",
    "#        'TYP_INT',\n",
    "        'URBANICITY',\n",
    "#        'VE_FORMS',\n",
    "#        'VE_TOTAL',\n",
    "        'WEATHER',\n",
    "#        'WRK_ZONE',\n",
    "        'YEAR',\n",
    "    ]\n",
    "    \n",
    "    Vehicle = [\n",
    "#        'BODY_TYP',\n",
    "#        'BUS_USE',\n",
    "#        'EMER_USE',\n",
    "#        'MAKE',\n",
    "#        'MOD_YEAR',\n",
    "#        'MODEL',\n",
    "#        'NUMOCCS',\n",
    "#        'VALIGN',\n",
    "#        'VNUM_LAN',\n",
    "#        'VPROFILE',\n",
    "#        'VSPD_LIM',\n",
    "#        'VSURCOND',\n",
    "#        'VTRAFCON',\n",
    "#        'VTRAFWAY',\n",
    "    ]\n",
    "    \n",
    "    Person = [\n",
    "#        'AGE',\n",
    "#        'LOCATION',\n",
    "#        'PER_TYP',\n",
    "#        'SEX',\n",
    "        'HOSPITAL',    \n",
    "    ]\n",
    "\n",
    "    Engineered = [\n",
    "#        'VEH_AGE',\n",
    "#        'AGE_x_SEX',\n",
    "#        'AGE_x_SCH_BUS'\n",
    "    ]\n",
    "    \n",
    "    # Put features in alphabetical order\n",
    "    Features = Accident + Vehicle + Person + Engineered\n",
    "    Features = sorted(Features)\n",
    "#    Features = Merge + Features\n",
    "    \n",
    "    data = data.filter(Features, axis=1)\n",
    "    \n",
    "    print ('data.shape: ', data.shape)\n",
    "    \n",
    "    print ('End Thin_Features()')\n",
    "    print ()\n",
    "        \n",
    "    return data\n",
    "\n",
    "def Test_Thin_to_Minimal_Features():\n",
    "    data = Get_Data()\n",
    "    data = Thin_to_Minimal_Features(data)\n",
    "    for feature in data:\n",
    "        display(data[feature].value_counts())\n",
    "        \n",
    "Test_Thin_to_Minimal_Features()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52366e1a",
   "metadata": {},
   "source": [
    "## Get Dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47cefa1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_Get_Dummies\n",
      "Get_Dummies\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A_a</th>\n",
       "      <th>A_b</th>\n",
       "      <th>B_a</th>\n",
       "      <th>B_b</th>\n",
       "      <th>B_c</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A_a  A_b  B_a  B_b  B_c  C\n",
       "0    1    0    0    1    0  1\n",
       "1    0    1    1    0    0  2\n",
       "2    1    0    0    0    1  3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def Get_Dummies(data, target):\n",
    "    print ('Get_Dummies')\n",
    "    data = data.astype('category')\n",
    "    Target = data.pop(target)\n",
    "    data_Dummies = pd.get_dummies(data, prefix = data.columns)\n",
    "    data_Dummies = data_Dummies.join(Target)\n",
    "#    for feature in data_Dummies:\n",
    "#        print (feature)\n",
    "    print ()\n",
    "\n",
    "    return data_Dummies\n",
    "\n",
    "def Test_Get_Dummies():\n",
    "    print ('Test_Get_Dummies')\n",
    "    A = pd.DataFrame({\n",
    "        'A': ['a', 'b', 'a'], \n",
    "        'B': ['b', 'a', 'c'], \n",
    "        'C': [1, 2, 3]})\n",
    "    C = Get_Dummies(A, 'C')\n",
    "    display(C)\n",
    "    print ()\n",
    "\n",
    "Test_Get_Dummies()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d43d6e",
   "metadata": {},
   "source": [
    "## Test-Train Split\n",
    "- We're using sklearn's train_test_split rather than Pandas's sample because the former has a 'stratify' option that will put the same proportion of HOSPITAL==1 into each set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "490cfcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Split_Data(data, target, test_size):\n",
    "    print ('Split_Data()')\n",
    "    X = data.drop(columns=[target])\n",
    "    y = data[target]\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        X, y, stratify=y, test_size=test_size, \n",
    "        #random_state=42\n",
    "    )\n",
    "    \n",
    "    a = y_train[y_train==1].shape[0]\n",
    "    b = y_test[y_test==1].shape[0]\n",
    "    print (\n",
    "        x_train.shape, \n",
    "        y_train.shape, a, round((a/(a+b)*100),2), '%')\n",
    "    print (\n",
    "        x_test.shape, \n",
    "        y_test.shape, b, round((b/(a+b)*100),2), '%'\n",
    "    )\n",
    "    print ()\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7b22f0",
   "metadata": {},
   "source": [
    "# Imbalanced Data Resampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e984f24a",
   "metadata": {},
   "source": [
    "## Tomek Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5a61c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Tomek_Links(X_train, y_train):\n",
    "    print ('Tomek_Links()')\n",
    "    M = len(y_train)\n",
    "    N = len(y_train)\n",
    "    n = len(y_train[y_train==1])\n",
    "    p = (N-n)/n\n",
    "    print ('Before Tomek Links:')\n",
    "    print ('%d samples, %d hospitalized, %d not hospitalized' % (N, n, N-n))\n",
    "    print ('%f percent of samples hospitalized' % (n/N*100))\n",
    "    print ('There are %f negative samples for each positive.' % ((N-n)/n))\n",
    "    print ()\n",
    "\n",
    "    X_train, y_train = TomekLinks().fit_resample(X_train, y_train)\n",
    "    N = len(y_train)\n",
    "    n = len(y_train[y_train==1])\n",
    "    p = (N-n)/n\n",
    "    print ('After Tomek Links:')\n",
    "    print ('%d samples, %d hospitalized, %d not hospitalized' % (N, n, N-n))\n",
    "    print ('%f percent of samples hospitalized' % (n/N*100))\n",
    "    print ('There are %f negative samples for each positive.' % ((N-n)/n))\n",
    "    print ('Removed %d samples, or %.2f%% of the set.' % (M-N, (M-N)/M*100))\n",
    "    print ()\n",
    "    \n",
    "    return X_train, y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ce9a6e",
   "metadata": {},
   "source": [
    "## Condensed Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05cfb8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Condensed_Nearest_Neighbour(X_train, y_train):\n",
    "    print ('Condensed_Nearest_Neighbour()')\n",
    "    N = X_train.shape[0]\n",
    "    print ('X_train.shape before = ', X_train.shape)\n",
    "    print ('y_train.shape before = ', y_train.shape)\n",
    "    print ()\n",
    "    cnn = CondensedNearestNeighbour(n_neighbors=None)\n",
    "    X_train, y_train = cnn.fit_resample(X_train, y_train)\n",
    "    n = X_train.shape[0]\n",
    "    print ('X_train.shape after = ', X_train.shape)\n",
    "    print ('y_train.shape after = ', y_train.shape)\n",
    "    print ()\n",
    "    print ('Removed %d samples, or %.2f%% of the set.' % (N-n, (N-n)/N*100))\n",
    "    print ()\n",
    "    \n",
    "    return X_train, y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bdd5a1",
   "metadata": {},
   "source": [
    "# Undersample Data\n",
    "- These functions take the three versions of the dataset, which correspond to these names in the paper:\n",
    "    - Thin (Hard)\n",
    "    - Really_Thin (Medium)\n",
    "    - Thin_to_Minimum (Easy)\n",
    "- runs Tomek Links on them once, then again, and saves the results to file.\n",
    "- Each of the three sets takes about 90 minutes to run on my laptop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8628b43",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
      "Wall time: 4.77 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def Undersample_Data_Thin(round_text):\n",
    "    print ('Undersample_Data_Thin()')\n",
    "    data = Get_Data()\n",
    "    data = data.astype('int64')\n",
    "    target = 'HOSPITAL'\n",
    "    data = Remove_Pedestrian_Crashes(data)\n",
    "    data = Feature_Engineering_Cross_Two(data)\n",
    "    data = Thin_Features(data)\n",
    "    data = Get_Dummies(data, target)\n",
    "\n",
    "    # Decrease set size, for debugging\n",
    "#    X_train, X_test, y_train, y_test = Split_Data(data, target, 0.80)\n",
    "#    data = X_train\n",
    "#    data[target] = y_train\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = Split_Data(data, target, 0.30)\n",
    "\n",
    "    # CNN took 6 minutes at 99% decreased set size.  \n",
    "#    X_train, y_train = Condensed_Nearest_Neighbour(X_train, y_train)\n",
    "\n",
    "    X_train.to_csv('../../Big_Files/X_train_Thin_before_Tomek' + round_text + '.csv', index=False)\n",
    "    y_train.to_csv('../../Big_Files/y_train_Thin_before_Tomek' + round_text + '.csv', index=False)\n",
    "    X_test.to_csv('../../Big_Files/X_test_Thin_before_Tomek' + round_text + '.csv', index=False)\n",
    "    y_test.to_csv('../../Big_Files/y_test_Thin_before_Tomek' + round_text + '.csv', index=False)\n",
    "\n",
    "    # Two rounds of Tomek took one hour 30 minutes\n",
    "    X_train, y_train = Tomek_Links(X_train, y_train)\n",
    "    # Write to csv and read back in, \n",
    "    #    so we can play with the stuff later without having to redo the Tomek Links, \n",
    "    #    which can take a long time.\n",
    "    X_train.to_csv('../../Big_Files/X_train_Thin_after_Tomek' + round_text + '.csv', index=False)\n",
    "    y_train.to_csv('../../Big_Files/y_train_Thin_after_Tomek' + round_text + '.csv', index=False)\n",
    "    X_test.to_csv('../../Big_Files/X_test_Thin_after_Tomek' + round_text + '.csv', index=False)\n",
    "    y_test.to_csv('../../Big_Files/y_test_Thin_after_Tomek' + round_text + '.csv', index=False)\n",
    "\n",
    "\n",
    "    X_train, y_train = Tomek_Links(X_train, y_train)\n",
    "    X_train.to_csv('../../Big_Files/X_train_Thin_after_Tomek_Twice' + round_text + '.csv', index=False)\n",
    "    y_train.to_csv('../../Big_Files/y_train_Thin_after_Tomek_Twice' + round_text + '.csv', index=False)\n",
    "    X_test.to_csv('../../Big_Files/X_test_Thin_after_Tomek_Twice' + round_text + '.csv', index=False)\n",
    "    y_test.to_csv('../../Big_Files/y_test_Thin_after_Tomek_Twice' + round_text + '.csv', index=False)\n",
    "    print ()\n",
    "    \n",
    "def Undersample_Data_Really_Thin(round_text):\n",
    "    print ('Undersample_Data_Really_Thin()')\n",
    "\n",
    "    data = Get_Data()\n",
    "    data = data.astype('int64')\n",
    "    target = 'HOSPITAL'\n",
    "    data = Remove_Pedestrian_Crashes(data)\n",
    "    data = Feature_Engineering_Cross_Two(data)\n",
    "    data = Really_Thin_Features(data)\n",
    "    data = Get_Dummies(data, target)\n",
    "\n",
    "    # Decrease set size, for debugging\n",
    "#    X_train, X_test, y_train, y_test = Split_Data(data, target, 0.80)\n",
    "#    data = X_train\n",
    "#    data[target] = y_train\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = Split_Data(data, target, 0.30)\n",
    "\n",
    "    # CNN took 6 minutes at 99% decreased set size.  \n",
    "#    X_train, y_train = Condensed_Nearest_Neighbour(X_train, y_train)\n",
    "\n",
    "    X_train.to_csv('../../Big_Files/X_train_Really_Thin_before_Tomek' + round_text + '.csv', index=False)\n",
    "    y_train.to_csv('../../Big_Files/y_train_Really_Thin_before_Tomek' + round_text + '.csv', index=False)\n",
    "    X_test.to_csv('../../Big_Files/X_test_Really_Thin_before_Tomek' + round_text + '.csv', index=False)\n",
    "    y_test.to_csv('../../Big_Files/y_test_Really_Thin_before_Tomek' + round_text + '.csv', index=False)\n",
    "\n",
    "    # Two rounds of Tomek took one hour 30 minutes\n",
    "    X_train, y_train = Tomek_Links(X_train, y_train)\n",
    "    # Write to csv and read back in, \n",
    "    #    so we can play with the stuff later without having to redo the Tomek Links, \n",
    "    #    which can take a long time.\n",
    "    X_train.to_csv('../../Big_Files/X_train_Really_Thin_after_Tomek' + round_text + '.csv', index=False)\n",
    "    y_train.to_csv('../../Big_Files/y_train_Really_Thin_after_Tomek' + round_text + '.csv', index=False)\n",
    "    X_test.to_csv('../../Big_Files/X_test_Really_Thin_after_Tomek' + round_text + '.csv', index=False)\n",
    "    y_test.to_csv('../../Big_Files/y_test_Really_Thin_after_Tomek' + round_text + '.csv', index=False)\n",
    "\n",
    "    X_train, y_train = Tomek_Links(X_train, y_train)\n",
    "    X_train.to_csv('../../Big_Files/X_train_Really_Thin_after_Tomek_Twice' + round_text + '.csv', index=False)\n",
    "    y_train.to_csv('../../Big_Files/y_train_Really_Thin_after_Tomek_Twice' + round_text + '.csv', index=False)\n",
    "    X_test.to_csv('../../Big_Files/X_test_Really_Thin_after_Tomek_Twice' + round_text + '.csv', index=False)\n",
    "    y_test.to_csv('../../Big_Files/y_test_Really_Thin_after_Tomek_Twice' + round_text + '.csv', index=False)\n",
    "    print ()\n",
    "    \n",
    "def Undersample_Data_Thin_to_Minimal(round_text):\n",
    "    print ('Undersample_Data_Thin_to_Minimal()')\n",
    "\n",
    "    data = Get_Data()\n",
    "    data = data.astype('int64')\n",
    "    target = 'HOSPITAL'\n",
    "    data = Remove_Pedestrian_Crashes(data)\n",
    "    data = Feature_Engineering_Cross_Two(data)\n",
    "    data = Thin_to_Minimal_Features(data)\n",
    "    data = Get_Dummies(data, target)\n",
    "\n",
    "    # Decrease set size, for debugging\n",
    "#    X_train, X_test, y_train, y_test = Split_Data(data, target, 0.80)\n",
    "#    data = X_train\n",
    "#    data[target] = y_train\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = Split_Data(data, target, 0.30)\n",
    "\n",
    "    # CNN took 6 minutes at 99% decreased set size.  \n",
    "#    X_train, y_train = Condensed_Nearest_Neighbour(X_train, y_train)\n",
    "    X_train.to_csv('../../Big_Files/X_train_Thin_to_Minimal_before_Tomek' + round_text + '.csv', index=False)\n",
    "    y_train.to_csv('../../Big_Files/y_train_Thin_to_Minimal_before_Tomek' + round_text + '.csv', index=False)\n",
    "    X_test.to_csv('../../Big_Files/X_test_Thin_to_Minimal_before_Tomek' + round_text + '.csv', index=False)\n",
    "    y_test.to_csv('../../Big_Files/y_test_Thin_to_Minimal_before_Tomek' + round_text + '.csv', index=False)\n",
    "\n",
    "\n",
    "    # Two rounds of Tomek took one hour 30 minutes\n",
    "    X_train, y_train = Tomek_Links(X_train, y_train)\n",
    "    # Write to csv and read back in, \n",
    "    #    so we can play with the stuff later without having to redo the Tomek Links, \n",
    "    #    which can take a long time.\n",
    "    X_train.to_csv('../../Big_Files/X_train_Thin_to_Minimal_after_Tomek' + round_text + '.csv', index=False)\n",
    "    y_train.to_csv('../../Big_Files/y_train_Thin_to_Minimal_after_Tomek' + round_text + '.csv', index=False)\n",
    "    X_test.to_csv('../../Big_Files/X_test_Thin_to_Minimal_after_Tomek' + round_text + '.csv', index=False)\n",
    "    y_test.to_csv('../../Big_Files/y_test_Thin_to_Minimal_after_Tomek' + round_text + '.csv', index=False)\n",
    "\n",
    "\n",
    "    X_train, y_train = Tomek_Links(X_train, y_train)\n",
    "    X_train.to_csv('../../Big_Files/X_train_Thin_to_Minimal_after_Tomek_Twice' + round_text + '.csv', index=False)\n",
    "    y_train.to_csv('../../Big_Files/y_train_Thin_to_Minimal_after_Tomek_Twice' + round_text + '.csv', index=False)\n",
    "    X_test.to_csv('../../Big_Files/X_test_Thin_to_Minimal_after_Tomek_Twice' + round_text + '.csv', index=False)\n",
    "    y_test.to_csv('../../Big_Files/y_test_Thin_to_Minimal_after_Tomek_Twice' + round_text + '.csv', index=False)\n",
    "    print ()\n",
    "    \n",
    "#Undersample_Data_Thin('_v1')\n",
    "#Undersample_Data_Really_Thin('_v1')\n",
    "#Undersample_Data_Thin_to_Minimal('_v1')\n",
    "\n",
    "#Undersample_Data_Thin('_v2')\n",
    "#Undersample_Data_Really_Thin('_v2')\n",
    "#Undersample_Data_Thin_to_Minimal('_v2')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d577bab5",
   "metadata": {},
   "source": [
    "## Undersampling Results\n",
    "- Start with 619,027 samples\n",
    "- Remove 27,723 samples with pedestrians to get 591,304 samples\n",
    "- Split 70/30 to have 413,912 samples in training set\n",
    "- 62,114 hospitalized, 351,798 not hospitalized\n",
    "\n",
    "| Feature Set | Random Seed | Tomek Round | # Samples Removed | % Samples Removed |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| Hard | 1 | 1 | 14,398 | 3.48 |\n",
    "| Hard | 2 | 1 | 14,199 | 3.43 |\n",
    "| Hard | 1 | 2 | 3,004 | 0.75 |\n",
    "| Hard | 2 | 2 | 2,996 | 0.75 |\n",
    "| Medium | 1 | 1 | 7,222 | 1.74 |\n",
    "| Medium | 2 | 1 | 7,132 | 1.72 |\n",
    "| Medium | 1 | 2 | 1,403 | 0.34 |\n",
    "| Medium | 2 | 2 | 1,413 | 0.35 |\n",
    "| Easy | 1 | 1 | 4 | 0.00 |\n",
    "| Easy | 2 | 1 | 5 | 0.00 |\n",
    "| Easy | 1 | 2 | 1 | 0.00 |\n",
    "| Easy | 2 | 2 | 1 | 0.00 |\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93129c5b",
   "metadata": {},
   "source": [
    "# Custom Metrics\n",
    "https://keras.io/api/metrics/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28552cd",
   "metadata": {},
   "source": [
    "## Balanced Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0cc2410",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Balanced_Accuracy(y_true, y_pred):\n",
    "    return K.mean(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80d7ecc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://aakashgoel12.medium.com/how-to-add-user-defined-function-get-f1-score-in-keras-metrics-3013f979ce0d\n",
    "def get_f1(y_true, y_pred): #taken from old keras source code\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "    return f1_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ae44b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://neptune.ai/blog/implementing-the-macro-f1-score-in-keras\n",
    "### Define F1 measures: F1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "def custom_f1(y_true, y_pred):\n",
    "    def recall_m(y_true, y_pred):\n",
    "        TP = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        Positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "\n",
    "        recall = TP / (Positives+K.epsilon())\n",
    "        return recall\n",
    "\n",
    "\n",
    "    def precision_m(y_true, y_pred):\n",
    "        TP = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        Pred_Positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "\n",
    "        precision = TP / (Pred_Positives+K.epsilon())\n",
    "        return precision\n",
    "\n",
    "    precision, recall = precision_m(y_true, y_pred), recall_m(y_true, y_pred)\n",
    "\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "146c67d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0. 1. 0. 1.], shape=(4,), dtype=float64)\n",
      "tf.Tensor([0 0 1 1], shape=(4,), dtype=int64)\n",
      "TP =  tf.Tensor(1.0, shape=(), dtype=float64)  FN =  tf.Tensor(1.0, shape=(), dtype=float64)  FP =  tf.Tensor(1.0, shape=(), dtype=float64)  TN =  tf.Tensor(1.0, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "def custom_metric(y_true, y_pred):\n",
    "    y_true = tf.dtypes.cast(y_true, tf.float64)\n",
    "    y_pred = tf.dtypes.cast(y_pred, tf.float64)\n",
    "    P = K.sum(y_true)\n",
    "    N = K.sum(1 - y_true)\n",
    "    # Note that Tensorflow and Keras round using \"banker's rounding,\"\n",
    "    # where halves round to the nearest even integer, so\n",
    "    # round(0.5) = 0, but round (1.5) = 2\n",
    "    Discrete_y_pred = K.round(y_pred)\n",
    "    TRUE = K.equal(y_true, Discrete_y_pred)\n",
    "    TRUE = tf.dtypes.cast(TRUE, tf.float64)\n",
    "    FALSE = 1-TRUE\n",
    "    Discrete_TP = Discrete_y_pred * TRUE\n",
    "    TP = K.sum(Discrete_TP)\n",
    "    FN = P - TP\n",
    "    Discrete_TN = (1 - Discrete_y_pred) * TRUE\n",
    "    TN = K.sum(Discrete_TN)\n",
    "    FP = N - TN    \n",
    "\n",
    "#    CM = confusion_matrix(y_true, y_pred)\n",
    "#    print (CM)\n",
    "#    P = CM[1][0] + CM[1][1]\n",
    "#    N = CM[0][0] + CM[0][1]\n",
    "#    TN = CM[0][0]\n",
    "#    FP = CM[0][1]\n",
    "#    FN = CM[1][0]\n",
    "#    TP = CM[1][1]\n",
    "#    print ('TP = ', TP, ' FN = ', FN, ' FP = ', FP, ' TN = ', TN)\n",
    "    \n",
    "    return P, N, TP, FN, TN, FP\n",
    "\n",
    "def Test_Custom_Metric():\n",
    "    y_true = [0.0,1.0,0.0,1.0]\n",
    "    y_proba = [0.2, 0.49, 0.75, 0.9]\n",
    "    y_pred = [round(x) for x in y_proba]\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_true = tf.convert_to_tensor(y_true)\n",
    "    y_pred = tf.convert_to_tensor(y_pred)\n",
    "    print (y_true)\n",
    "    print (y_pred)\n",
    "    P, N, TP, FN, TN, FP = custom_metric(y_true, y_pred)\n",
    "    print ('TP = ', TP, ' FN = ', FN, ' FP = ', FP, ' TN = ', TN)\n",
    "    \n",
    "Test_Custom_Metric()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7527cec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Accuracy_Metric(y_true, y_pred):\n",
    "    P, N, TP, FN, TN, FP = custom_metric(y_true, y_pred)\n",
    "    metric = (TP+TN)/(TP + FN + FP + TN + K.epsilon())\n",
    "    return metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a24413b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Precision_Metric(y_true, y_pred):\n",
    "    P, N, TP, FN, TN, FP = custom_metric(y_true, y_pred)\n",
    "    metric = TP/(TP + FP + K.epsilon())\n",
    "    return metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8c8c0e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Recall_Metric(y_true, y_pred):\n",
    "    P, N, TP, FN, TN, FP = custom_metric(y_true, y_pred)\n",
    "    metric = TP/(TP + FN + K.epsilon())\n",
    "    return metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0defac89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Balanced_Accuracy_Metric(y_true, y_pred):\n",
    "    P, N, TP, FN, TN, FP = custom_metric(y_true, y_pred)\n",
    "    metric = ( TN/(2*(TN + FP + K.epsilon())) + TP/(2*(FN + TP + K.epsilon())))\n",
    "    return metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9afe9e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def F1_Metric(y_true, y_pred):\n",
    "    precision = Precision_Metric(y_true, y_pred)\n",
    "    recall = Recall_Metric(y_true, y_pred)\n",
    "    metric = 2/(1/(precision + K.epsilon()) + 1/(recall + K.epsilon()))\n",
    "    return metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "604a0833",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gmean_Metric(y_true, y_pred):\n",
    "    P, N, TP, FN, TN, FP = custom_metric(y_true, y_pred)\n",
    "    precision = TP/(TP + FP + K.epsilon())\n",
    "    specificity = TN/(TN + FP + K.epsilon())\n",
    "    metric = K.sqrt(precision * specificity)\n",
    "    return metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7d911f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Balanced_Precision_Metric(y_true, y_pred):\n",
    "    P, N, TP, FN, TN, FP = custom_metric(y_true, y_pred)\n",
    "    metric = (TP * N)/(TP * N + FP * P + K.epsilon())\n",
    "    return metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b1f07d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Balanced_F1_Metric(y_true, y_pred):\n",
    "    precision = Balanced_Precision_Metric(y_true, y_pred)\n",
    "    recall = Recall_Metric(y_true, y_pred)\n",
    "    metric = 2/(1/(precision + K.epsilon()) + 1/(recall + K.epsilon()))\n",
    "    return metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88dcfd4d",
   "metadata": {},
   "source": [
    "# Loss Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7cf4a61",
   "metadata": {},
   "source": [
    "## Alpha Weighted Binary Crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a639e7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_weighted_binary_crossentropy_with_parameter(alpha = 0.5):\n",
    "    def alpha_weighted_binary_crossentropy(y_true, y_pred):\n",
    "        y_true = tf.cast(y_true, dtype=y_pred.dtype)\n",
    "\n",
    "        binary_crossentropy = keras.backend.binary_crossentropy(y_true, y_pred)\n",
    "        weights = tf.where(tf.equal(y_true,1),alpha, 1-alpha)\n",
    "        product = tf.multiply(binary_crossentropy, weights)\n",
    "        loss = keras.backend.mean(product)\n",
    "        return loss\n",
    "    return alpha_weighted_binary_crossentropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "51fa3b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_weighted_binary_crossentropy_with_class_weight_parameters(weight_0 = 1.0, weight_1 = 1.0):\n",
    "    # Weights for each class = (nSamples Total)/(2* (nSamples in Class))\n",
    "    def alpha_weighted_binary_crossentropy(y_true, y_pred):\n",
    "        y_true = tf.cast(y_true, dtype=y_pred.dtype)\n",
    "        binary_crossentropy = keras.backend.binary_crossentropy(y_true, y_pred, from_logits=False)\n",
    "        weights = tf.where(tf.equal(y_true,1),weight_1, weight_0)\n",
    "        product = tf.multiply(binary_crossentropy, weights)\n",
    "        loss = keras.backend.mean(product)\n",
    "        return loss\n",
    "    return alpha_weighted_binary_crossentropy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74dedab",
   "metadata": {},
   "source": [
    "## Focal Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f61cb331",
   "metadata": {},
   "outputs": [],
   "source": [
    "def focal_loss(y_true, y_pred):\n",
    "    # The dataset has  259077  elements.\n",
    "    # The target group has  31891  elements.\n",
    "    # Our target is  12.3095 % of the dataset.\n",
    "    # There are  8.12  negative elements for each positive.    \n",
    "#    p = 8.12\n",
    "    p = 5.94\n",
    "\n",
    "    alpha = (p/(p+1))*1.0\n",
    "\n",
    "    gamma_1 = 0.0 # Must be float for the tf.math.pow() function to work.\n",
    "    gamma_2 = 0.0\n",
    "    y_true = tf.cast(y_true, dtype=y_pred.dtype)\n",
    "    binary_crossentropy = keras.backend.binary_crossentropy(y_true, y_pred)\n",
    "#    print (binary_crossentropy.numpy())\n",
    "    weights = tf.where(tf.equal(y_true,1),alpha, 1-alpha)\n",
    "#    print (weights.numpy())\n",
    "    focal = tf.where(tf.equal(y_true,1), (1.0-y_pred), (y_pred))\n",
    "    power = tf.where(tf.equal(y_true,1), gamma_1, gamma_2)\n",
    "    focal_power = tf.math.pow(focal,power)\n",
    "#    print (focal.numpy())\n",
    "#    print (power.numpy())\n",
    "#    print (focal_power.numpy())\n",
    "    product = tf.multiply(binary_crossentropy, weights)\n",
    "    focal_power_product = tf.multiply(product, focal_power)\n",
    "#    print (focal_power_product.numpy())\n",
    "    loss = keras.backend.mean(focal_power_product)\n",
    "#    print (loss.numpy())\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efaef565",
   "metadata": {},
   "source": [
    "## Focal Loss with Parameters\n",
    "- Adapted from https://www.kaggle.com/code/abazdyrev/keras-nn-focal-loss-experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c48a20f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def focal_loss_with_parameters(alpha = 0.5, gamma_0=0.0, gamma_1=0.0):\n",
    "    def focal_loss(y_true, y_pred):\n",
    "        y_true = tf.cast(y_true, dtype=y_pred.dtype)\n",
    "#        tf.clip_by_value(y_pred, 0.00001, 0.99999) # Make sure we don't blow up the logarithm\n",
    "        binary_crossentropy = keras.backend.binary_crossentropy(y_true, y_pred)\n",
    "        weights = tf.where(tf.equal(y_true,1),alpha, 1.0-alpha)\n",
    "        focal = tf.where(tf.equal(y_true,1), (1.0-y_pred), (y_pred))\n",
    "        power = tf.where(tf.equal(y_true,0), gamma_0, gamma_1)\n",
    "        focal_power = tf.math.pow(focal,power)\n",
    "        product = tf.multiply(binary_crossentropy, weights)\n",
    "        focal_power_product = tf.multiply(product, focal_power)\n",
    "#        tf.clip_by_value(focal_power_product, 0.00001, 0.99999)\n",
    "        loss = keras.backend.mean(focal_power_product)\n",
    "        if math.isnan(loss):\n",
    "            print ('loss is nan')\n",
    "        return loss\n",
    "    \n",
    "    return focal_loss\n",
    "\n",
    "get_custom_objects().update({'focal_loss_with_parameters': focal_loss_with_parameters()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1224812d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def focal_loss_with_parameters_2(alpha=.25, gamma=2.0):\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
    "        pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
    "        return -K.mean(alpha * K.pow(1. - pt_1, gamma) * K.log(K.epsilon()+pt_1))-K.mean((1-alpha) * K.pow( pt_0, gamma) * K.log(1. - pt_0 + K.epsilon()))\n",
    "    return focal_loss_fixed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0c9b6f",
   "metadata": {},
   "source": [
    "## Test Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0b909c30",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test with p==1.0, alpha = 0.5, gamma = 0.0\n",
      "1.4222431275492453   Hand-calculated BCE loss\n",
      "1.0175692   My custom AWBCE function's no-alpha backend\n",
      "0.5087846   My custom one-parameter AWBCE function\n",
      "1.0175692   My custom two-parameter AWBCE function\n",
      "1.0175692   Keras's BCE function\n",
      "0.5087846   Keras's BFC function\n",
      "0.5087846   My BFC function with gamma=0.0\n",
      "\n",
      "Test with p = 3.0, alpha = 0.75, gamma = 0.0\n",
      "0.5171758   My custom one-parameter AWBCE function\n",
      "1.3791353   My custom two-parameter AWBCE function\n",
      "0.5171758   Keras's BFC function\n",
      "0.5171758   My BFC function with gamma=0.0\n",
      "\n",
      "Test with alpha = 0.8, gamma = 0.0\n",
      "0.518854   Keras's BFC function\n",
      "0.518854   My BFC function\n",
      "\n",
      "Test with alpha = 0.8, gamma = 2.0\n",
      "0.32591802   Keras's BFC function\n",
      "0.325918   My BFC function with gamma=2.0\n",
      "\n",
      "Test with p = 1.0, alpha = 0.5, gamma = 2.0\n",
      "0.3167107   Keras's BFC function\n",
      "0.3167107   My BFC function with gamma=2.0\n",
      "\n",
      "Test Keras's BFC Function with different values of alpha\n",
      "0.4953587   Keras's BFC function\n",
      "0.5087846   Keras's BFC function\n",
      "0.5222105   Keras's BFC function\n"
     ]
    }
   ],
   "source": [
    "def Test_Loss_Functions():\n",
    "    \n",
    "    ### Data as list y_test and y_prob\n",
    "    y_test = [0.0]*500 + [1.0]*500\n",
    "    y_test_binary = [0]*500 + [1]*500\n",
    "#    y_test = [0.0, 1.0]*5\n",
    "#    y_test_binary = [0,1]*5\n",
    "#    y_prob = [0.0001, 0.001, 0.01, 0.1, 0.3, 0.5, 0.7, 0.9, 0.99, 0.999]\n",
    "    y_prob = [random.random() for x in range (1000)]\n",
    "#    print (y_prob)\n",
    "    \n",
    "    ### Data as tensors y_true and y_pred\n",
    "    y_true = np.array(y_test, dtype=np.float32)\n",
    "    y_true = tf.convert_to_tensor(y_true)\n",
    "    y_pred = np.array(y_prob, dtype=np.float32)\n",
    "    y_pred = tf.convert_to_tensor(y_pred)\n",
    "\n",
    "    ####################################################\n",
    "    print ('Test with p==1.0, alpha = 0.5, gamma = 0.0')\n",
    "\n",
    "    ### Calculate binary crossentropy by hand\n",
    "    BCE = [-(y_test[i] * math.log(y_prob[i]) + (1 - y_test[i]) * math.log(1 - y_prob[i])) for i in range (10)]\n",
    "    Class_Weights = [1.0,1.0]\n",
    "    Weights = [Class_Weights[y_test_binary[i]] for i in range(10)]\n",
    "    Product = [BCE[i] * Weights[i] for i in range (10)]\n",
    "    loss = sum(Product)/len(Product)\n",
    "    print (loss, \"  Hand-calculated BCE loss\")\n",
    "    \n",
    "    ### Calculate binary crossentropy like I did in my custom loss functions\n",
    "    binary_crossentropy = keras.backend.binary_crossentropy(y_true, y_pred, from_logits=False)\n",
    "#    display(binary_crossentropy.numpy())\n",
    "    loss = keras.backend.mean(binary_crossentropy).numpy()\n",
    "    print (loss, \"  My custom AWBCE function's no-alpha backend\")\n",
    "    \n",
    "    ### Calculate binary crossentropy using my custom loss function\n",
    "    loss_function = alpha_weighted_binary_crossentropy_with_parameter(alpha = 0.5)\n",
    "    loss = loss_function(y_true, y_pred).numpy()\n",
    "    print (loss, '  My custom one-parameter AWBCE function')\n",
    "    \n",
    "    ### Calculate binary crossentropy using my custom loss function\n",
    "    # Weights for each class = (nSamples Total)/(2* (nSamples in Class))\n",
    "    loss_function = alpha_weighted_binary_crossentropy_with_class_weight_parameters(weight_0 = 1.0, weight_1 = 1.0)\n",
    "    loss = loss_function(y_true, y_pred).numpy()\n",
    "    print (loss, '  My custom two-parameter AWBCE function')\n",
    "    \n",
    "    ### Calculate binary crossentropy using Keras's loss function\n",
    "    bce = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "    loss = bce(y_true, y_pred).numpy()\n",
    "    print (loss, \"  Keras's BCE function\")\n",
    "    \n",
    "    ### Calculate the same value using the BinaryFocalCrossentropy function\n",
    "    loss_function = tf.keras.losses.BinaryFocalCrossentropy(\n",
    "        apply_class_balancing = True, \n",
    "        alpha = 0.5,\n",
    "        gamma = 0.0, \n",
    "        from_logits=False\n",
    "    )\n",
    "    loss = loss_function(y_true, y_pred).numpy()\n",
    "    print (loss, \"  Keras's BFC function\")\n",
    "    \n",
    "    ### Calculate focal loss using my custom loss function\n",
    "    loss_function = focal_loss_with_parameters(0.5, 0.0, 0.0)\n",
    "    loss = loss_function(y_true, y_pred).numpy()\n",
    "    print (loss, '  My BFC function with gamma=0.0')\n",
    "    \n",
    "    ####################################################\n",
    "    print ()\n",
    "    print ('Test with p = 3.0, alpha = 0.75, gamma = 0.0')\n",
    "    \n",
    "    ### Calculate binary crossentropy using my custom loss function\n",
    "    loss_function = alpha_weighted_binary_crossentropy_with_parameter(alpha = 0.75)\n",
    "    loss = loss_function(y_true, y_pred).numpy()\n",
    "    print (loss, '  My custom one-parameter AWBCE function')\n",
    "    \n",
    "    ### Calculate binary crossentropy using my custom loss function\n",
    "    # Weights for each class = (nSamples Total)/(2* (nSamples in Class))\n",
    "    loss_function = alpha_weighted_binary_crossentropy_with_class_weight_parameters(weight_0 = 2.0/3.0, weight_1 = 2.0)\n",
    "    loss = loss_function(y_true, y_pred).numpy()\n",
    "    print (loss, '  My custom two-parameter AWBCE function')\n",
    "    \n",
    "    ### Calculate the same value using the BinaryFocalCrossentropy function\n",
    "    loss_function = tf.keras.losses.BinaryFocalCrossentropy(\n",
    "        apply_class_balancing = True, \n",
    "        alpha = 0.75,\n",
    "        gamma = 0.0, \n",
    "        from_logits=False\n",
    "    )\n",
    "    loss = loss_function(y_true, y_pred).numpy()\n",
    "    print (loss, \"  Keras's BFC function\")\n",
    "    \n",
    "    ### Calculate focal loss using my custom loss function\n",
    "    loss_function = focal_loss_with_parameters(0.75, 0.0, 0.0)\n",
    "    loss = loss_function(y_true, y_pred).numpy()\n",
    "    print (loss, '  My BFC function with gamma=0.0')\n",
    "    \n",
    "    ####################################################\n",
    "    print ()\n",
    "    print ('Test with alpha = 0.8, gamma = 0.0')\n",
    "    \n",
    "    ### Calculate the same value using the BinaryFocalCrossentropy function\n",
    "    loss_function = tf.keras.losses.BinaryFocalCrossentropy(\n",
    "        apply_class_balancing = True, \n",
    "        alpha = 0.8,\n",
    "        gamma = 0.0, \n",
    "#        from_logits=False\n",
    "    )\n",
    "    loss = loss_function(y_true, y_pred).numpy()\n",
    "    print (loss, \"  Keras's BFC function\")\n",
    "    \n",
    "    ### Calculate focal loss using my custom loss function\n",
    "    loss_function = focal_loss_with_parameters(0.8, 0.0, 0.0)\n",
    "    loss = loss_function(y_true, y_pred).numpy()\n",
    "    print (loss, '  My BFC function')\n",
    "\n",
    "    ####################################################\n",
    "    print ()\n",
    "    print ('Test with alpha = 0.8, gamma = 2.0')\n",
    "    \n",
    "    ### Calculate the same value using the BinaryFocalCrossentropy function\n",
    "    loss_function = tf.keras.losses.BinaryFocalCrossentropy(\n",
    "        apply_class_balancing = True, \n",
    "        alpha = 0.8,\n",
    "        gamma = 2.0, \n",
    "#        from_logits=False\n",
    "    )\n",
    "    loss = loss_function(y_true, y_pred).numpy()\n",
    "    print (loss, \"  Keras's BFC function\")\n",
    "    \n",
    "    ### Calculate focal loss using my custom loss function\n",
    "    loss_function = focal_loss_with_parameters(0.8, 2.0, 2.0)\n",
    "    loss = loss_function(y_true, y_pred).numpy()\n",
    "    print (loss, '  My BFC function with gamma=2.0')\n",
    "\n",
    "    ####################################################\n",
    "    print ()\n",
    "    print ('Test with p = 1.0, alpha = 0.5, gamma = 2.0')\n",
    "    \n",
    "    ### Calculate the same value using the BinaryFocalCrossentropy function\n",
    "    loss_function = tf.keras.losses.BinaryFocalCrossentropy(\n",
    "        apply_class_balancing = True, \n",
    "        alpha = 0.5,\n",
    "        gamma = 2.0, \n",
    "#        from_logits=False\n",
    "    )\n",
    "    loss = loss_function(y_true, y_pred).numpy()\n",
    "    print (loss, \"  Keras's BFC function\")\n",
    "    \n",
    "    ### Calculate focal loss using my custom loss function\n",
    "    loss_function = focal_loss_with_parameters(0.5, 2.0, 2.0)\n",
    "    loss = loss_function(y_true, y_pred).numpy()\n",
    "    print (loss, '  My BFC function with gamma=2.0')\n",
    "\n",
    "    ##################################################################\n",
    "    print ()\n",
    "    print (\"Test Keras's BFC Function with different values of alpha\")\n",
    "    \n",
    "    ### Calculate the same value using the BinaryFocalCrossentropy function\n",
    "    loss_function = tf.keras.losses.BinaryFocalCrossentropy(\n",
    "        apply_class_balancing = True, \n",
    "        alpha = 0.1,\n",
    "        gamma = 0.0, \n",
    "#        from_logits=False\n",
    "    )\n",
    "    loss = loss_function(y_true, y_pred).numpy()\n",
    "    print (loss, \"  Keras's BFC function\")\n",
    "    \n",
    "    ### Calculate the same value using the BinaryFocalCrossentropy function\n",
    "    loss_function = tf.keras.losses.BinaryFocalCrossentropy(\n",
    "        apply_class_balancing = True, \n",
    "        alpha = 0.5,\n",
    "        gamma = 0.0, \n",
    "        from_logits=False\n",
    "    )\n",
    "    loss = loss_function(y_true, y_pred).numpy()\n",
    "    print (loss, \"  Keras's BFC function\")\n",
    "    \n",
    "    ### Calculate the same value using the BinaryFocalCrossentropy function\n",
    "    loss_function = tf.keras.losses.BinaryFocalCrossentropy(\n",
    "        apply_class_balancing = True, \n",
    "        alpha = 0.9,\n",
    "        gamma = 0.0, \n",
    "        from_logits=False\n",
    "    )\n",
    "    loss = loss_function(y_true, y_pred).numpy()\n",
    "    print (loss, \"  Keras's BFC function\")\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "Test_Loss_Functions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c65a77",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a36e3f",
   "metadata": {},
   "source": [
    "## Simple Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3635b98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Make_Simple_Model(X_train):\n",
    "    print ('Make_Model()')\n",
    "    model = keras.Sequential(\n",
    "        [\n",
    "            keras.layers.Dense(\n",
    "                256, activation=\"relu\", input_shape=(X_train.shape[-1],)\n",
    "            ),\n",
    "            keras.layers.Dense(256, activation=\"relu\"),\n",
    "            keras.layers.Dropout(0.3),\n",
    "            keras.layers.Dense(256, activation=\"relu\"),\n",
    "            keras.layers.Dropout(0.3),\n",
    "            keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "        ]\n",
    "    )\n",
    "#    display(model.summary())\n",
    "    print ()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "78cb5f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Train_Simple_Model (X_train, X_test, y_train, y_test, model, loss_function, r_target, filename):\n",
    "    print ('Train_Model()')\n",
    "    metrics = [\n",
    "#        keras.metrics.FalseNegatives(name=\"fn\"),\n",
    "#        keras.metrics.FalsePositives(name=\"fp\"),\n",
    "#        keras.metrics.TrueNegatives(name=\"tn\"),\n",
    "#        keras.metrics.TruePositives(name=\"tp\"),\n",
    "        keras.metrics.Precision(name=\"precision\"),\n",
    "        keras.metrics.Recall(name=\"recall\"),\n",
    "#        keras.metrics.BinaryAccuracy(name=\"accuracy\"),\n",
    "        Balanced_Accuracy_Metric,\n",
    "#        Gmean_Metric,\n",
    "        Balanced_Precision_Metric,\n",
    "#        F1_Metric,\n",
    "        Balanced_F1_Metric,\n",
    "    ]\n",
    "\n",
    "    model.compile(\n",
    "#        optimizer=keras.optimizers.Adam(), \n",
    "        optimizer=keras.optimizers.Adam(1e-7, clipnorm=0.99999), \n",
    "        loss=loss_function, \n",
    "        metrics=metrics\n",
    "    )\n",
    "\n",
    "#    class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "#    class_weight = {0: 1, 1: 1}\n",
    "    class_weight={0:(1+r_target)/(2*r_target), 1:(1+r_target)/(2*1)}\n",
    "    \n",
    "    model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        batch_size=128,\n",
    "        epochs=30,\n",
    "        verbose=0,\n",
    "#        callbacks=callbacks,\n",
    "        validation_data=(X_test, y_test),\n",
    "        class_weight=class_weight,\n",
    "    )\n",
    "    \n",
    "    # Make everything a numpy array\n",
    "    y_proba = model.predict(X_test)\n",
    "    # y_proba is a numpy array\n",
    "    y_pred = np.around(y_proba)\n",
    "    # y_test is a Pandas dataframe\n",
    "    y_test = y_test.to_numpy()\n",
    "    \n",
    "    Balance_Proba(y_test, y_proba, y_pred, r_target, filename)    \n",
    "    \n",
    "    print ()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f61f36",
   "metadata": {},
   "source": [
    "## Another Keras Binary Classification Model\n",
    "https://machinelearningmastery.com/binary-classification-tutorial-with-the-keras-deep-learning-library/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2c68709e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Keras_Binary_Focal_Crossentropy(X_train, X_test, y_train, y_test, r_target, alpha, gamma, epochs, filename, title):\n",
    "    print ('Keras_Binary_Focal_Crossentropy')\n",
    "    print ('alpha = ', alpha)\n",
    "    loss_function = tf.keras.losses.BinaryFocalCrossentropy(\n",
    "        apply_class_balancing=True,\n",
    "        alpha=alpha,\n",
    "        gamma=gamma,\n",
    "#        from_logits=False,\n",
    "#        label_smoothing=0.0,\n",
    "#        axis=-1,\n",
    "#        reduction=losses_utils.ReductionV2.AUTO,\n",
    "#        name='binary_focal_crossentropy'\n",
    "    )   \n",
    "    \n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(60, input_shape=(X_train.shape[-1],), activation='relu'))\n",
    "#    model.add(Dense(30, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))    \n",
    "    # Compile model\n",
    "    metrics = [\n",
    "        keras.metrics.Precision(name=\"precision\"),\n",
    "        keras.metrics.Recall(name=\"recall\"),\n",
    "        F1_Metric,\n",
    "    ]\n",
    "    model.compile(loss=loss_function, optimizer=tf.keras.optimizers.Adam(), metrics=metrics)\n",
    "    estimator = KerasClassifier(\n",
    "        model=model, \n",
    "#        random_state=42,\n",
    "        metrics=metrics,\n",
    "        batch_size=128, \n",
    "        verbose=0,\n",
    "        epochs=epochs,\n",
    "    )\n",
    "    # What does this do?\n",
    "    kfold = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "    \n",
    "    # Fit model\n",
    "    estimator.fit(\n",
    "        X_train, \n",
    "        y_train.values.ravel(),\n",
    "        class_weight={0:(1+r_target)/(2*r_target), 1:(1+r_target)/(2*1)},\n",
    "    )\n",
    "    y_proba = estimator.predict_proba(X_test)\n",
    "    y_proba = [x[1] for x in y_proba]\n",
    "    print ('y_proba unique')\n",
    "    print (np.unique(y_proba))\n",
    "    y_pred = K.round(y_proba).numpy()\n",
    "    y_proba = np.array(y_proba)\n",
    "\n",
    "    Balance_Proba(y_test, y_proba, y_pred, r_target, filename, title)\n",
    "    print ()\n",
    "    return 0    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d06a6c",
   "metadata": {},
   "source": [
    "## Our Binary Focal Crossentropy Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2c65be95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Our_Binary_Focal_Crossentropy(X_train, X_test, y_train, y_test, r_target, gamma_0, gamma_1, epochs, filename, title):\n",
    "    print ('Keras_Binary_Focal_Crossentropy')\n",
    "\n",
    "    alpha_target = r_target/(r_target+1)\n",
    "    loss_function = focal_loss_with_parameters(alpha_target, gamma_0, gamma_1)\n",
    "#    loss_function = focal_loss_with_parameters_2(alpha_target, gamma)\n",
    "    \n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(60, input_shape=(X_train.shape[-1],), activation='relu'))\n",
    "#    model.add(Dense(30, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))    \n",
    "    # Compile model\n",
    "    model.compile(loss=loss_function, optimizer=tf.keras.optimizers.Adam(), metrics=['accuracy'])\n",
    "    metrics = [\n",
    "        keras.metrics.Precision(name=\"precision\"),\n",
    "        keras.metrics.Recall(name=\"recall\"),\n",
    "        F1_Metric,\n",
    "    ]\n",
    "    estimator = KerasClassifier(\n",
    "        model=model, \n",
    "#        random_state=42,\n",
    "        metrics=metrics,\n",
    "        batch_size=128, \n",
    "        verbose=0,\n",
    "        epochs=epochs,\n",
    "    )\n",
    "    # What does this do?\n",
    "    kfold = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "    \n",
    "    # Fit model\n",
    "    estimator.fit(\n",
    "        X_train, \n",
    "        y_train.values.ravel(),\n",
    "        class_weight={0:(1+r_target)/(2*r_target), 1:(1+r_target)/(2*1)},\n",
    "    )\n",
    "    y_proba = estimator.predict_proba(X_test)\n",
    "    y_proba = [x[1] for x in y_proba]\n",
    "    y_pred = K.round(y_proba).numpy()\n",
    "    y_proba = np.array(y_proba)\n",
    "\n",
    "    Balance_Proba(y_test, y_proba, y_pred, r_target, filename, title)\n",
    "    print ()\n",
    "    return 0    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91de86f",
   "metadata": {},
   "source": [
    "## AdaBoost Model\n",
    "https://stackoverflow.com/questions/39063676/how-to-boost-a-keras-based-neural-network-using-adaboost\n",
    "- model.predict_proba(X_test) returns two columns, \n",
    "    - the first the probability that the sample is in class 0, \n",
    "    - and the second the probability that the sample is in class 1.\n",
    "    - We just want the second column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "764615d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AdaBoost(X_train, X_test, y_train, y_test, r_target, filename, title):\n",
    "    print ('AdaBoost() ', filename)\n",
    "    model = AdaBoostClassifier(n_estimators=100)\n",
    "    model.fit(\n",
    "        X_train, \n",
    "        y_train.values.ravel(),\n",
    "    )\n",
    "    y_proba = model.predict_proba(X_test)\n",
    "    y_proba = [x[1] for x in y_proba]\n",
    "    y_pred = K.round(y_proba).numpy()\n",
    "    y_proba = np.array(y_proba)\n",
    "\n",
    "    Balance_Proba(y_test, y_proba, y_pred, r_target, filename, title)\n",
    "    print ()\n",
    "    return model    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14afd759",
   "metadata": {},
   "source": [
    "### Ensembles of Classifiers\n",
    "https://imbalanced-learn.org/stable/ensemble.html#bagging-classifier\n",
    "\n",
    "with arguments based on the documentation examples\n",
    "\n",
    "https://imbalanced-learn.org/stable/auto_examples/ensemble/plot_comparison_ensemble_classifier.html#sphx-glr-auto-examples-ensemble-plot-comparison-ensemble-classifier-py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5cffa9",
   "metadata": {},
   "source": [
    "## Bagging Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fe617891",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Bagging(X_train, X_test, y_train, y_test, r_target, filename, title):\n",
    "    print ('Bagging() ', filename)\n",
    "    model = BalancedBaggingClassifier(\n",
    "#        random_state=42\n",
    "    )\n",
    "    model.fit(\n",
    "        X_train, \n",
    "        y_train.values.ravel(),\n",
    "    )\n",
    "    y_proba = model.predict_proba(X_test)\n",
    "    y_proba = [x[1] for x in y_proba]\n",
    "    y_pred = K.round(y_proba)\n",
    "    y_proba = np.array(y_proba)\n",
    "#    display(pd.DataFrame(y_proba).value_counts())\n",
    "\n",
    "    Balance_Proba(y_test, y_proba, y_pred, r_target, filename, title)\n",
    "    print ()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1421ec7b",
   "metadata": {},
   "source": [
    "## Balanced Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ee95effe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Balanced_Random_Forest_Classifier(X_train, X_test, y_train, y_test, r_target, filename, title):\n",
    "    print ('Balanced Random Forest Classifier ', filename)\n",
    "    model = BalancedRandomForestClassifier(\n",
    "#        max_depth=2, \n",
    "#        random_state=42, \n",
    "        class_weight={0:(1+r_target)/(2*r_target), 1:(1+r_target)/(2*1)}\n",
    "    )\n",
    "    model.fit(\n",
    "        X_train, \n",
    "        y_train.values.ravel(),\n",
    "    )\n",
    "    y_proba = model.predict_proba(X_test)\n",
    "    y_proba = [x[1] for x in y_proba]\n",
    "    y_pred = K.round(y_proba)\n",
    "    y_proba = np.array(y_proba)\n",
    "#    display(pd.DataFrame(y_proba).value_counts())\n",
    "\n",
    "    Balance_Proba(y_test, y_proba, y_pred, r_target, filename, title)\n",
    "    \n",
    "    print ()\n",
    "    return model    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8a4b47",
   "metadata": {},
   "source": [
    "## RUSBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "240eb43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RUSBoost_Classifier(X_train, X_test, y_train, y_test, estimator, r_target, filename, title):\n",
    "    print ('RUSBoost Classifier ', filename)\n",
    "    model = RUSBoostClassifier(\n",
    "        n_estimators=1000, \n",
    "        estimator=estimator,\n",
    "        algorithm='SAMME.R', \n",
    "#        random_state=42\n",
    "    )\n",
    "    model.fit(\n",
    "        X_train, \n",
    "        y_train.values.ravel(),\n",
    "    )\n",
    "    y_proba = model.predict_proba(X_test)\n",
    "    y_proba = [x[1] for x in y_proba]\n",
    "    y_pred = K.round(y_proba)\n",
    "    y_proba = np.array(y_proba)\n",
    "#    display(pd.DataFrame(y_proba).value_counts())\n",
    "\n",
    "    Balance_Proba(y_test, y_proba, y_pred, r_target, filename, title)\n",
    "    \n",
    "    print ()\n",
    "    return model    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2feb5091",
   "metadata": {},
   "source": [
    "## Easy Ensemble Classifier (Adaboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "db654cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Easy_Ensemble_Classifier(X_train, X_test, y_train, y_test, r_target, filename, title):\n",
    "    print ('Easy Ensemble Classifier ', filename)\n",
    "    estimator = AdaBoostClassifier(n_estimators=10)\n",
    "    model = EasyEnsembleClassifier(n_estimators=10, estimator=estimator)\n",
    "    model.fit(\n",
    "        X_train, \n",
    "        y_train.values.ravel(),\n",
    "    )\n",
    "    y_proba = model.predict_proba(X_test)\n",
    "    y_proba = [x[1] for x in y_proba]\n",
    "    y_pred = K.round(y_proba)\n",
    "    y_proba = np.array(y_proba)\n",
    "#    display(pd.DataFrame(y_proba).value_counts())\n",
    "\n",
    "    Balance_Proba(y_test, y_proba, y_pred, r_target, filename, title)\n",
    "    \n",
    "    print ()\n",
    "    return model    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6592a6f5",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9075eef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Logistic_Regression_Classifier(X_train, X_test, y_train, y_test, r_target, filename, title):\n",
    "    print ('Logistic Regression Classifier ', filename)\n",
    "    model = LogisticRegression(\n",
    "        class_weight={0:(1+r_target)/(2*r_target), 1:(1+r_target)/(2*1)},\n",
    "        max_iter=1000,\n",
    "#        random_state=42,\n",
    "    )\n",
    "    model.fit(\n",
    "        X_train, \n",
    "        y_train.values.ravel(),\n",
    "    )\n",
    "    y_proba = model.predict_proba(X_test)\n",
    "    y_proba = [x[1] for x in y_proba]\n",
    "    y_pred = K.round(y_proba)\n",
    "    y_proba = np.array(y_proba)\n",
    "\n",
    "    Balance_Proba(y_test, y_proba, y_pred, r_target, filename, title)\n",
    "    \n",
    "    print ()\n",
    "    return model    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44982302",
   "metadata": {},
   "source": [
    "# Evaluate Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f6c830",
   "metadata": {},
   "source": [
    "## Adjust Center of Probability Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6960f728",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Shift_y_proba(y_test, y_proba, y_pred, filename):\n",
    "    print ('Shift_y_proba()')\n",
    "    print ()\n",
    "    N_median = np.median(y_proba[np.array(y_test)==0])\n",
    "    P_median = np.median(y_proba[np.array(y_test)==1])\n",
    "    center = (N_median + P_median)/2\n",
    "    print ('N_median = %.3f, P_median = %.3f, center = %.3f' % (N_median, P_median, center))\n",
    "\n",
    "    y_proba = y_proba - center + 0.5\n",
    "    y_proba = np.where (y_proba < 0.0, 0.0, y_proba)\n",
    "    y_proba = np.where (y_proba > 1.0, 1.0, y_proba)\n",
    "    y_pred = K.round(y_proba)\n",
    "\n",
    "    N_median = np.median(y_proba[np.array(y_test)==0])\n",
    "    P_median = np.median(y_proba[np.array(y_test)==1])\n",
    "    center = (N_median + P_median)/2\n",
    "    print ('N_median = %.3f, P_median = %.3f, center = %.3f' % (N_median, P_median, center))\n",
    "    \n",
    "    print ()\n",
    "    \n",
    "    return y_test, y_proba, y_pred, filename\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "de890369",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Linear_Transform_y_proba(y_test, y_proba, y_pred, filename):\n",
    "    print ('Linear_Transform_y_proba()')\n",
    "    print ()\n",
    "    \n",
    "    # I considered two methods.  \n",
    "    # One was to take the medians of the negative and positive classes and transform them to 0.25 and 0.75.\n",
    "    # That didn't always work the way I wanted.  \n",
    "    # Then I tried taking the 0.05 quantile to 0.05 and the 0.95 quantile to 0.95.\n",
    "    \n",
    "#    N_median = np.median(y_proba[np.array(y_test)==0])\n",
    "#    P_median = np.median(y_proba[np.array(y_test)==1])\n",
    "#    center = (N_median + P_median)/2\n",
    "#    print ('N_median = %.3f, P_median = %.3f, center = %.3f' % (N_median, P_median, center))\n",
    "#    y_proba = 0.25/(center - N_median) * (y_proba - center) + 0.5\n",
    "\n",
    "    \n",
    "    a = np.quantile(y_proba[np.array(y_test)==0],0.05)\n",
    "    b = np.quantile(y_proba[np.array(y_test)==1],0.95)\n",
    "    print ('a = %.3f, b = %.3f' % (a, b))\n",
    "    y_proba = 0.9/(b-a) * (y_proba - a) + 0.05\n",
    "    \n",
    "    y_proba = np.where (y_proba < 0.0, 0.0, y_proba)\n",
    "    y_proba = np.where (y_proba > 1.0, 1.0, y_proba)\n",
    "    y_pred = K.round(y_proba)\n",
    "\n",
    "    print ()\n",
    "    \n",
    "    return y_test, y_proba, y_pred, filename\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4a5d35d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Shift_y_proba_to_FP_equals_r_TP(y_test, y_proba, r_target, filename):\n",
    "    print ('Shift_y_proba_to_FP_equals_r_TP()')\n",
    "    print ('y_test is a ', type(y_test))\n",
    "    print ('y_proba is a ', type(y_proba))\n",
    "    print ()\n",
    "    \n",
    "    \n",
    "    A = pd.DataFrame(y_proba, columns=['HOSPITAL'])\n",
    "    B = pd.DataFrame(y_test, columns=['HOSPITAL'])\n",
    "    B = B.reset_index(drop=True)\n",
    "    C = A[B['HOSPITAL']==0]\n",
    "    D = A[B['HOSPITAL']==1]\n",
    "    n = 100\n",
    "    m = np.quantile(C, 0.005)\n",
    "    M = np.quantile(D,0.995)\n",
    "    print ('Quantiles ', m, M)\n",
    "    bins = [(M-m) * (x/n) + m for x in range (0, n+1)]\n",
    "    E = pd.cut(C['HOSPITAL'], bins=bins, include_lowest=False)\n",
    "    F = pd.cut(D['HOSPITAL'], bins=bins, include_lowest=False)\n",
    "    G = E.value_counts(sort=False)\n",
    "    H = F.value_counts(sort=False)\n",
    "\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame()\n",
    "    df['TP'] = G\n",
    "    df['FP'] = H\n",
    "    roll = 10\n",
    "    df['TP_RA'] = G.rolling(roll, center=True, min_periods=1).mean()\n",
    "    df['FP_RA'] = H.rolling(roll, center=True, min_periods=1).mean()\n",
    "    df['TP/FP'] = df['TP_RA']/df['FP_RA']\n",
    "    df['TP/FP_RA'] = df['TP/FP'].rolling(roll, center=True, min_periods=1).mean()\n",
    "    df['Truncate'] = np.where(df['TP/FP_RA']>2,2,df['TP/FP_RA'])\n",
    "    df['bins'] = bins[:-1]\n",
    "    df.fillna(0, inplace=True)\n",
    "    \n",
    "    #    display(df)\n",
    "    df_closest = df.iloc[(df['TP/FP_RA'] - r_target).abs().argsort()[:1]]\n",
    "    center = df_closest['bins'].to_numpy()\n",
    "    center = center[0]\n",
    "    center_index = df.index[df['bins'] == center].tolist()\n",
    "#    print (df_closest)\n",
    "    print ('center = ', center)\n",
    "#    print (center_index)\n",
    "    print ()\n",
    "    \n",
    "    print ('Plot TP/FP')\n",
    "    x = df['bins'].to_numpy()\n",
    "    y = df['TP/FP_RA'].to_numpy()\n",
    "    fig = plt.figure(figsize=(2.4,1.8)) # Create matplotlib figure\n",
    "    ax = fig.add_subplot(111) # Create matplotlib axes\n",
    "    \n",
    "    plt.plot(x,y, label='TP/FP', color='black')\n",
    "    plt.axhline(y=2.0, color='black', linestyle='--', label='2.0')  \n",
    "    plt.plot([center], [2.0], marker=\"o\", markersize=6, markerfacecolor='black', markeredgecolor='black')\n",
    "    plt.xticks(\n",
    "        ticks = [m, center, M], \n",
    "        labels = [round(m,3), round(center, 3), round(M,3)],\n",
    "        rotation=0\n",
    "    )\n",
    "    ax.legend()\n",
    "    plt.title('$\\Delta$TP/$\\Delta$FP')\n",
    "    plt.xlabel('$p$')\n",
    "    plt.ylabel('$\\Delta$TP/$\\Delta$FP')\n",
    "    plt.savefig('./Images/' + filename + '_TP_FP.png', bbox_inches=\"tight\")\n",
    "    plt.savefig('./Images/' + filename + '_TP_FP.pgf', bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    df['FP'] = G\n",
    "    df['TP'] = H\n",
    "    roll = 10\n",
    "    df['FP_RA'] = G.rolling(roll, center=True, min_periods=1).mean()\n",
    "    df['TP_RA'] = H.rolling(roll, center=True, min_periods=1).mean()\n",
    "    df['FP/TP'] = df['FP_RA']/df['TP_RA']\n",
    "    df['FP/TP_RA'] = df['FP/TP'].rolling(roll, center=True, min_periods=1).mean()\n",
    "    df['Truncate'] = np.where(df['FP/TP_RA']>2,2,df['FP/TP_RA'])\n",
    "    df['bins'] = bins[:-1]\n",
    "    df.fillna(0, inplace=True)\n",
    "    \n",
    "    #    display(df)\n",
    "    df_closest = df.iloc[(df['FP/TP_RA'] - r_target).abs().argsort()[:1]]\n",
    "    center = df_closest['bins'].to_numpy()\n",
    "    center = center[0]\n",
    "    center_index = df.index[df['bins'] == center].tolist()\n",
    "#    print (df_closest)\n",
    "    print ('center = ', center)\n",
    "#    print (center_index)\n",
    "    print ()\n",
    "    \n",
    "    print ('Plot FP/TP')\n",
    "    x = df['bins'].to_numpy()\n",
    "    y = df['FP/TP_RA'].to_numpy()\n",
    "    fig = plt.figure(figsize=(2.0,1.5)) # Create matplotlib figure\n",
    "    ax = fig.add_subplot(111) # Create matplotlib axes\n",
    "    \n",
    "    plt.plot(x,y, label='$\\Delta FP/\\Delta TP$', color='black')\n",
    "    plt.axhline(y=2.0, color='black', linestyle='--')  \n",
    "    plt.plot([center], [2.0], label='(%.3f,2)' % center, marker=\"o\", markersize=6, markerfacecolor='black', markeredgecolor='black')\n",
    "    plt.xticks(\n",
    "        ticks = [m, M], \n",
    "#        labels = [round(m,3), round(center, 3), round(M,3)],\n",
    "        labels = [round(m,3), round(M,3)],\n",
    "        rotation=0\n",
    "    )\n",
    "#    ax.annotate('data = (%.3f, %.1f)'%(center, 2.0),(center, 2.0), textcoords='data')\n",
    "#    plt.text(center,2.0,'(%.3f,%.1f)' % (center, 2.0),horizontalalignment='left', verticalalignment='bottom')\n",
    "#    plt.title('$\\Delta FP/\\Delta TP$')\n",
    "    plt.xlabel('$p$')\n",
    "    plt.ylabel('$\\Delta$FP/$\\Delta$TP')\n",
    "    ax.legend()\n",
    "    plt.savefig('./Images/' + filename + '_FP_TP.png', bbox_inches=\"tight\")\n",
    "    plt.savefig('./Images/' + filename + '_FP_TP.pgf', bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    # Re-center the distribution\n",
    "    y_proba = y_proba - center + 0.5\n",
    "\n",
    "    # Decide which direction to dilate the distribution\n",
    "    M = np.quantile(y_proba,0.995)\n",
    "    m = np.quantile(y_proba,0.005)\n",
    "    right = M-0.5\n",
    "    left = 0.5-m\n",
    "    # If the tail to the right is longer, map M to 1 and 0.5 to itself.\n",
    "    if left < right:\n",
    "        y_proba = (1/(2*M-1))*(y_proba - 0.5) + 0.5\n",
    "    # If the tail to the left is longer, map m to 0 and 0.5 to itself.\n",
    "    if left > right:\n",
    "        y_proba = (1/(1-2*m))*(y_proba - 0.5) + 0.5\n",
    "    print ('y_proba unique = ', np.unique(y_proba))\n",
    "    y_proba = np.clip(y_proba,0,1)\n",
    "    print ('y_proba unique = ', np.unique(y_proba))\n",
    "    print ('M, m, left, right = ', M, m, left, right)\n",
    "    y_pred = K.round(y_proba).numpy()\n",
    "    \n",
    "    return y_test, y_proba, y_pred, center, filename\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7d27e7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Balance_Proba(y_test, y_proba, y_pred, r_target, filename, title):\n",
    "    print ('Balance_Proba')\n",
    "    print (filename)\n",
    "\n",
    "    y_test, y_proba_New, y_pred_New, center, filename = Shift_y_proba_to_FP_equals_r_TP(y_test, y_proba, r_target, filename)\n",
    "\n",
    "    N = y_proba[np.array(y_test)==0]\n",
    "    P = y_proba[np.array(y_test)==1]\n",
    "    N_median = np.median(N)\n",
    "    P_median = np.median(P)\n",
    "\n",
    "    Plot_Prediction(y_test, y_proba, filename, title)\n",
    "#    ROC(y_test, y_proba, [center, N_median, P_median], filename)    \n",
    "    ROC(y_test, y_proba, [], filename)    \n",
    "    Evaluate_Model(y_test, y_proba, y_pred, center, filename)    \n",
    "    print ()\n",
    "\n",
    "    filename = filename + '_Linear_Transform'\n",
    "    title = title + ' Trans'\n",
    "\n",
    "    N = y_proba_New[np.array(y_test)==0]\n",
    "    P = y_proba_New[np.array(y_test)==1]\n",
    "    N_median = np.median(N)\n",
    "    P_median = np.median(P)\n",
    "    \n",
    "    Plot_Prediction(y_test, y_proba_New, filename, title)\n",
    "#    ROC(y_test, y_proba, [center, N_median, P_median], filename)    \n",
    "    ROC(y_test, y_proba, [], filename)    \n",
    "    Evaluate_Model(y_test, y_proba_New, y_pred_New, center, filename)    \n",
    "    print ()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5085583e",
   "metadata": {},
   "source": [
    "## Evaluate_Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "97848247",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Evaluate_Model(y_test, y_proba, y_pred, center, filename):\n",
    "    print ('Evaluate_Model()')\n",
    "    y_test = np.array(y_test)\n",
    "    y_pred = [round(x) for x in y_proba]\n",
    "    y_pred = np.array(y_pred)\n",
    "    print ('np.unique(y_proba) = ', np.unique(y_proba))\n",
    "    print ('np.unique(y_pred) = ', np.unique(y_pred))\n",
    "    CM = confusion_matrix(y_test, y_pred)\n",
    "    print(CM)\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n",
    "    auc_value = auc(fpr, tpr)\n",
    "    \n",
    "    CSV = [[filename, CM[0][0], CM[0][1], CM[1][0], CM[1][1], center, auc_value]]\n",
    "    np.savetxt('./Confusion_Matrices/' + filename + '.csv', \n",
    "        CSV,\n",
    "        delimiter =\", \", \n",
    "        fmt ='% s'\n",
    "              )\n",
    "    print ()\n",
    "    CM = confusion_matrix(y_test, y_pred, normalize='all')\n",
    "    print(CM)\n",
    "    print ()\n",
    "\n",
    "    y_pred = y_pred.ravel()\n",
    "    y_test = tf.convert_to_tensor(y_test)\n",
    "    y_pred = tf.convert_to_tensor(y_pred)\n",
    "\n",
    "    print ('%.3f & Precision \\cr ' %  Precision_Metric(y_test, y_pred).numpy())\n",
    "    print ('%.3f & Recall \\cr ' %  Recall_Metric(y_test, y_pred).numpy())\n",
    "    print ('%.3f & F1 \\cr ' %  F1_Metric(y_test, y_pred).numpy())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf928217",
   "metadata": {},
   "source": [
    "## Plot Prediction\n",
    "\n",
    "How to insert a .pgf plot into a \\LaTeX document:\n",
    "\n",
    "\\begin{figure}\n",
    "    \\begin{center}\n",
    "        \\input{Plot.pgf}\n",
    "    \\end{center}\n",
    "    \\caption{A PGF histogram from \\texttt{matplotlib}.}\n",
    "\\end{figure}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f3496ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Plot_Prediction(y_test, y_proba, filename, title):\n",
    "    print ('Plot_Prediction()')\n",
    "    print (filename)\n",
    "    \n",
    "#    print (y_test)\n",
    "#    print (y_proba)\n",
    "#    return 0\n",
    "#    y_test = y_test.numpy()\n",
    "    A = pd.DataFrame(y_proba, columns=['HOSPITAL'])\n",
    "    B = pd.DataFrame(y_test, columns=['HOSPITAL'])\n",
    "    B = B.reset_index(drop=True)\n",
    "    C = A[B['HOSPITAL']==0]\n",
    "    D = A[B['HOSPITAL']==1]\n",
    "#    bins = [x*0.05 for x in range (21)]\n",
    "#    bins = [x*0.10 for x in range (11)]\n",
    "    n = 10\n",
    "    bins= [x/n for x in range (0, n+1)]\n",
    "    print (bins)\n",
    "    E = pd.cut(C['HOSPITAL'], bins=bins, include_lowest=False)\n",
    "    F = pd.cut(D['HOSPITAL'], bins=bins, include_lowest=False)\n",
    "    \n",
    "    G = E.value_counts(sort=False)\n",
    "    H = F.value_counts(sort=False)\n",
    "\n",
    "    G = G/len(y_proba)*100\n",
    "    H = H/len(y_proba)*100\n",
    "\n",
    "    fig = plt.figure(figsize=(2.0,1.5)) # Create matplotlib figure\n",
    "    ax = fig.add_subplot(111) # Create matplotlib axes\n",
    "    \n",
    "    G.plot(kind='bar', fill=False, ax=ax, width=0.4, position=1)\n",
    "    H.plot(kind='bar', color='black', ax=ax, width=0.4, position=0)\n",
    "    plt.xticks(\n",
    "        ticks = [0, 2.5, 5, 7.5, 10], \n",
    "        labels = ['0.0', '0.25', '0.5', '0.75', '1.0'],\n",
    "        rotation=0\n",
    "    )\n",
    "    ax.legend(['Neg', 'Pos'])\n",
    "#    plt.title(title)\n",
    "    plt.xlabel('$p$')\n",
    "    plt.ylabel('Percent of Data Set')\n",
    "    plt.savefig('./Images/' + filename + '_Pred.png', bbox_inches=\"tight\")\n",
    "    plt.savefig('./Images/' + filename + '_Pred.pgf', bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    print ()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a04113",
   "metadata": {},
   "source": [
    "## ROC Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7e088e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 1]\n",
      "[0.553 0.543 0.454 ... 0.562 0.564 0.571]\n",
      "ROC()\n",
      "tmp\n",
      "p_values =  [0.5]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x150 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def ROC(y_test, y_proba, p_values, filename):\n",
    "    print ('ROC()')\n",
    "    print (filename)\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n",
    "    \n",
    "    N_median = np.median(y_proba[np.array(y_test)==0])\n",
    "    P_median = np.median(y_proba[np.array(y_test)==1])\n",
    "#    print ('N_median, P_median = ', N_median, P_median)\n",
    "\n",
    "    m = np.quantile(y_proba,0.50)\n",
    "    p = np.quantile(y_proba,0.25)\n",
    "    q = np.quantile(y_proba,0.75)\n",
    "    \n",
    "    Y = []\n",
    "    print ('p_values = ', p_values)\n",
    "    for X in p_values:\n",
    "        difference_array = np.absolute(thresholds-X)\n",
    "        index = difference_array.argmin()\n",
    "        F = fpr[index]\n",
    "        T = tpr[index]\n",
    "        Y.append([X,str(round(X,3)),F,T])\n",
    "    \n",
    "    auc_value = auc(fpr, tpr)\n",
    "    fig = plt.figure(figsize=(2.0,1.5)) # Create matplotlib figure\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.plot(fpr, tpr, color='black', label='AUC {:.3f})'.format(auc_value))\n",
    "    \n",
    "    for y in Y:\n",
    "#        plt.plot([y[2]], [y[3]], marker=\"o\", markersize=20, markeredgecolor=\"white\", markerfacecolor=\"white\")\n",
    "#        plt.annotate(\n",
    "#            y[1], # this is the text\n",
    "#            (y[2], y[3]), # these are the coordinates to position the label\n",
    "#            ha='center' # horizontal alignment can be left, right or center\n",
    "#        )\n",
    "        plt.text(\n",
    "            y[2], y[3], # these are the coordinates to position the label\n",
    "            y[1], # this is the text\n",
    "            backgroundcolor='white', # horizontal alignment can be left, right or center\n",
    "            bbox=dict(facecolor='white', edgecolor='none', boxstyle='square,pad=0.3')\n",
    "        )\n",
    "    plt.xlabel('False positive rate')\n",
    "    plt.ylabel('True positive rate')\n",
    "#    plt.title('ROC with AUC {:.3f}'.format(auc_value))\n",
    "    plt.legend(loc='best')\n",
    "    plt.savefig('./Images/' + filename + '_ROC.png', bbox_inches=\"tight\")\n",
    "    plt.savefig('./Images/' + filename + '_ROC.pgf', bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    print ()\n",
    "    return 0\n",
    "\n",
    "def Test_ROC():\n",
    "    y_test = [0,0,0,0,0,1]*10000\n",
    "#    y_proba = [abs(0.45 - y)+round(0.45*random.random(),2) for y in y_test]\n",
    "    y_proba = [abs(0.45 - y)+round(0.45*random.normalvariate(mu=0.2, sigma=0.2),3) for y in y_test]\n",
    "#    random.normalvariate(mu=0.0, sigma=1.0)\n",
    "    y_test = np.array(y_test)\n",
    "    y_proba = np.array(y_proba)\n",
    "    print (y_test)\n",
    "    print (y_proba)\n",
    "    ROC(y_test, y_proba, [0.5], \"tmp\")\n",
    "    \n",
    "Test_ROC()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdb935a",
   "metadata": {},
   "source": [
    "## Build Idealized Results Plots\n",
    "- The Plot_Prediciton and ROC_Curves functions take two lists (or np arrays) and a filename for saving the plots:\n",
    "    - ROC(y_test, y_proba, filename):\n",
    "    - Plot_Prediction(y_test, y_proba, filename):\n",
    "    - y_test is the {0,1} binary and \n",
    "    - y_proba is the (0,1) continuous\n",
    "- The Evaluate_Model(y_test, y_proba, y_pred, filename) takes three lists (or np arrays)\n",
    "    - y_test is the {0,1} binary ground truth,\n",
    "    - y_proba is the (0,1) continuous prediction, and\n",
    "    - y_pred is the discrete {0,1} binary version of y_proba\n",
    "- We want a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6e66bb65",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def Move_Threshold(y_proba, y_test):\n",
    "    print ('Move_Threshold()')\n",
    "    n = 10\n",
    "    T = [x/n for x in range (n+1)]\n",
    "    \n",
    "    print (type(y_proba))\n",
    "    print (type(y_test))\n",
    "    y_test = np.array(y_test)\n",
    "    print (type(y_test))\n",
    "    N = y_proba[y_test==0]\n",
    "    P = y_proba[y_test==1]\n",
    "    print (len(N), len(P))\n",
    "\n",
    "    A = [['t', 'TN', 'FP', 'FN', 'TP', 'TPR', 'FPR']]\n",
    "    for t in T:\n",
    "        TN = len(N[N<t])\n",
    "        FP = len(N[N>t])\n",
    "        FN = len(P[P<t])\n",
    "        TP = len(P[P>t])\n",
    "        TPR = TP/len(P)\n",
    "        FPR = FP/len(N)\n",
    "        A.append([t, TN, FP, FN, TP, TPR, FPR])\n",
    "    display(pd.DataFrame(A))\n",
    "    \n",
    "    print ()\n",
    "\n",
    "\n",
    "def Idealized_Results():\n",
    "    print ('Idealized_Results()')\n",
    "    # Set randomness\n",
    "    np.random.seed(42) # NumPy\n",
    "    random.seed(42) # Python\n",
    "    tf.random.set_seed(42) # Tensorflow    \n",
    "\n",
    "    shape, scale = 3.7, 0.1 # mean=4, std=2*sqrt(2)\n",
    "    a = np.random.gamma(shape, scale, 150771)\n",
    "    a = np.where(a>1.0, random.random(), a)\n",
    "    \n",
    "    shape, scale = 3.8, 0.1 # mean=4, std=2*sqrt(2)\n",
    "    b = np.random.gamma(shape, scale, 26621)    \n",
    "    b = np.where(b>1.0, random.random(), b)\n",
    "    b = 1-b\n",
    "    \n",
    "    y_proba = np.concatenate((a,b),axis=0)\n",
    "    Y_PROBA = np.concatenate((a,b),axis=0)\n",
    "    y_pred = K.round(y_proba)\n",
    "    y_test = [0]*len(a) + [1]*len(b)\n",
    "    N_median = np.median(a)\n",
    "    P_median = np.median(b)\n",
    "    \n",
    "    Move_Threshold(y_proba, y_test)\n",
    "    \n",
    "    filename = 'Ideal'\n",
    "    print (filename)\n",
    "    title = 'Original Example'\n",
    "    Plot_Prediction(y_test, y_proba, filename, title)\n",
    "    ROC(y_test, y_proba, [N_median, P_median], filename)    \n",
    "    Evaluate_Model(y_test, y_proba, y_pred, 0.5, filename)    \n",
    "    print ()\n",
    "    \n",
    "    filename = 'Ideal_Left'\n",
    "    title = 'Never Ambulance'\n",
    "    print (filename)\n",
    "    y_proba = 0.5 * y_proba\n",
    "    y_pred = K.round(y_proba)\n",
    "    Plot_Prediction(y_test, y_proba, filename, title)\n",
    "    ROC(y_test, y_proba, [N_median, 0.5, P_median], filename)    \n",
    "    Evaluate_Model(y_test, y_proba, y_pred, 0.5, filename)    \n",
    "    print ()\n",
    "\n",
    "    filename = 'Ideal_Left_Shifted'\n",
    "    title = ''\n",
    "    print (filename)\n",
    "    y_test, y_proba, y_pred, filename = Shift_y_proba(y_test, y_proba, y_pred, filename)\n",
    "    Plot_Prediction(y_test, y_proba, filename, title)\n",
    "    ROC(y_test, y_proba, [], filename)    \n",
    "    Evaluate_Model(y_test, y_proba, y_pred, 0.5, filename)    \n",
    "    print ()\n",
    "    \n",
    "    filename = 'Ideal_Left_Linear_Transform'\n",
    "    title = ''\n",
    "    print (filename)\n",
    "    y_test, y_proba, y_pred, filename = Linear_Transform_y_proba(y_test, y_proba, y_pred, filename)\n",
    "    Plot_Prediction(y_test, y_proba, filename, title)\n",
    "    ROC(y_test, y_proba, [], filename)    \n",
    "    Evaluate_Model(y_test, y_proba, y_pred, 0.5, filename)    \n",
    "    print ()\n",
    "    \n",
    "    filename = 'Ideal_Right'\n",
    "    title = 'Always Ambulance'\n",
    "    print (filename)\n",
    "    y_proba = 0.5 * Y_PROBA + 0.5\n",
    "    y_pred = K.round(y_proba)\n",
    "    Plot_Prediction(y_test, y_proba, filename, title)\n",
    "    ROC(y_test, y_proba, [N_median, 0.5, P_median], filename)    \n",
    "    Evaluate_Model(y_test, y_proba, y_pred, 0.5, filename)    \n",
    "    print ()\n",
    "\n",
    "    filename = 'Ideal_Right_Shifted'\n",
    "    title = ''\n",
    "    print (filename)\n",
    "    y_test, y_proba, y_pred, filename = Shift_y_proba(y_test, y_proba, y_pred, filename)\n",
    "    Plot_Prediction(y_test, y_proba, filename, title)\n",
    "    ROC(y_test, y_proba, [], filename)    \n",
    "    Evaluate_Model(y_test, y_proba, y_pred, 0.5, filename)    \n",
    "    print ()\n",
    "    \n",
    "    filename = 'Ideal_Right_Linear_Transform'\n",
    "    title = ''\n",
    "    print (filename)\n",
    "    y_test, y_proba, y_pred, filename = Linear_Transform_y_proba(y_test, y_proba, y_pred, filename)\n",
    "    Plot_Prediction(y_test, y_proba, filename, title)\n",
    "    ROC(y_test, y_proba, [], filename)    \n",
    "    Evaluate_Model(y_test, y_proba, y_pred, 0.5, filename)    \n",
    "    print ()\n",
    "    \n",
    "    y_proba = Y_PROBA\n",
    "    y_pred = K.round(y_proba)\n",
    "    y_test = [0]*len(a) + [1]*len(b)\n",
    "    \n",
    "    filename = 'Ideal_Tight'\n",
    "    title = 'Tight'\n",
    "    print (filename)\n",
    "    y_proba = 0.2 * Y_PROBA + 0.4\n",
    "    y_pred = K.round(y_proba)\n",
    "    Plot_Prediction(y_test, y_proba, filename, title)\n",
    "    ROC(y_test, y_proba, [N_median, 0.5, P_median], filename)    \n",
    "    Evaluate_Model(y_test, y_proba, y_pred, 0.5, filename)    \n",
    "    print ()\n",
    "   \n",
    "    y_proba = Y_PROBA\n",
    "    y_pred = K.round(y_proba)\n",
    "    y_test = [0]*len(a) + [1]*len(b)\n",
    "    \n",
    "    filename = 'Ideal_Shift_to_FP_equals_r_TP'\n",
    "    title = 'Transformed'\n",
    "    print (filename)\n",
    "    y_test, y_proba, y_pred, p_target, filename_tmp = Shift_y_proba_to_FP_equals_r_TP(y_test, y_proba, 2.0, filename)\n",
    "    print ('type(y_test) = ', type(y_test))\n",
    "    N = y_proba[np.array(y_test)==0]\n",
    "    P = y_proba[np.array(y_test)==1]\n",
    "    display(N)\n",
    "    N_median = np.median(N)\n",
    "    P_median = np.median(P)\n",
    "    Plot_Prediction(y_test, y_proba, filename, title)\n",
    "    ROC(y_test, y_proba, [N_median, P_median], filename)    \n",
    "    Evaluate_Model(y_test, y_proba, y_pred, 0.5, filename)    \n",
    "    print ()\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "#Idealized_Results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2a285425",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def Awful_Results():\n",
    "    # Set randomness\n",
    "    np.random.seed(42) # NumPy\n",
    "    random.seed(42) # Python\n",
    "    tf.random.set_seed(42) # Tensorflow    \n",
    "    \n",
    "    \n",
    "    shape, scale = 1.0, 0.5 # mean=4, std=2*sqrt(2)\n",
    "    a = np.random.random(600)   \n",
    "    \n",
    "    b = np.random.random(100)    \n",
    "    b = np.where(b>1.0, random.random(), b)\n",
    "    b = 1-b\n",
    "    \n",
    "    y_proba = np.concatenate((a,b),axis=0)\n",
    "    y_pred = K.round(y_proba)\n",
    "    y_test = [0]*len(a) + [1]*len(b)\n",
    "    \n",
    "    filename = 'Awful'\n",
    "    title = 'Awful'\n",
    "    Plot_Prediction(y_test, y_proba, filename, title)\n",
    "    ROC(y_test, y_proba, [], filename)    \n",
    "    Evaluate_Model(y_test, y_proba, y_pred, 0.5, filename)    \n",
    "    \n",
    "#Awful_Results()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c4a296",
   "metadata": {},
   "source": [
    "## Run Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "93eb0b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Run_Models(Features = 'Hard', Tomek = 0, Version = 1):\n",
    "    r_target = 2.0\n",
    "    alpha = r_target/(1+r_target)\n",
    "\n",
    "    \n",
    "    if Features == 'Hard':\n",
    "        read_filename_features = '_Thin'\n",
    "        write_filename_features = '_Hard'\n",
    "    if Features == 'Medium':\n",
    "        read_filename_features = '_Really_Thin'\n",
    "        write_filename_features = '_Medium'\n",
    "    if Features == 'Easy':\n",
    "        read_filename_features = '_Thin_to_Minimal'\n",
    "        write_filename_features = '_Easy'\n",
    "    if Tomek==0:\n",
    "        read_filename_tomek = '_before_Tomek'\n",
    "        write_filename_tomek = '_Tomek_0'\n",
    "    if Tomek==1:\n",
    "        read_filename_tomek = '_after_Tomek'\n",
    "        write_filename_tomek = '_Tomek_1'\n",
    "    if Tomek==2:\n",
    "        read_filename_tomek = '_after_Tomek_Twice'\n",
    "        write_filename_tomek = '_Tomek_2'\n",
    "    if Version==1:\n",
    "        filename_version = '_v1'\n",
    "        random_seed = 0\n",
    "    if Version==2:\n",
    "        filename_version = '_v2'\n",
    "        random_seed = 42\n",
    "\n",
    "    X_train = pd.read_csv('../../Big_Files/X_train' + read_filename_features + read_filename_tomek + filename_version + '.csv')\n",
    "    y_train = pd.read_csv('../../Big_Files/y_train' + read_filename_features + read_filename_tomek + filename_version + '.csv').squeeze()\n",
    "    X_test = pd.read_csv('../../Big_Files/X_test' + read_filename_features + read_filename_tomek + filename_version + '.csv')\n",
    "    y_test = pd.read_csv('../../Big_Files/y_test' + read_filename_features + read_filename_tomek + filename_version + '.csv').squeeze()\n",
    "\n",
    "    N = len(y_train)\n",
    "    n = len(y_train[y_train==1])\n",
    "    p = (N-n)/n\n",
    "    alpha_balanced = p/(p+1)\n",
    "    print ('p = ', p)\n",
    "    print ('alpha_balanced = ', alpha_balanced)\n",
    "    \n",
    "    np.random.seed(random_seed) # NumPy\n",
    "    random.seed(random_seed) # Python\n",
    "    tf.random.set_seed(random_seed) # Tensorflow\n",
    "    \n",
    "    \"\"\"\n",
    "    print ()\n",
    "    print ('------------------------------------------')\n",
    "    filename_model = 'KBFC'\n",
    "    filename = filename_model + write_filename_features + write_filename_tomek + '_alpha_balanced_gamma_0_0' + filename_version\n",
    "    title = 'Focal $\\gamma=0.0$'\n",
    "    print (filename)\n",
    "    print ('alpha_balanced = ', alpha_balanced)\n",
    "    gamma = 0.0\n",
    "    epochs=20\n",
    "    Keras_Binary_Focal_Crossentropy(X_train, X_test, y_train, y_test, r_target, alpha_balanced, gamma, epochs, filename, title)\n",
    "\n",
    "    np.random.seed(random_seed) # NumPy\n",
    "    random.seed(random_seed) # Python\n",
    "    tf.random.set_seed(random_seed) # Tensorflow\n",
    "    \n",
    "    print ()\n",
    "    print ('------------------------------------------')\n",
    "    filename_model = 'KBFC'\n",
    "    filename = filename_model + write_filename_features + write_filename_tomek + '_alpha_target_gamma_0_0' + filename_version\n",
    "    title = 'Focal $\\gamma=0.0$'\n",
    "    print (filename)\n",
    "    gamma = 0.0\n",
    "    epochs=20\n",
    "    Keras_Binary_Focal_Crossentropy(X_train, X_test, y_train, y_test, r_target, alpha, gamma, epochs, filename, title)\n",
    "\n",
    "    np.random.seed(random_seed) # NumPy\n",
    "    random.seed(random_seed) # Python\n",
    "    tf.random.set_seed(random_seed) # Tensorflow\n",
    "    \n",
    "    print ()\n",
    "    print ('------------------------------------------')\n",
    "    filename_model = 'KBFC'\n",
    "    filename = filename_model + write_filename_features + write_filename_tomek + '_alpha_0_5_gamma_0_0' + filename_version\n",
    "    title = 'Focal $\\gamma=0.0$'\n",
    "    print (filename)\n",
    "    gamma = 0.0\n",
    "    epochs=20\n",
    "    Keras_Binary_Focal_Crossentropy(X_train, X_test, y_train, y_test, r_target, 0.5, gamma, epochs, filename, title)\n",
    "\n",
    "\n",
    "    np.random.seed(random_seed) # NumPy\n",
    "    random.seed(random_seed) # Python\n",
    "    tf.random.set_seed(random_seed) # Tensorflow\n",
    "    \n",
    "    print ()\n",
    "    print ('------------------------------------------')\n",
    "    filename_model = 'KBFC'\n",
    "    filename = filename_model + write_filename_features + write_filename_tomek + '_alpha_target_gamma_0_5' + filename_version\n",
    "    title = 'Focal $\\gamma=0.5$'\n",
    "    print (filename)\n",
    "    gamma = 0.5\n",
    "    epochs=20\n",
    "    Keras_Binary_Focal_Crossentropy(X_train, X_test, y_train, y_test, r_target, alpha, gamma, epochs, filename, title)\n",
    "\n",
    "    np.random.seed(random_seed) # NumPy\n",
    "    random.seed(random_seed) # Python\n",
    "    tf.random.set_seed(random_seed) # Tensorflow\n",
    "    \n",
    "    print ()\n",
    "    print ('------------------------------------------')\n",
    "    filename_model = 'KBFC'\n",
    "    filename = filename_model + write_filename_features + write_filename_tomek + '_alpha_target_gamma_1_0' + filename_version\n",
    "    title = 'Focal $\\gamma=1.0$'\n",
    "    print (filename)\n",
    "    gamma = 1.0\n",
    "    epochs=20\n",
    "    Keras_Binary_Focal_Crossentropy(X_train, X_test, y_train, y_test, r_target, alpha, gamma, epochs, filename, title)\n",
    "\n",
    "    np.random.seed(random_seed) # NumPy\n",
    "    random.seed(random_seed) # Python\n",
    "    tf.random.set_seed(random_seed) # Tensorflow\n",
    "    \n",
    "    print ()\n",
    "    print ('------------------------------------------')\n",
    "    filename_model = 'KBFC'\n",
    "    filename = filename_model + write_filename_features + write_filename_tomek + '_alpha_target_gamma_2_0' + filename_version\n",
    "    title = 'Focal $\\gamma=2.0$'\n",
    "    print (filename)\n",
    "    gamma = 2.0\n",
    "    epochs=20\n",
    "    Keras_Binary_Focal_Crossentropy(X_train, X_test, y_train, y_test, r_target, alpha, gamma, epochs, filename, title)\n",
    "\n",
    "    \"\"\"\n",
    "    np.random.seed(random_seed) # NumPy\n",
    "    random.seed(random_seed) # Python\n",
    "    tf.random.set_seed(random_seed) # Tensorflow\n",
    "    \n",
    "    print ()\n",
    "    print ('------------------------------------------')\n",
    "    filename_model = 'KBFC'\n",
    "    filename = filename_model + write_filename_features + write_filename_tomek + '_alpha_target_gamma_5_0' + filename_version\n",
    "    title = 'Focal $\\gamma=5.0$'\n",
    "    print (filename)\n",
    "    gamma = 5.0\n",
    "    epochs=20\n",
    "    Keras_Binary_Focal_Crossentropy(X_train, X_test, y_train, y_test, r_target, alpha, gamma, epochs, filename, title)\n",
    "\n",
    "    return 0\n",
    "\n",
    "    print ()\n",
    "    print ('------------------------------------------')\n",
    "    filename_model = 'LRC'\n",
    "    filename = filename_model + write_filename_features + write_filename_tomek + '' + filename_version\n",
    "    title = 'LogReg'\n",
    "    Logistic_Regression_Classifier(X_train, X_test, y_train, y_test, r_target, filename, title)\n",
    "\n",
    "    print ()\n",
    "    print ('------------------------------------------')\n",
    "    filename_model = 'BRFC'\n",
    "    filename = filename_model + write_filename_features + write_filename_tomek + '' + filename_version\n",
    "    title = 'BRForest'\n",
    "    Balanced_Random_Forest_Classifier(X_train, X_test, y_train, y_test, r_target, filename, title)\n",
    "\n",
    "    print ()\n",
    "    print ('------------------------------------------')\n",
    "    filename_model = 'AdaBoost'\n",
    "    filename = filename_model + write_filename_features + write_filename_tomek + '' + filename_version\n",
    "    title = 'AdaBoost'\n",
    "    AdaBoost(X_train, X_test, y_train, y_test, r_target, filename, title)\n",
    "    \n",
    "    print ()\n",
    "    print ('------------------------------------------')\n",
    "    filename_model = 'Bagging'\n",
    "    filename = filename_model + write_filename_features + write_filename_tomek + '' + filename_version\n",
    "    title = 'BalBag'\n",
    "    Bagging(X_train, X_test, y_train, y_test, r_target, filename, title)\n",
    "\n",
    "    print ()\n",
    "    print ('------------------------------------------')\n",
    "    filename_model = 'RUSBoost'\n",
    "    filename = filename_model + write_filename_features + write_filename_tomek + '' + filename_version\n",
    "    title = 'RUSBoost'\n",
    "    estimator = DecisionTreeClassifier(\n",
    "        max_depth=1,\n",
    "        class_weight={0:(1+r_target)/(2*r_target), 1:(1+r_target)/(2*1)},\n",
    "    )\n",
    "    RUSBoost_Classifier(X_train, X_test, y_train, y_test, estimator, r_target, filename, title)\n",
    "\n",
    "    print ()\n",
    "    print ('------------------------------------------')\n",
    "    filename_model = 'EEC'\n",
    "    filename = filename_model + write_filename_features + write_filename_tomek + '' + filename_version\n",
    "    title = 'EasyEns'\n",
    "    Easy_Ensemble_Classifier(X_train, X_test, y_train, y_test, r_target, filename, title)\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a7b79ffa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p =  5.6637473033454615\n",
      "alpha_balanced =  0.849934285548619\n",
      "\n",
      "------------------------------------------\n",
      "KBFC_Hard_Tomek_0_alpha_target_gamma_5_0_v1\n",
      "Keras_Binary_Focal_Crossentropy\n",
      "alpha =  0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-05 09:23:58.222747: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_proba unique\n",
      "[0.01635994 0.02265758 0.02892492 ... 0.71977025 0.75557065 0.8307317 ]\n",
      "Balance_Proba\n",
      "KBFC_Hard_Tomek_0_alpha_target_gamma_5_0_v1\n",
      "Shift_y_proba_to_FP_equals_r_TP()\n",
      "y_test is a  <class 'pandas.core.series.Series'>\n",
      "y_proba is a  <class 'numpy.ndarray'>\n",
      "\n",
      "Quantiles  0.22291552647948265 0.6332842230796816\n",
      "center =  0.5430031098276378\n",
      "\n",
      "Plot FP/TP\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x150 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_proba unique =  [-0.34398967 -0.3338971  -0.32385314 ...  0.7832842   0.8406573\n",
      "  0.96110916]\n",
      "y_proba unique =  [0.         0.00000122 0.00005233 ... 0.7832842  0.8406573  0.96110916]\n",
      "M, m, left, right =  0.5707012644410133 0.1880037848651409 0.3119962151348591 0.07070126444101332\n",
      "Plot_Prediction()\n",
      "KBFC_Hard_Tomek_0_alpha_target_gamma_5_0_v1\n",
      "[0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOEAAACvCAYAAAAL4blmAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAVPklEQVR4nO3dz1Ma9/8H8CfmG52xjWzQzGQy0QlLe/BWEfoHRGzvFfSSWwO0104rkkumJ4X03gA95lAB/QPC4q2XIpuc6nSmrCZ2kszEwoIdM6ap+zn43S3rYtxdFxbk9ZhhRt4s8NLsK+/d90+HJEkSCCG2GbA7AEL6HSUhITajJCTEZpSEhNiMkpAQm1ESEmIzSkJCbEZJSIjN/s/Mm3Z2dnDr1i0AQL1eB8dxmJ6eVsrscHR0hBcvXuDKlStwOBy2xUEuPkmSsL+/jxs3bmBgwIJ6TDIhk8noKuuk3d1dCQA96NGxx+7uriXnru6asF6vI5vNwuFwoFAoaF4vl8u4e/eu3o+z3JUrVwAAu7u7GBkZsS0OcvE1Gg2Mj48r59x56U5Cp9OJQCCARCKBSqUCt9uten1xcdGSgMySL0FHRkYoCUlHWHXb45Ak4wO4i8UiZmZmLAnAKo1GA06nE/V6nZKQtJXV55qphpmZmRk8ePAAm5ubWF1dRbFYhN/vp5O/g54/f469vT1N+djYGCYmJmyIiJhlKgnj8ThYlkUgEABwnJTr6+v44osvLA2OtPb8+XNMTk7i4OBA89rw8DC2trYoEXuIqST0+XyYm5tDsVi0Oh6iw97eHg4ODvDo0SNMTk4q5VtbW7hz5w729vZ0JaEkSXj37h3+/fffdobbky5fvoxLly515LtMJeH29jYA9Y1pqVSimrDDJicn4fV6Tb337du3ePnyZcvalByf2zdv3sSHH37Y9u8ylYRTU1Pw+XwYHR1FoVAAx3FIJBJWx0ba5OjoCNvb27h06RJu3LiBwcFBGuDQRJIkvH79Gn/++Sc+/vjjtteIphtmstks0uk0JElCOp3G1NSU1bGRNnn79i2Ojo4wPj6O4eFhu8PpSteuXcPOzg7++eef7kxCAGBZFisrK1bGQjrMkiFXF1Qnrwx0JWEmk4EgCBgdHUUkEsHIyAjW19exvLwMURQRDAaxvLzc7lhJB5zW9dEO1J3y//SMbeM4Tkomk6rnAwMDUiaTkURRlPL5vLS0tGTJODqz6vW6BECq1+u2xtEJ5XJZAiCVy2Vd5Se9efNG+u2336Q3b96oyp89eyYNDw93bOzl8PCw9OzZM92/8+LiogRASqVSSnmlUpEikYjEsqyq/LxO+xtJkvXnmq6acHt7G999953yPJFIIBgMKmNF5+bmUK1WTf43QLrFaV0f7WC0O8Xr9YJlWYiiiGg0ivn5eTAMA5ZlkUqlkEwmEYlE2hpzu5i6J+Q4Dul0WlVGrWsXx3m6PtotFAqhWq0iHA4jl8sp5QzD2BfUOem6M6/VasrPmUwGAJTRMjJRFK2LipD3yGQy4DgO+Xze7lAsoasmDAaD8Pl8cDgcqFQqyOVyygTeJ0+eYGlpCaFQqJ1xEqJgGAaJRALhcBjBYFDzOsdx4HkeLMuiVCopfdj5fB6CIIBhGJTLZYRCIfA8b/sMIF1J6Ha7sbm5ie3tbdUUpnq9DgDUVUE6LhKJIJfLIRqNIpVKKeWCICAWi6FcLgMAqtWqcr8YDoeVqzqPx4NYLKa5orODoXvCk3MInU4nddIT26RSKXg8HkSjUVWZy+UCx3FKWalU6upGG9Od9YTYjWVZJBIJhEIhxGIxpdzr9apqODkBI5EIkskkGIZBNBoFy7Idj7kVSkLSM1p1gy0uLmJ1dVVpGFxYWEA4HFYdw3EcAoEARkdHbb//a4WSkGhsbW113XfwPI9YLIZqtYp4PK5qkMlkMtjc3ARwXAsmEgnEYjH4/X4A/7XkVyoVeDweMAwDl8uFUCjUFZepliThxsYGRFGkqUw9bmxsDMPDw7hz505Hvm94eBhjY2O6jvV6vS0XGJNfa+7XDAQCmgYXjuPg8XiURhy5Aad5crpdTCfh+vo6BEEAcDz1Y3Nzk5Kwx01MTGBra+tCjh0tFApYWFhQnrMsi4WFBeUctpOpJFxaWoIoiqhWq6qhRKT3TUxMXMhB1YlEAslkEhzHKQ0y1Wq1dy9HPR4PwuEwtre34XA4cOvWLWxsbFgdGyGW6sZGGcDkXhQsy+LZs2dwu90XZugQIXYxlYSiKIJlWTQaDezt7eHzzz9XjVowIhaLqcadCoKAZDKJfD6PZDJJY1LJhWfqcnRubk5ZoWtlZQXFYhE+n8/w5/A8j2QyiXg8rpSFQiFlyJEgCJrR8oRcNKZqwp2dHeXner0OURRVMy30EgRBNWrhZEsVy7Kq4UeEXESmkrA5MZxOJ+bm5gwnSz6f14yA5zgOLpdLVeZyucDzvOb9h4eHaDQaqgchvciWXZlEUWw5CfO0+79Ww5WWl5fx/fff6/o+ol8nJ2dLxrdBuZB014Tyrkybm5uoVCr4448/VA8jzb/ZbNbQKIVWyRmPx1Gv15XH7u6u7s8jvYfneUSjUTgcDsRiMaTTacRiMYRCoZ6/ZTE8lenhw4fn2pWJ4zjMz8+3fI1hGE2tV61WW9aaQ0NDGBoaMhUD6T3ymNB0Oo14PK6cE6Io4urVqyiXy127JMdZTN0TnkzAjY0NrK+v636/vHBwOp2GIAhYXl4Gz/On1o5mWl5Jf5AXe1pdXbU7FNM6Pnb0ZKJFo9FT53YJggCfz9fTi/iQ9qtWq/B4PHaHYZptY0dFUVRWbEskEohGo/B6vcjlcso0lFKpRH2E5FSiKGJ5eRmBQEAZA8rzvDI+VBAEBINB5RzNZrPKz81rz9jNtrGjDMNgcXFR06Ajz5YG0HIRH0LS6bRy5dR8FSVPT2puvZ+enkaxWEQ6nVbNuO+mdXJNJWHz2NEffvgB3377rdVxEXKqSCTS8hYllUppGmdYlkU2m0UwGMT09LQyhakbZk/IbB87SkgnuFwu1Go1ZDIZ/PXXX121RKepJJTHjo6MjGBlZQWLi4uaFbkJaZfTLiUXFhY0fYY8z2N+fh7Ly8sQBEHp6uimxj5Llrcw22dIuk+3jmLheV7phmhuyGsmJ1gymVQW/s3lcmAYBqOjo8qwyGq1qpplbzdDSdhoNJBOp1EqlSCKIrxeL6LRqLIaNyHtIq8jc1aLZvP6Ms0Ne906oRcwcDn64MEDMAyDn3/+GZIkwel0olAoYHp6Gvfu3WtnjIRcaLpqwrW1NZRKJdRqNTidTs3rX331FdbX12mhJ0JM0FUTchyHbDbbMgEB4OHDh6cuR0cIeT9dSahnufBuWVKckF6jKwmvXr1qyTGkuxwdHdkdQtfqZCuxrnvCSqWC/f399wZWqVQsC4q01+DgIAYGBvDixQtcu3YNg4ODtNNyE0mS8Pr1azgcDly+fLnt36crCeW+l9NIkgSHw4Hl5WXLAiPtMzAwALfbjZcvX+LFixd2h9OVHA4Hbt68iUuXLrX9u3QlYSQSeW//jCRJWFpasiwo0n6Dg4OYmJjAu3fvlJXzyH8uX77ckQQEdCZhNBo9tWW0+RjSW+TLrU5ccpHT6WqY0bMbL+3YS4g5pgZwE0KsQ0lIiM0oCQmx2ZlJWK/X4ff7aYVrQtrkzCTc3NxELpfDyMiIUvbTTz9pjjOy5CEh5D9ndlH4fD6Ew2F8+umnymzkXC6nWRW7UCjQLApCTDizJnQ6nchkMnC73ajVaqjVapAkSfP466+/OhEvIReOrs56eeclWSAQ0PQLGtlbghDyH1NrzExNTaHRaCCbzQIA5ufnqbOeEJNMdVFsb2/j9u3bePz4MR4/fozp6Wk8ffrU4tAI6Q+masK1tTVsbm6qyuLxOD755BMrYiKkr5iqCd1ut6aMdk4ixBxTSXhyb3ng+BKVEGKcqcvRQCCAzz77DNPT0wCOF4Lqlh1uCOk1pmrCqakppFIppY8wnU7j9u3bVsdGSF8wvQy+2+3GysqKqffKe8gBQKlUQiaTUUbjCIKAfD6v7C932g48hFwUluxFYRTHccqy5MlkEjMzMyiXywCAUCik/CwIAsLhMG0USi60jk9l4nletSBUMBgEz/MQBEHT4MOyrGaXHUIumo4nodfrRSaTUZ7LA8FdLpeya04zl8sFnuc7GSIhHWXL5Wjzbjmrq6sIBAJgGEYzM0PWaj+6w8NDHB4eKs9pviPpVaZqwp2dHeXner2OtbU1VZleoigin8+fec/XKjmXl5fhdDqVx/j4uOHvJ6QbmErC5vs0eYaFmXu3WCyGQqGgtH4yDKOp9arVasvW0Xg8jnq9rjx2d3cNfz8h3UD35Wi9Xkc2m4XD4Wi5A1O5XMbdu3d1f3EymUQsFgPLskpNFwgEkEqlNMe2GhI3NDSEoaEh3d9HSLfSnYROpxOBQACJRAKVSkUzftTITqj5fB5er1dJwGw227I/UBAE+Hw+6ie02PPnz7G3t6cpHxsbw8TEhA0R9TdDDTNutxsPHz5EsVg0vU+9IAgIhUKqMoZhEIlEABwvnRGLxeD3+5U9x4l1nj9/jsnJSRwcHGheGx4extbWFiVih5lqHW2VgDs7O7r2rmdZ9r27O7Esq4xDbW5FJdbY29vDwcEBHj16hMnJSaV8a2sLd+7cwd7eHiVhh5nuonj69KmqESWVSmF1ddWSoEj7TU5Owuv12h0GgckknJ+fhyiKqnu1J0+eWBUTIX3FVBLOzs4iHA6rytbW1iwJiJB+Y6qf0OPx6CojhJzNVE1YqVSQSqXg9/sBHG8Sms1mUSqVLA2OkH5gqiZMpVJwu93KpF4A723xJISczlRNmEgkNN0UtPgvIeaYqglnZmbw4MEDLCwsAACKxSLdExJikqkkjMfjYBhGqf1mZmZo8i0hJplKQnmnJpZlrY6HkL5j6p5QXmPU4XAoZaVSibZGM4gGUhPgHBvC+Hw+jI6OolAo0LqjJtBAaiIzPYA7l8spa4+m02nalckgGkhNZKaSUF7S4t69exgZGUGxWESj0VBtqU30oYHUxFTDTDabVd3LUOsoIeaZqglHR0c1A7gJIeaYqgl//fVX7O/vq8po3Cgh5piqCSORCKampuDxeMAwDHieb7lAEyHkbKaSkGVZlMtlZLNZiKKIlZWVlhuHEkLOZioJ/X4/4vE43RdeQPKek81ohkx7mbonjEQimtExGxsblgRESL8xVRM6HA58/fXX8Hg8YFkW1WoVuVyONgolxARTSbiysoJAIIC9vT2lv7DVpi2EkLOZSsJUKqWZ1FssFi0JiJB+Y9mkXnm9GWK/6elpOBwO1YN0L5rUS4jNaFIvITYzlYSnTeolhBhHk3oJsZnphplcLoepqSllUi/1ERJiju6a8OnTp1hdXcVHH32EL7/8Em63GysrK+2MjZC+oCsJi8UiZmdnldExjx8/bts2aIIgIJ/Pg2VZCILQcgdfQi4SXUmYTqdRq9XgdDoBAEtLS7o3BTUqFAqhXC4DOE7IcDjctbv10mppxAq6ktDtdisJCBz3ExaLRcuTUBAE1XOWZbu2/5FWSyNW0dUwc3KJe6fTqZne8vTp03MHw3EcXC6XqszlcoHn+XN/ttWaV0srl8vK49GjRzg4OGhZQ15kJ0fo0Egd/XTVhIIgYH9/X5V429vbSlm1WkUqlcKPP/54rmBEUWxZ3mpw+OHhIQ4PD5Xn9XodAPDLL7/ggw8+AABcv34d169ff+93vnr1Cq9evdKUn/Xev//+GwBwcHCg/Cw/l19vNBpnvr9cLqve//vvvwNoPa9P/h3Pem8rcizneS9w+t/rPO9t57/Ted/bivw7WTbPUtLB4XBIAwMDqkdzmfzzeSUSCSkQCKjKWJaVcrmc5tj79+9LAOhBD9selUrl3Oe8JEmSrpowEom8tzNekiRLuisYhtHUetVqtWXraDwexzfffKM8Pzo6QrVaxejoKBwOBxqNBsbHx7G7u9tV66FSXMZ0Y1z1eh0TExOaWyezdCVhNBpVNcy0Is+oOI9AINBywSifz6cpGxoawtDQkKqsVbKOjIx0zT9eM4rLmG6Ma2DA1FgX7efoOUjPEvdWLIN/ckC4IAjw+XzUT0guNFNjR9spl8shFovB7/ejVCp1bR8hIVbpuiRkWVa5/wwGg6Y/Z2hoCPfv39dcstqN4jKmG+OyOiaHJNF6doTYyZo7S0KIaZSEhNiMkpAQm3Vdw4wRRqY9tXuKlJHP53leGZheKpWQyWSUY+Vxsl6vF4IgQBRFyzYRNRpjN8SRz+eVBcVOHtPOGOXPD4fDyqye05z73LJk3I1NvF6v8nOlUpGCwaAlx7Y7lkQiofq5+b2RSEQZFhUIBKRarWZLjN0SB1oMF5P/fu2MMZfLSeVyWdKTIuc9t3o2CSuViuqXlyRJYhjm3Me2O5Zyuax6rVKpqMYhplIpqVarWXpCGY2xW+Ko1WqaccPN/4G1K8ZmZyWhFedWz94TGpn21O4pUkY+3+v1IpPJKM/lmSPN72cYxvJRQmb+Bt0QR3NfcT6f1/QdtyNGI6w4t3r2ntDItCcjx7Y7FkB9Yq2uriIQCCgnkiiKyOfzAI7vF6PRqCXruxqNsRviaE4uURRRrVZVMbQrRiOsOLd6NglPc9of5bzHmnHW58snUfONf/NNPcuymJ2dRaVS6XiM3RKHLBaLaWbydDpGI4ycWz17OWpk2pORY9sdS7NYLIZCoaA6rnmJD7m17eSyH52IsVviAI5PaI7jNMe0K0YjrDi3ejYJ5Wbrk1pNezJybLtjkSWTScRiMbAsC1EUIYoieJ7X7HYFwJJ5a0Zi7JY4ZJubmy27J9oVoxFWnFs9m4RnTXvieV75X7HdU6SMxAIcNzB4vV4lAbPZLBiGUQ1eB45v+oPBoCVxGv17dUMcMp7nNcnVzhhPOnlpafW51dMDuAVBQCqVUqY9ybtFAcdLJ/r9fiwuLp55bCdjEQRBs3AWwzCo1WoA/uvIZxgGlUrF0u0FjPy9uiUO4PiqoVKpaCZ8tzNGjuNQKBSQTCaxuLgIv9+vNKhZfW71dBISchH07OUoIRcFJSEhNqMkJMRmlISE2IySkBCbURISYjNKQkJsRklIiM0oCQmxGSUhITa7cPMJiT7ywPFyuYxQKAQAKBQKtkyM7XdUE/YpjuMQiUSU5RkCgQBmZ2cRi8XsDq3vUBL2qWAwqEzRkZcJ7PSEWHKMkrCPcRynmpRaKBQwOztrY0T9iZKwj5VKJUxPTwOAsjREJBKxOar+Qw0zfYzjOHg8HuTzeZRKJRSLRbtD6ks0qbePeTyerlmdrJ/R5Wif4jjO0n0biHmUhH1IEAQkEgmIokgtol2ALkcJsRnVhITYjJKQEJtREhJiM0pCQmxGSUiIzSgJCbEZJSEhNqMkJMRmlISE2Ox/IEaRXUAqrJYAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 200x150 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ROC()\n",
      "KBFC_Hard_Tomek_0_alpha_target_gamma_5_0_v1\n",
      "p_values =  []\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x150 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluate_Model()\n",
      "np.unique(y_proba) =  [0.01635994 0.02265758 0.02892492 ... 0.71977025 0.75557065 0.8307317 ]\n",
      "np.unique(y_pred) =  [0 1]\n",
      "[[117906  32865]\n",
      " [ 10516  16105]]\n",
      "\n",
      "[[0.66466357 0.18526766]\n",
      " [0.05928114 0.09078763]]\n",
      "\n",
      "0.329 & Precision \\cr \n",
      "0.605 & Recall \\cr \n",
      "0.426 & F1 \\cr \n",
      "\n",
      "Plot_Prediction()\n",
      "KBFC_Hard_Tomek_0_alpha_target_gamma_5_0_v1_Linear_Transform\n",
      "[0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x150 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ROC()\n",
      "KBFC_Hard_Tomek_0_alpha_target_gamma_5_0_v1_Linear_Transform\n",
      "p_values =  []\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x150 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluate_Model()\n",
      "np.unique(y_proba) =  [0.         0.00000122 0.00005233 ... 0.7832842  0.8406573  0.96110916]\n",
      "np.unique(y_pred) =  [0 1]\n",
      "[[143657   7114]\n",
      " [ 19351   7270]]\n",
      "\n",
      "[[0.80982795 0.04010327]\n",
      " [0.10908609 0.04098268]]\n",
      "\n",
      "0.505 & Precision \\cr \n",
      "0.273 & Recall \\cr \n",
      "0.355 & F1 \\cr \n",
      "\n",
      "\n",
      "CPU times: user 9min 48s, sys: 9.38 s, total: 9min 57s\n",
      "Wall time: 9min 51s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "Run_Models(Features = 'Hard', Tomek = 0, Version = 1)\n",
    "#Run_Models(Features = 'Hard', Tomek = 1, Version = 1)\n",
    "#Run_Models(Features = 'Hard', Tomek = 2, Version = 1)\n",
    "#Run_Models(Features = 'Medium', Tomek = 0, Version = 1)\n",
    "#Run_Models(Features = 'Easy', Tomek = 0, Version = 1)\n",
    "\n",
    "#Run_Models(Features = 'Hard', Tomek = 0, Version = 2)\n",
    "#Run_Models(Features = 'Hard', Tomek = 1, Version = 2)\n",
    "#Run_Models(Features = 'Hard', Tomek = 2, Version = 2)\n",
    "#Run_Models(Features = 'Medium', Tomek = 0, Version = 2)\n",
    "#Run_Models(Features = 'Easy', Tomek = 0, Version = 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c238c61",
   "metadata": {},
   "source": [
    "# Main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "07093edf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<unknown>, line 486)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[1;32m~/miniforge3/envs/Tensorflow_2_11/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3460\u001b[0m in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0m  Cell \u001b[1;32mIn[53], line 1\u001b[0m\n    get_ipython().run_cell_magic('time', '', 'def Main():\\n    target = \\'HOSPITAL\\'\\n    r_target = 2.0\\n    alpha_target = r_target/(r_target+1)\\n    \\n\\n    # These functions run Tomek Links twice on all three versions of the dataset,\\n    # then save the results to file.  \\n#    Undersample_Data_Thin()\\n#    Undersample_Data_Really_Thin()\\n#    Undersample_Data_Thin_to_Minimal()\\n\\n    data = Get_Data()\\n    data = data.astype(\\'int64\\')\\n    \\n    data = Remove_Pedestrian_Crashes(data)\\n    data = Feature_Engineering_Cross_Two(data)\\n\\n    N = len(data)\\n    n = len(data[data[target]==1])\\n    print (\\'%d samples, %d hospitalized, %d not hospitalized\\' % (N, n, N-n))\\n    print (\\'%f percent of samples hospitalized\\' % (n/N*100))\\n    print (\\'There are %f negative samples for each positive.\\' % ((N-n)/n))\\n    print ()\\n            \\n    data = Thin_Features(data)\\n#    data = Really_Thin_Features(data)\\n#    data = Thin_to_Minimal_Features(data)\\n    for feature in data:\\n        print (feature)\\n    print ()\\n    \\n    # Alternate dataset, for debugging\\n#    file_url = \"http://storage.googleapis.com/download.tensorflow.org/data/heart.csv\"\\n#    data = pd.read_csv(file_url)\\n#    target = \\'target\\'\\n\\n    # Decrease set size, for debugging\\n#    X_train, X_test, y_train, y_test = Split_Data(data, target, 0.95)\\n#    data = X_train\\n#    data[\\'HOSPITAL\\'] = y_train\\n\\n    data = Get_Dummies(data, target)\\n    X_train, X_test, y_train, y_test = Split_Data(data, target, 0.30)\\n    \\n    print (\\'X_train.shape = \\', X_train.shape)\\n    print (\\'X_test.shape = \\', X_test.shape)\\n    print (\\'y_train.shape = \\', y_train.shape)\\n    print (\\'y_test.shape = \\', y_test.shape)\\n    print ()\\n    \\n    print (\\'type(X_train): \\', type(X_train))\\n    print (\\'type(X_test): \\', type(X_test))\\n    print (\\'type(y_train): \\', type(y_train))\\n    print (\\'type(y_test): \\', type(y_test))\\n    print ()\\n    \\n    \\n    \\n    print (\\'X_train.shape = \\', X_train.shape)\\n    print (\\'X_test.shape = \\', X_test.shape)\\n    print (\\'y_train.shape = \\', y_train.shape)\\n    print (\\'y_test.shape = \\', y_test.shape)\\n    print ()\\n    \\n    print (\\'type(X_train): \\', type(X_train))\\n    print (\\'type(X_test): \\', type(X_test))\\n    print (\\'type(y_train): \\', type(y_train))\\n    print (\\'type(y_test): \\', type(y_test))\\n    print ()\\n    \\n    \\n    ##### Without Tomek\\n    print (\\'Without Tomek\\')\\n    print ()\\n    \\n    version = \\'_v1\\'\\n    X_train = pd.read_csv(\\'../../Big_Files/X_train_Thin_before_Tomek_v1.csv\\')\\n    y_train = pd.read_csv(\\'../../Big_Files/y_train_Thin_before_Tomek_v1.csv\\').squeeze()\\n    X_test = pd.read_csv(\\'../../Big_Files/X_test_Thin_before_Tomek_v1.csv\\')\\n    y_test = pd.read_csv(\\'../../Big_Files/y_test_Thin_before_Tomek_v1.csv\\').squeeze()\\n    \\n    \\n    N = len(y_train)\\n    n = len(y_train[y_train==1])\\n    p = (N-n)/n\\n    alpha = p/(p+1)\\n    weights = class_weight.compute_class_weight(\\'balanced\\',\\n                                            classes = np.unique(y_train),\\n                                            y = y_train).astype(\\'float32\\')\\n\\n    # Weights for each class = (nSamples Total)/(2* (nSamples in Class))\\n#    weights = [1.0,1.0]\\n#    weights = [0.55,5.5]\\n\\n    print ()\\n\\n    \"\"\"\\n    print ()\\n    print (\\'------------------------------------------\\')\\n    filename = \\'OBFC_Hard_Tomek_0_alpha_target_gamma_0_0\\'\\n    title = \\'Focal $\\\\gamma=0.0$\\'\\n    print (filename)\\n    gamma_0 = 0.0\\n    gamma_1 = 0.0\\n    epochs=20\\n    Our_Binary_Focal_Crossentropy(X_train, X_test, y_train, y_test, r_target, gamma_0, gamma_1, epochs, filename, title)\\n    \"\"\"\\n\\n    np.random.seed(42) # NumPy\\n    random.seed(42) # Python\\n    tf.random.set_seed(42) # Tensorflow\\n\\n    print ()\\n    print (\\'------------------------------------------\\')\\n    filename = \\'KBFC_Hard_Tomek_0_alpha_target_gamma_0_0\\'\\n    filename = filename + version\\n    title = \\'Focal $\\\\gamma=0.0$\\'\\n    print (filename)\\n    gamma = 0.0\\n    epochs=20\\n    Keras_Binary_Focal_Crossentropy(X_train, X_test, y_train, y_test, r_target, alpha_target, gamma, epochs, filename, title)\\n\\n    np.random.seed(42) # NumPy\\n    random.seed(42) # Python\\n    tf.random.set_seed(42) # Tensorflow\\n\\n    print ()\\n    print (\\'------------------------------------------\\')\\n    filename = \\'KBFC_Hard_Tomek_0_alpha_target_gamma_0_5\\'\\n    title = \\'Focal $\\\\gamma=0.5$\\'\\n    print (filename)\\n    gamma = 0.5\\n    epochs=20\\n    Keras_Binary_Focal_Crossentropy(X_train, X_test, y_train, y_test, r_target, alpha_target, gamma, epochs, filename, title)\\n\\n    np.random.seed(42) # NumPy\\n    random.seed(42) # Python\\n    tf.random.set_seed(42) # Tensorflow\\n\\n    print ()\\n    print (\\'------------------------------------------\\')\\n    filename = \\'KBFC_Hard_Tomek_0_alpha_target_gamma_1_0\\'\\n    title = \\'Focal $\\\\gamma=1.0$\\'\\n    print (filename)\\n    gamma = 1.0\\n    epochs=20\\n    Keras_Binary_Focal_Crossentropy(X_train, X_test, y_train, y_test, r_target, alpha_target, gamma, epochs, filename, title)\\n\\n    np.random.seed(42) # NumPy\\n    random.seed(42) # Python\\n    tf.random.set_seed(42) # Tensorflow\\n\\n    print ()\\n    print (\\'------------------------------------------\\')\\n    filename = \\'KBFC_Hard_Tomek_0_alpha_target_gamma_2_0\\'\\n    title = \\'Focal $\\\\gamma=2.0$\\'\\n    print (filename)\\n    gamma = 2.0\\n    epochs=20\\n    Keras_Binary_Focal_Crossentropy(X_train, X_test, y_train, y_test, r_target, alpha_target, gamma, epochs, filename, title)\\n\\n    np.random.seed(42) # NumPy\\n    random.seed(42) # Python\\n    tf.random.set_seed(42) # Tensorflow\\n\\n    print ()\\n    print (\\'------------------------------------------\\')\\n    filename = \\'KBFC_Hard_Tomek_0_alpha_target_gamma_5_0\\'\\n    title = \\'Focal $\\\\gamma=5.0$\\'\\n    print (filename)\\n    gamma = 5.0\\n    epochs=20\\n    Keras_Binary_Focal_Crossentropy(X_train, X_test, y_train, y_test, r_target, alpha_target, gamma, epochs, filename, title)\\n\\n    print ()\\n    print (\\'------------------------------------------\\')\\n    filename = \\'LRC_Hard_Tomek_0_r_target\\'\\n    title = \\'LogReg\\'\\n    Logistic_Regression_Classifier(X_train, X_test, y_train, y_test, r_target, filename, title)\\n\\n    print ()\\n    print (\\'------------------------------------------\\')\\n    filename = \\'BRFC_Hard_Tomek_0_r_target\\'\\n    title = \\'BRForest\\'\\n    Balanced_Random_Forest_Classifier(X_train, X_test, y_train, y_test, r_target, filename, title)\\n\\n    print ()\\n    print (\\'------------------------------------------\\')\\n    filename = \\'AdaBoost_Hard_Tomek_0\\'\\n    title = \\'AdaBoost\\'\\n    AdaBoost(X_train, X_test, y_train, y_test, r_target, filename, title)\\n    print ()\\n    print (\\'------------------------------------------\\')\\n    filename = \\'Bagging_Hard_Tomek_0\\'\\n    title = \\'BalBag\\'\\n    Bagging(X_train, X_test, y_train, y_test, r_target, filename, title)\\n\\n    print ()\\n    print (\\'------------------------------------------\\')\\n    filename = \\'RUSB_Hard_Tomek_0\\'\\n    title = \\'RUSBoost\\'\\n    estimator = DecisionTreeClassifier(\\n        max_depth=1,\\n        class_weight={0:(1+r_target)/(2*r_target), 1:(1+r_target)/(2*1)},\\n    )\\n    RUSBoost_Classifier(X_train, X_test, y_train, y_test, estimator, r_target, filename, title)\\n\\n    print ()\\n    print (\\'------------------------------------------\\')\\n    filename = \\'EEC_Hard_Tomek_0\\'\\n    title = \\'EasyEns\\'\\n    Easy_Ensemble_Classifier(X_train, X_test, y_train, y_test, r_target, filename, title)\\n    \\n    #####\\n    #\\n    # With Tomek Once\\n    #\\n    #####\\n    \\n    print ()\\n    print (\"Tomek once\")\\n    \\n    X_train = pd.read_csv(\\'../../Big_Files/X_train_Thin_after_Tomek_v2.csv\\')\\n    y_train = pd.read_csv(\\'../../Big_Files/y_train_Thin_after_Tomek_v2.csv\\').squeeze()\\n    X_test = pd.read_csv(\\'../../Big_Files/X_test_Thin_after_Tomek_v2.csv\\')\\n    y_test = pd.read_csv(\\'../../Big_Files/y_test_Thin_after_Tomek_v2.csv\\').squeeze()\\n    \\n    print ()\\n\\n    np.random.seed(42) # NumPy\\n    random.seed(42) # Python\\n    tf.random.set_seed(42) # Tensorflow\\n\\n    print ()\\n    print (\\'------------------------------------------\\')\\n    filename = \\'KBFC_Hard_Tomek_1_alpha_target_gamma_0_0\\'\\n    title = \\'Focal $\\\\gamma=0.0$\\'\\n    print (filename)\\n    gamma = 0.0\\n    epochs=20\\n    Keras_Binary_Focal_Crossentropy(X_train, X_test, y_train, y_test, r_target, alpha_target, gamma, epochs, filename, title)\\n\\n    np.random.seed(42) # NumPy\\n    random.seed(42) # Python\\n    tf.random.set_seed(42) # Tensorflow\\n\\n    print ()\\n    print (\\'------------------------------------------\\')\\n    filename = \\'KBFC_Hard_Tomek_1_alpha_target_gamma_0_5\\'\\n    title = \\'Focal $\\\\gamma = 0.5$\\'\\n    print (filename)\\n    gamma = 0.5\\n    epochs=20\\n    Keras_Binary_Focal_Crossentropy(X_train, X_test, y_train, y_test, r_target, alpha_target, gamma, epochs, filename, title)\\n\\n    np.random.seed(42) # NumPy\\n    random.seed(42) # Python\\n    tf.random.set_seed(42) # Tensorflow\\n\\n    print ()\\n    print (\\'------------------------------------------\\')\\n    filename = \\'KBFC_Hard_Tomek_1_alpha_target_gamma_1_0\\'\\n    title = \\'Focal $\\\\gamma = 1.0$\\'\\n    print (filename)\\n    gamma = 1.0\\n    epochs=20\\n    Keras_Binary_Focal_Crossentropy(X_train, X_test, y_train, y_test, r_target, alpha_target, gamma, epochs, filename, title)\\n\\n    np.random.seed(42) # NumPy\\n    random.seed(42) # Python\\n    tf.random.set_seed(42) # Tensorflow\\n\\n    print ()\\n    print (\\'------------------------------------------\\')\\n    filename = \\'KBFC_Hard_Tomek_1_alpha_target_gamma_2_0\\'\\n    title = \\'Focal $\\\\gamma = 2.0$\\'\\n    print (filename)\\n    gamma = 2.0\\n    epochs=20\\n    Keras_Binary_Focal_Crossentropy(X_train, X_test, y_train, y_test, r_target, alpha_target, gamma, epochs, filename, title)\\n\\n    np.random.seed(42) # NumPy\\n    random.seed(42) # Python\\n    tf.random.set_seed(42) # Tensorflow\\n\\n    print ()\\n    print (\\'------------------------------------------\\')\\n    filename = \\'KBFC_Hard_Tomek_1_alpha_target_gamma_5_0\\'\\n    title = \\'Focal $\\\\gamma = 5.0$\\'\\n    print (filename)\\n    gamma = 5.0\\n    epochs=20\\n    Keras_Binary_Focal_Crossentropy(X_train, X_test, y_train, y_test, r_target, alpha_target, gamma, epochs, filename, title)\\n    \\n    print ()\\n    print (\\'------------------------------------------\\')\\n    filename = \\'LRC_Hard_Tomek_1_r_target\\'\\n    title = \\'LogReg\\'\\n    Logistic_Regression_Classifier(X_train, X_test, y_train, y_test, r_target, filename, title)\\n\\n    print ()\\n    print (\\'------------------------------------------\\')\\n    filename = \\'BRFC_Hard_Tomek_1_r_target\\'\\n    title = \\'BRForest\\'\\n    Balanced_Random_Forest_Classifier(X_train, X_test, y_train, y_test, r_target, filename, title)\\n\\n    print ()\\n    print (\\'------------------------------------------\\')\\n    filename = \\'AdaBoost_Hard_Tomek_1\\'\\n    title = \\'AdaBoost\\'\\n    AdaBoost(X_train, X_test, y_train, y_test, r_target, filename, title)\\n    print ()\\n    print (\\'------------------------------------------\\')\\n    filename = \\'Bagging_Hard_Tomek_1\\'\\n    title = \\'BalBag\\'\\n    Bagging(X_train, X_test, y_train, y_test, r_target, filename, title)\\n\\n    print ()\\n    print (\\'------------------------------------------\\')\\n    filename = \\'RUSB_Hard_Tomek_1\\'\\n    title = \\'RUSBoost\\'\\n    estimator = DecisionTreeClassifier(\\n        max_depth=1,\\n        class_weight={0:(1+r_target)/(2*r_target), 1:(1+r_target)/(2*1)},\\n    )\\n    RUSBoost_Classifier(X_train, X_test, y_train, y_test, estimator, r_target, filename, title)\\n\\n    print ()\\n    print (\\'------------------------------------------\\')\\n    filename = \\'EEC_Hard_Tomek_1\\'\\n    title = \\'EasyEns\\'\\n    Easy_Ensemble_Classifier(X_train, X_test, y_train, y_test, r_target, filename, title)\\n\\n\\n    #####\\n    #\\n    # With Tomek Twice\\n    #\\n    #####\\n    \\n    X_train = pd.read_csv(\\'../../Big_Files/X_train_Thin_after_Tomek_Twice_v1.csv\\')\\n    y_train = pd.read_csv(\\'../../Big_Files/y_train_Thin_after_Tomek_Twice_v1.csv\\').squeeze()\\n    X_test = pd.read_csv(\\'../../Big_Files/X_test_Thin_after_Tomek_Twice_v1.csv\\')\\n    y_test = pd.read_csv(\\'../../Big_Files/y_test_Thin_after_Tomek_Twice_v1.csv\\').squeeze()\\n    \\n    print ()\\n    print ()\\n    print (\"Tomek twice\")\\n\\n#    np.random.seed(42) # NumPy\\n#    random.seed(42) # Python\\n#    tf.random.set_seed(42) # Tensorflow    \\n\\n    print ()\\n    print (\\'------------------------------------------\\')\\n    filename = \\'KBFC_Hard_Tomek_2_alpha_target_gamma_0_0\\'\\n    title = \\'Focal $\\\\gamma=0.0$\\'\\n    print (filename)\\n    gamma = 0.0\\n    epochs=20\\n    Keras_Binary_Focal_Crossentropy(X_train, X_test, y_train, y_test, r_target, alpha_target, gamma, epochs, filename, title)\\n\\n    np.random.seed(42) # NumPy\\n    random.seed(42) # Python\\n    tf.random.set_seed(42) # Tensorflow\\n\\n    print ()\\n    print (\\'------------------------------------------\\')\\n    filename = \\'KBFC_Hard_Tomek_2_alpha_target_gamma_0_5\\'\\n    title = \\'Focal $\\\\gamma = 0.5$\\'\\n    print (filename)\\n    gamma = 0.5\\n    epochs=20\\n    Keras_Binary_Focal_Crossentropy(X_train, X_test, y_train, y_test, r_target, alpha_target, gamma, epochs, filename, title)\\n\\n    np.random.seed(42) # NumPy\\n    random.seed(42) # Python\\n    tf.random.set_seed(42) # Tensorflow\\n\\n    print ()\\n    print (\\'------------------------------------------\\')\\n    filename = \\'KBFC_Hard_Tomek_2_alpha_target_gamma_1_0\\'\\n    title = \\'Focal $\\\\gamma = 1.0$\\'\\n    print (filename)\\n    gamma = 1.0\\n    epochs=20\\n    Keras_Binary_Focal_Crossentropy(X_train, X_test, y_train, y_test, r_target, alpha_target, gamma, epochs, filename, title)\\n\\n    np.random.seed(42) # NumPy\\n    random.seed(42) # Python\\n    tf.random.set_seed(42) # Tensorflow\\n\\n    print ()\\n    print (\\'------------------------------------------\\')\\n    filename = \\'KBFC_Hard_Tomek_2_alpha_target_gamma_2_0\\'\\n    title = \\'Focal $\\\\gamma = 2.0$\\'\\n    print (filename)\\n    gamma = 2.0\\n    epochs=20\\n    Keras_Binary_Focal_Crossentropy(X_train, X_test, y_train, y_test, r_target, alpha_target, gamma, epochs, filename, title)\\n\\n    np.random.seed(42) # NumPy\\n    random.seed(42) # Python\\n    tf.random.set_seed(42) # Tensorflow\\n\\n    print ()\\n    print (\\'------------------------------------------\\')\\n    filename = \\'KBFC_Hard_Tomek_2_alpha_target_gamma_5_0\\'\\n    title = \\'Focal $\\\\gamma = 5.0$\\'\\n    print (filename)\\n    gamma = 5.0\\n    epochs=20\\n    Keras_Binary_Focal_Crossentropy(X_train, X_test, y_train, y_test, r_target, alpha_target, gamma, epochs, filename, title)\\n    \\n    print ()\\n    print (\\'------------------------------------------\\')\\n    filename = \\'LRC_Hard_Tomek_2_r_target\\'\\n    title = \\'LogReg\\'\\n    Logistic_Regression_Classifier(X_train, X_test, y_train, y_test, r_target, filename, title)\\n\\n    print ()\\n    print (\\'------------------------------------------\\')\\n    filename = \\'BRFC_Hard_Tomek_2_r_target\\'\\n    title = \\'BRForest\\'\\n    Balanced_Random_Forest_Classifier(X_train, X_test, y_train, y_test, r_target, filename, title)\\n\\n    print ()\\n    print (\\'------------------------------------------\\')\\n    filename = \\'AdaBoost_Hard_Tomek_2\\'\\n    title = \\'AdaBoost\\'\\n    AdaBoost(X_train, X_test, y_train, y_test, r_target, filename, title)\\n    print ()\\n    print (\\'------------------------------------------\\')\\n    filename = \\'Bagging_Hard_Tomek_2\\'\\n    title = \\'BalBag\\'\\n    Bagging(X_train, X_test, y_train, y_test, r_target, filename, title)\\n\\n    print ()\\n    print (\\'------------------------------------------\\')\\n    filename = \\'RUSB_Hard_Tomek_2\\'\\n    title = \\'RUSBoost\\'\\n    estimator = DecisionTreeClassifier(\\n        max_depth=1,\\n        class_weight={0:(1+r_target)/(2*r_target), 1:(1+r_target)/(2*1)},\\n    )\\n    RUSBoost_Classifier(X_train, X_test, y_train, y_test, estimator, r_target, filename, title)\\n\\n    print ()\\n    print (\\'------------------------------------------\\')\\n    filename = \\'EEC_Hard_Tomek_2\\'\\n    title = \\'EasyEns\\'\\n    Easy_Ensemble_Classifier(X_train, X_test, y_train, y_test, r_target, filename, title)\\n\\n\\n    #####\\n    #\\n    # Really Thin Features\\n    #\\n    #####\\n    \\n    data = Get_Data()\\n    data = data.astype(\\'int64\\')\\n    \\n    data = Remove_Pedestrian_Crashes(data)\\n    data = Feature_Engineering_Cross_Two(data)\\n\\n    N = len(data)\\n    n = len(data[data[target]==1])\\n    print (\\'%d samples, %d hospitalized, %d not hospitalized\\' % (N, n, N-n))\\n    print (\\'%f percent of samples hospitalized\\' % (n/N*100))\\n    print (\\'There are %f negative samples for each positive.\\' % ((N-n)/n))\\n    print ()\\n            \\n#    data = Thin_Features(data)\\n    data = Really_Thin_Features(data)\\n#    data = Thin_to_Minimal_Features(data)\\n    print (\\'Really_Thin_Features\\')\\n    for feature in data:\\n        print (feature)\\n    print ()\\n\\n    data = Get_Dummies(data, target)\\n    X_train, X_test, y_train, y_test = Split_Data(data, target, 0.30)\\n    \\na    X_train = pd.read_csv(\\'../../Big_Files/X_train_Thin_before_Tomek_v1.csv\\')\\n    y_train = pd.read_csv(\\'../../Big_Files/y_train_Thin_before_Tomek_v1.csv\\').squeeze()\\n    X_test = pd.read_csv(\\'../../Big_Files/X_test_Thin_before_Tomek_v1.csv\\')\\n    y_test = pd.read_csv(\\'../../Big_Files/y_test_Thin_before_Tomek_v1.csv\\').squeeze()\\n\\n    \\n    print ()\\n\\n    print ()\\n    print (\\'------------------------------------------\\')\\n    filename = \\'KBFC_Medium_Tomek_0_alpha_target_gamma_0_0\\'\\n    title = \\'Focal $\\\\gamma=0.0$\\'\\n    print (filename)\\n    gamma = 0.0\\n    epochs=20\\n    Keras_Binary_Focal_Crossentropy(X_train, X_test, y_train, y_test, r_target, alpha_target, gamma, epochs, filename, title)\\n\\n    \"\"\"\\n    print ()\\n    print (\\'------------------------------------------\\')\\n    filename = \\'KBFC_Medium_Tomek_0_alpha_target_gamma_0_5\\'\\n    title = \\'Focal $\\\\gamma = 0.5$\\'\\n    print (filename)\\n    gamma = 0.5\\n    epochs=20\\n    Keras_Binary_Focal_Crossentropy(X_train, X_test, y_train, y_test, r_target, alpha_target, gamma, epochs, filename, title)\\n\\n    print ()\\n    print (\\'------------------------------------------\\')\\n    filename = \\'KBFC_Medium_Tomek_0_alpha_target_gamma_1_0\\'\\n    title = \\'Focal $\\\\gamma = 1.0$\\'\\n    print (filename)\\n    gamma = 1.0\\n    epochs=20\\n    Keras_Binary_Focal_Crossentropy(X_train, X_test, y_train, y_test, r_target, alpha_target, gamma, epochs, filename, title)\\n\\n    print ()\\n    print (\\'------------------------------------------\\')\\n    filename = \\'KBFC_Medium_Tomek_0_alpha_target_gamma_2_0\\'\\n    title = \\'Focal $\\\\gamma = 2.0$\\'\\n    print (filename)\\n    gamma = 2.0\\n    epochs=20\\n    Keras_Binary_Focal_Crossentropy(X_train, X_test, y_train, y_test, r_target, alpha_target, gamma, epochs, filename, title)\\n    \"\"\"\\n\\n    print ()\\n    print (\\'------------------------------------------\\')\\n    filename = \\'LRC_Medium_Tomek_0_r_target\\'\\n    title = \\'LogReg\\'\\n    Logistic_Regression_Classifier(X_train, X_test, y_train, y_test, r_target, filename, title)\\n\\n    print ()\\n    print (\\'------------------------------------------\\')\\n    filename = \\'BRFC_Medium_Tomek_0_r_target\\'\\n    title = \\'BRForest\\'\\n    Balanced_Random_Forest_Classifier(X_train, X_test, y_train, y_test, r_target, filename, title)\\n\\n    print ()\\n    print (\\'------------------------------------------\\')\\n    filename = \\'AdaBoost_Medium_Tomek_0\\'\\n    title = \\'AdaBoost\\'\\n    AdaBoost(X_train, X_test, y_train, y_test, r_target, filename, title)\\n    print ()\\n    print (\\'------------------------------------------\\')\\n    filename = \\'Bagging_Medium_Tomek_0\\'\\n    title = \\'BalBag\\'\\n    Bagging(X_train, X_test, y_train, y_test, r_target, filename, title)\\n\\n    print ()\\n    print (\\'------------------------------------------\\')\\n    filename = \\'RUSB_Medium_Tomek_0\\'\\n    title = \\'RUSBoost\\'\\n    estimator = DecisionTreeClassifier(\\n        max_depth=1,\\n        class_weight={0:(1+r_target)/(2*r_target), 1:(1+r_target)/(2*1)},\\n    )\\n    RUSBoost_Classifier(X_train, X_test, y_train, y_test, estimator, r_target, filename, title)\\n\\n    print ()\\n    print (\\'------------------------------------------\\')\\n    filename = \\'EEC_Medium_Tomek_0\\'\\n    title = \\'EasyEns\\'\\n    Easy_Ensemble_Classifier(X_train, X_test, y_train, y_test, r_target, filename, title)\\n\\n\\n    #####\\n    #\\n    # Thin_to_Minimal\\n    #\\n    #####\\n    \\n    data = Get_Data()\\n    data = data.astype(\\'int64\\')\\n    \\n    data = Remove_Pedestrian_Crashes(data)\\n    data = Feature_Engineering_Cross_Two(data)\\n\\n    N = len(data)\\n    n = len(data[data[target]==1])\\n    print (\\'%d samples, %d hospitalized, %d not hospitalized\\' % (N, n, N-n))\\n    print (\\'%f percent of samples hospitalized\\' % (n/N*100))\\n    print (\\'There are %f negative samples for each positive.\\' % ((N-n)/n))\\n    print ()\\n            \\n#    data = Thin_Features(data)\\n#    data = Really_Thin_Features(data)\\n    data = Thin_to_Minimal_Features(data)\\n    print (\\'Thin to Minimal\\')\\n    for feature in data:\\n        print (feature)\\n    print ()\\n\\n    data = Get_Dummies(data, target)\\n    X_train, X_test, y_train, y_test = Split_Data(data, target, 0.30)\\n    \\n    print ()\\n\\n    print ()\\n    print (\\'------------------------------------------\\')\\n    filename = \\'KBFC_Easy_Tomek_0_alpha_target_gamma_0_0\\'\\n    title = \\'Focal $\\\\gamma=0.0$\\'\\n    print (filename)\\n    gamma = 0.0\\n    epochs=20\\n    Keras_Binary_Focal_Crossentropy(X_train, X_test, y_train, y_test, r_target, alpha_target, gamma, epochs, filename, title)\\n\\n    \"\"\"\\n    print ()\\n    print (\\'------------------------------------------\\')\\n    filename = \\'KBFC_Easy_Tomek_0_alpha_target_gamma_0_5\\'\\n    title = \\'Focal $\\\\gamma = 0.5$\\'\\n    print (filename)\\n    gamma = 0.5\\n    epochs=20\\n    Keras_Binary_Focal_Crossentropy(X_train, X_test, y_train, y_test, r_target, alpha_target, gamma, epochs, filename, title)\\n\\n    print ()\\n    print (\\'------------------------------------------\\')\\n    filename = \\'KBFC_Easy_Tomek_0_alpha_target_gamma_1_0\\'\\n    title = \\'Focal $\\\\gamma = 1.0$\\'\\n    print (filename)\\n    gamma = 1.0\\n    epochs=20\\n    Keras_Binary_Focal_Crossentropy(X_train, X_test, y_train, y_test, r_target, alpha_target, gamma, epochs, filename, title)\\n\\n    print ()\\n    print (\\'------------------------------------------\\')\\n    filename = \\'KBFC_Easy_Tomek_0_alpha_target_gamma_2_0\\'\\n    title = \\'Focal $\\\\gamma = 2.0$\\'\\n    print (filename)\\n    gamma = 2.0\\n    epochs=20\\n    Keras_Binary_Focal_Crossentropy(X_train, X_test, y_train, y_test, r_target, alpha_target, gamma, epochs, filename, title)\\n    \"\"\"\\n\\n    print ()\\n    print (\\'------------------------------------------\\')\\n    filename = \\'LRC_Easy_Tomek_0_r_target\\'\\n    title = \\'LogReg\\'\\n    Logistic_Regression_Classifier(X_train, X_test, y_train, y_test, r_target, filename, title)\\n\\n    print ()\\n    print (\\'------------------------------------------\\')\\n    filename = \\'BRFC_Easy_Tomek_0_r_target\\'\\n    title = \\'BRForest\\'\\n    Balanced_Random_Forest_Classifier(X_train, X_test, y_train, y_test, r_target, filename, title)\\n\\n    print ()\\n    print (\\'------------------------------------------\\')\\n    filename = \\'AdaBoost_Easy_Tomek_0\\'\\n    title = \\'AdaBoost\\'\\n    AdaBoost(X_train, X_test, y_train, y_test, r_target, filename, title)\\n    print ()\\n    print (\\'------------------------------------------\\')\\n    filename = \\'Bagging_Easy_Tomek_0\\'\\n    title = \\'BalBag\\'\\n    Bagging(X_train, X_test, y_train, y_test, r_target, filename, title)\\n\\n    print ()\\n    print (\\'------------------------------------------\\')\\n    filename = \\'RUSB_Easy_Tomek_0\\'\\n    title = \\'RUSBoost\\'\\n    estimator = DecisionTreeClassifier(\\n        max_depth=1,\\n        class_weight={0:(1+r_target)/(2*r_target), 1:(1+r_target)/(2*1)},\\n    )\\n    RUSBoost_Classifier(X_train, X_test, y_train, y_test, estimator, r_target, filename, title)\\n\\n    print ()\\n    print (\\'------------------------------------------\\')\\n    filename = \\'EEC_Easy_Tomek_0\\'\\n    title = \\'EasyEns\\'\\n    Easy_Ensemble_Classifier(X_train, X_test, y_train, y_test, r_target, filename, title)\\n\\n\\n\\n\\n    \\n    \\n    return 0\\n        \\n#Main()\\n\\n\\n')\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m~/miniforge3/envs/Tensorflow_2_11/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2430\u001b[0m in \u001b[1;35mrun_cell_magic\u001b[0m\n    result = fn(*args, **kwargs)\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m~/miniforge3/envs/Tensorflow_2_11/lib/python3.10/site-packages/IPython/core/magics/execution.py:1275\u001b[0m in \u001b[1;35mtime\u001b[0m\n    expr_ast = self.shell.compile.ast_parse(expr)\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m~/miniforge3/envs/Tensorflow_2_11/lib/python3.10/site-packages/IPython/core/compilerop.py:86\u001b[0;36m in \u001b[0;35mast_parse\u001b[0;36m\n\u001b[0;31m    return compile(source, filename, symbol, self.flags | PyCF_ONLY_AST, 1)\u001b[0;36m\n",
      "\u001b[0;36m  File \u001b[0;32m<unknown>:486\u001b[0;36m\u001b[0m\n\u001b[0;31m    a    X_train = pd.read_csv('../../Big_Files/X_train_Thin_before_Tomek_v1.csv')\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def Main():\n",
    "    target = 'HOSPITAL'\n",
    "    r_target = 2.0\n",
    "    alpha_target = r_target/(r_target+1)\n",
    "    \n",
    "\n",
    "    # These functions run Tomek Links twice on all three versions of the dataset,\n",
    "    # then save the results to file.  \n",
    "#    Undersample_Data_Thin()\n",
    "#    Undersample_Data_Really_Thin()\n",
    "#    Undersample_Data_Thin_to_Minimal()\n",
    "\n",
    "    data = Get_Data()\n",
    "    data = data.astype('int64')\n",
    "    \n",
    "    data = Remove_Pedestrian_Crashes(data)\n",
    "    data = Feature_Engineering_Cross_Two(data)\n",
    "\n",
    "    N = len(data)\n",
    "    n = len(data[data[target]==1])\n",
    "    print ('%d samples, %d hospitalized, %d not hospitalized' % (N, n, N-n))\n",
    "    print ('%f percent of samples hospitalized' % (n/N*100))\n",
    "    print ('There are %f negative samples for each positive.' % ((N-n)/n))\n",
    "    print ()\n",
    "            \n",
    "    data = Thin_Features(data)\n",
    "#    data = Really_Thin_Features(data)\n",
    "#    data = Thin_to_Minimal_Features(data)\n",
    "    for feature in data:\n",
    "        print (feature)\n",
    "    print ()\n",
    "    \n",
    "    # Alternate dataset, for debugging\n",
    "#    file_url = \"http://storage.googleapis.com/download.tensorflow.org/data/heart.csv\"\n",
    "#    data = pd.read_csv(file_url)\n",
    "#    target = 'target'\n",
    "\n",
    "    # Decrease set size, for debugging\n",
    "#    X_train, X_test, y_train, y_test = Split_Data(data, target, 0.95)\n",
    "#    data = X_train\n",
    "#    data['HOSPITAL'] = y_train\n",
    "\n",
    "    data = Get_Dummies(data, target)\n",
    "    X_train, X_test, y_train, y_test = Split_Data(data, target, 0.30)\n",
    "    \n",
    "    print ('X_train.shape = ', X_train.shape)\n",
    "    print ('X_test.shape = ', X_test.shape)\n",
    "    print ('y_train.shape = ', y_train.shape)\n",
    "    print ('y_test.shape = ', y_test.shape)\n",
    "    print ()\n",
    "    \n",
    "    print ('type(X_train): ', type(X_train))\n",
    "    print ('type(X_test): ', type(X_test))\n",
    "    print ('type(y_train): ', type(y_train))\n",
    "    print ('type(y_test): ', type(y_test))\n",
    "    print ()\n",
    "    \n",
    "    \n",
    "    \n",
    "    print ('X_train.shape = ', X_train.shape)\n",
    "    print ('X_test.shape = ', X_test.shape)\n",
    "    print ('y_train.shape = ', y_train.shape)\n",
    "    print ('y_test.shape = ', y_test.shape)\n",
    "    print ()\n",
    "    \n",
    "    print ('type(X_train): ', type(X_train))\n",
    "    print ('type(X_test): ', type(X_test))\n",
    "    print ('type(y_train): ', type(y_train))\n",
    "    print ('type(y_test): ', type(y_test))\n",
    "    print ()\n",
    "    \n",
    "    \n",
    "    ##### Without Tomek\n",
    "    print ('Without Tomek')\n",
    "    print ()\n",
    "    \n",
    "    version = '_v1'\n",
    "    X_train = pd.read_csv('../../Big_Files/X_train_Thin_before_Tomek_v1.csv')\n",
    "    y_train = pd.read_csv('../../Big_Files/y_train_Thin_before_Tomek_v1.csv').squeeze()\n",
    "    X_test = pd.read_csv('../../Big_Files/X_test_Thin_before_Tomek_v1.csv')\n",
    "    y_test = pd.read_csv('../../Big_Files/y_test_Thin_before_Tomek_v1.csv').squeeze()\n",
    "    \n",
    "    \n",
    "    N = len(y_train)\n",
    "    n = len(y_train[y_train==1])\n",
    "    p = (N-n)/n\n",
    "    alpha = p/(p+1)\n",
    "    weights = class_weight.compute_class_weight('balanced',\n",
    "                                            classes = np.unique(y_train),\n",
    "                                            y = y_train).astype('float32')\n",
    "\n",
    "    # Weights for each class = (nSamples Total)/(2* (nSamples in Class))\n",
    "#    weights = [1.0,1.0]\n",
    "#    weights = [0.55,5.5]\n",
    "\n",
    "    print ()\n",
    "\n",
    "    \"\"\"\n",
    "    print ()\n",
    "    print ('------------------------------------------')\n",
    "    filename = 'OBFC_Hard_Tomek_0_alpha_target_gamma_0_0'\n",
    "    title = 'Focal $\\gamma=0.0$'\n",
    "    print (filename)\n",
    "    gamma_0 = 0.0\n",
    "    gamma_1 = 0.0\n",
    "    epochs=20\n",
    "    Our_Binary_Focal_Crossentropy(X_train, X_test, y_train, y_test, r_target, gamma_0, gamma_1, epochs, filename, title)\n",
    "    \"\"\"\n",
    "\n",
    "    np.random.seed(42) # NumPy\n",
    "    random.seed(42) # Python\n",
    "    tf.random.set_seed(42) # Tensorflow\n",
    "\n",
    "    print ()\n",
    "    print ('------------------------------------------')\n",
    "    filename = 'KBFC_Hard_Tomek_0_alpha_target_gamma_0_0'\n",
    "    filename = filename + version\n",
    "    title = 'Focal $\\gamma=0.0$'\n",
    "    print (filename)\n",
    "    gamma = 0.0\n",
    "    epochs=20\n",
    "    Keras_Binary_Focal_Crossentropy(X_train, X_test, y_train, y_test, r_target, alpha_target, gamma, epochs, filename, title)\n",
    "\n",
    "    np.random.seed(42) # NumPy\n",
    "    random.seed(42) # Python\n",
    "    tf.random.set_seed(42) # Tensorflow\n",
    "\n",
    "    print ()\n",
    "    print ('------------------------------------------')\n",
    "    filename = 'KBFC_Hard_Tomek_0_alpha_target_gamma_0_5'\n",
    "    title = 'Focal $\\gamma=0.5$'\n",
    "    print (filename)\n",
    "    gamma = 0.5\n",
    "    epochs=20\n",
    "    Keras_Binary_Focal_Crossentropy(X_train, X_test, y_train, y_test, r_target, alpha_target, gamma, epochs, filename, title)\n",
    "\n",
    "    np.random.seed(42) # NumPy\n",
    "    random.seed(42) # Python\n",
    "    tf.random.set_seed(42) # Tensorflow\n",
    "\n",
    "    print ()\n",
    "    print ('------------------------------------------')\n",
    "    filename = 'KBFC_Hard_Tomek_0_alpha_target_gamma_1_0'\n",
    "    title = 'Focal $\\gamma=1.0$'\n",
    "    print (filename)\n",
    "    gamma = 1.0\n",
    "    epochs=20\n",
    "    Keras_Binary_Focal_Crossentropy(X_train, X_test, y_train, y_test, r_target, alpha_target, gamma, epochs, filename, title)\n",
    "\n",
    "    np.random.seed(42) # NumPy\n",
    "    random.seed(42) # Python\n",
    "    tf.random.set_seed(42) # Tensorflow\n",
    "\n",
    "    print ()\n",
    "    print ('------------------------------------------')\n",
    "    filename = 'KBFC_Hard_Tomek_0_alpha_target_gamma_2_0'\n",
    "    title = 'Focal $\\gamma=2.0$'\n",
    "    print (filename)\n",
    "    gamma = 2.0\n",
    "    epochs=20\n",
    "    Keras_Binary_Focal_Crossentropy(X_train, X_test, y_train, y_test, r_target, alpha_target, gamma, epochs, filename, title)\n",
    "\n",
    "    np.random.seed(42) # NumPy\n",
    "    random.seed(42) # Python\n",
    "    tf.random.set_seed(42) # Tensorflow\n",
    "\n",
    "    print ()\n",
    "    print ('------------------------------------------')\n",
    "    filename = 'KBFC_Hard_Tomek_0_alpha_target_gamma_5_0'\n",
    "    title = 'Focal $\\gamma=5.0$'\n",
    "    print (filename)\n",
    "    gamma = 5.0\n",
    "    epochs=20\n",
    "    Keras_Binary_Focal_Crossentropy(X_train, X_test, y_train, y_test, r_target, alpha_target, gamma, epochs, filename, title)\n",
    "\n",
    "    print ()\n",
    "    print ('------------------------------------------')\n",
    "    filename = 'LRC_Hard_Tomek_0_r_target'\n",
    "    title = 'LogReg'\n",
    "    Logistic_Regression_Classifier(X_train, X_test, y_train, y_test, r_target, filename, title)\n",
    "\n",
    "    print ()\n",
    "    print ('------------------------------------------')\n",
    "    filename = 'BRFC_Hard_Tomek_0_r_target'\n",
    "    title = 'BRForest'\n",
    "    Balanced_Random_Forest_Classifier(X_train, X_test, y_train, y_test, r_target, filename, title)\n",
    "\n",
    "    print ()\n",
    "    print ('------------------------------------------')\n",
    "    filename = 'AdaBoost_Hard_Tomek_0'\n",
    "    title = 'AdaBoost'\n",
    "    AdaBoost(X_train, X_test, y_train, y_test, r_target, filename, title)\n",
    "    print ()\n",
    "    print ('------------------------------------------')\n",
    "    filename = 'Bagging_Hard_Tomek_0'\n",
    "    title = 'BalBag'\n",
    "    Bagging(X_train, X_test, y_train, y_test, r_target, filename, title)\n",
    "\n",
    "    print ()\n",
    "    print ('------------------------------------------')\n",
    "    filename = 'RUSB_Hard_Tomek_0'\n",
    "    title = 'RUSBoost'\n",
    "    estimator = DecisionTreeClassifier(\n",
    "        max_depth=1,\n",
    "        class_weight={0:(1+r_target)/(2*r_target), 1:(1+r_target)/(2*1)},\n",
    "    )\n",
    "    RUSBoost_Classifier(X_train, X_test, y_train, y_test, estimator, r_target, filename, title)\n",
    "\n",
    "    print ()\n",
    "    print ('------------------------------------------')\n",
    "    filename = 'EEC_Hard_Tomek_0'\n",
    "    title = 'EasyEns'\n",
    "    Easy_Ensemble_Classifier(X_train, X_test, y_train, y_test, r_target, filename, title)\n",
    "    \n",
    "    #####\n",
    "    #\n",
    "    # With Tomek Once\n",
    "    #\n",
    "    #####\n",
    "    \n",
    "    print ()\n",
    "    print (\"Tomek once\")\n",
    "    \n",
    "    X_train = pd.read_csv('../../Big_Files/X_train_Thin_after_Tomek_v2.csv')\n",
    "    y_train = pd.read_csv('../../Big_Files/y_train_Thin_after_Tomek_v2.csv').squeeze()\n",
    "    X_test = pd.read_csv('../../Big_Files/X_test_Thin_after_Tomek_v2.csv')\n",
    "    y_test = pd.read_csv('../../Big_Files/y_test_Thin_after_Tomek_v2.csv').squeeze()\n",
    "    \n",
    "    print ()\n",
    "\n",
    "    np.random.seed(42) # NumPy\n",
    "    random.seed(42) # Python\n",
    "    tf.random.set_seed(42) # Tensorflow\n",
    "\n",
    "    print ()\n",
    "    print ('------------------------------------------')\n",
    "    filename = 'KBFC_Hard_Tomek_1_alpha_target_gamma_0_0'\n",
    "    title = 'Focal $\\gamma=0.0$'\n",
    "    print (filename)\n",
    "    gamma = 0.0\n",
    "    epochs=20\n",
    "    Keras_Binary_Focal_Crossentropy(X_train, X_test, y_train, y_test, r_target, alpha_target, gamma, epochs, filename, title)\n",
    "\n",
    "    np.random.seed(42) # NumPy\n",
    "    random.seed(42) # Python\n",
    "    tf.random.set_seed(42) # Tensorflow\n",
    "\n",
    "    print ()\n",
    "    print ('------------------------------------------')\n",
    "    filename = 'KBFC_Hard_Tomek_1_alpha_target_gamma_0_5'\n",
    "    title = 'Focal $\\gamma = 0.5$'\n",
    "    print (filename)\n",
    "    gamma = 0.5\n",
    "    epochs=20\n",
    "    Keras_Binary_Focal_Crossentropy(X_train, X_test, y_train, y_test, r_target, alpha_target, gamma, epochs, filename, title)\n",
    "\n",
    "    np.random.seed(42) # NumPy\n",
    "    random.seed(42) # Python\n",
    "    tf.random.set_seed(42) # Tensorflow\n",
    "\n",
    "    print ()\n",
    "    print ('------------------------------------------')\n",
    "    filename = 'KBFC_Hard_Tomek_1_alpha_target_gamma_1_0'\n",
    "    title = 'Focal $\\gamma = 1.0$'\n",
    "    print (filename)\n",
    "    gamma = 1.0\n",
    "    epochs=20\n",
    "    Keras_Binary_Focal_Crossentropy(X_train, X_test, y_train, y_test, r_target, alpha_target, gamma, epochs, filename, title)\n",
    "\n",
    "    np.random.seed(42) # NumPy\n",
    "    random.seed(42) # Python\n",
    "    tf.random.set_seed(42) # Tensorflow\n",
    "\n",
    "    print ()\n",
    "    print ('------------------------------------------')\n",
    "    filename = 'KBFC_Hard_Tomek_1_alpha_target_gamma_2_0'\n",
    "    title = 'Focal $\\gamma = 2.0$'\n",
    "    print (filename)\n",
    "    gamma = 2.0\n",
    "    epochs=20\n",
    "    Keras_Binary_Focal_Crossentropy(X_train, X_test, y_train, y_test, r_target, alpha_target, gamma, epochs, filename, title)\n",
    "\n",
    "    np.random.seed(42) # NumPy\n",
    "    random.seed(42) # Python\n",
    "    tf.random.set_seed(42) # Tensorflow\n",
    "\n",
    "    print ()\n",
    "    print ('------------------------------------------')\n",
    "    filename = 'KBFC_Hard_Tomek_1_alpha_target_gamma_5_0'\n",
    "    title = 'Focal $\\gamma = 5.0$'\n",
    "    print (filename)\n",
    "    gamma = 5.0\n",
    "    epochs=20\n",
    "    Keras_Binary_Focal_Crossentropy(X_train, X_test, y_train, y_test, r_target, alpha_target, gamma, epochs, filename, title)\n",
    "    \n",
    "    print ()\n",
    "    print ('------------------------------------------')\n",
    "    filename = 'LRC_Hard_Tomek_1_r_target'\n",
    "    title = 'LogReg'\n",
    "    Logistic_Regression_Classifier(X_train, X_test, y_train, y_test, r_target, filename, title)\n",
    "\n",
    "    print ()\n",
    "    print ('------------------------------------------')\n",
    "    filename = 'BRFC_Hard_Tomek_1_r_target'\n",
    "    title = 'BRForest'\n",
    "    Balanced_Random_Forest_Classifier(X_train, X_test, y_train, y_test, r_target, filename, title)\n",
    "\n",
    "    print ()\n",
    "    print ('------------------------------------------')\n",
    "    filename = 'AdaBoost_Hard_Tomek_1'\n",
    "    title = 'AdaBoost'\n",
    "    AdaBoost(X_train, X_test, y_train, y_test, r_target, filename, title)\n",
    "    print ()\n",
    "    print ('------------------------------------------')\n",
    "    filename = 'Bagging_Hard_Tomek_1'\n",
    "    title = 'BalBag'\n",
    "    Bagging(X_train, X_test, y_train, y_test, r_target, filename, title)\n",
    "\n",
    "    print ()\n",
    "    print ('------------------------------------------')\n",
    "    filename = 'RUSB_Hard_Tomek_1'\n",
    "    title = 'RUSBoost'\n",
    "    estimator = DecisionTreeClassifier(\n",
    "        max_depth=1,\n",
    "        class_weight={0:(1+r_target)/(2*r_target), 1:(1+r_target)/(2*1)},\n",
    "    )\n",
    "    RUSBoost_Classifier(X_train, X_test, y_train, y_test, estimator, r_target, filename, title)\n",
    "\n",
    "    print ()\n",
    "    print ('------------------------------------------')\n",
    "    filename = 'EEC_Hard_Tomek_1'\n",
    "    title = 'EasyEns'\n",
    "    Easy_Ensemble_Classifier(X_train, X_test, y_train, y_test, r_target, filename, title)\n",
    "\n",
    "\n",
    "    #####\n",
    "    #\n",
    "    # With Tomek Twice\n",
    "    #\n",
    "    #####\n",
    "    \n",
    "    X_train = pd.read_csv('../../Big_Files/X_train_Thin_after_Tomek_Twice_v1.csv')\n",
    "    y_train = pd.read_csv('../../Big_Files/y_train_Thin_after_Tomek_Twice_v1.csv').squeeze()\n",
    "    X_test = pd.read_csv('../../Big_Files/X_test_Thin_after_Tomek_Twice_v1.csv')\n",
    "    y_test = pd.read_csv('../../Big_Files/y_test_Thin_after_Tomek_Twice_v1.csv').squeeze()\n",
    "    \n",
    "    print ()\n",
    "    print ()\n",
    "    print (\"Tomek twice\")\n",
    "\n",
    "#    np.random.seed(42) # NumPy\n",
    "#    random.seed(42) # Python\n",
    "#    tf.random.set_seed(42) # Tensorflow    \n",
    "\n",
    "    print ()\n",
    "    print ('------------------------------------------')\n",
    "    filename = 'KBFC_Hard_Tomek_2_alpha_target_gamma_0_0'\n",
    "    title = 'Focal $\\gamma=0.0$'\n",
    "    print (filename)\n",
    "    gamma = 0.0\n",
    "    epochs=20\n",
    "    Keras_Binary_Focal_Crossentropy(X_train, X_test, y_train, y_test, r_target, alpha_target, gamma, epochs, filename, title)\n",
    "\n",
    "    np.random.seed(42) # NumPy\n",
    "    random.seed(42) # Python\n",
    "    tf.random.set_seed(42) # Tensorflow\n",
    "\n",
    "    print ()\n",
    "    print ('------------------------------------------')\n",
    "    filename = 'KBFC_Hard_Tomek_2_alpha_target_gamma_0_5'\n",
    "    title = 'Focal $\\gamma = 0.5$'\n",
    "    print (filename)\n",
    "    gamma = 0.5\n",
    "    epochs=20\n",
    "    Keras_Binary_Focal_Crossentropy(X_train, X_test, y_train, y_test, r_target, alpha_target, gamma, epochs, filename, title)\n",
    "\n",
    "    np.random.seed(42) # NumPy\n",
    "    random.seed(42) # Python\n",
    "    tf.random.set_seed(42) # Tensorflow\n",
    "\n",
    "    print ()\n",
    "    print ('------------------------------------------')\n",
    "    filename = 'KBFC_Hard_Tomek_2_alpha_target_gamma_1_0'\n",
    "    title = 'Focal $\\gamma = 1.0$'\n",
    "    print (filename)\n",
    "    gamma = 1.0\n",
    "    epochs=20\n",
    "    Keras_Binary_Focal_Crossentropy(X_train, X_test, y_train, y_test, r_target, alpha_target, gamma, epochs, filename, title)\n",
    "\n",
    "    np.random.seed(42) # NumPy\n",
    "    random.seed(42) # Python\n",
    "    tf.random.set_seed(42) # Tensorflow\n",
    "\n",
    "    print ()\n",
    "    print ('------------------------------------------')\n",
    "    filename = 'KBFC_Hard_Tomek_2_alpha_target_gamma_2_0'\n",
    "    title = 'Focal $\\gamma = 2.0$'\n",
    "    print (filename)\n",
    "    gamma = 2.0\n",
    "    epochs=20\n",
    "    Keras_Binary_Focal_Crossentropy(X_train, X_test, y_train, y_test, r_target, alpha_target, gamma, epochs, filename, title)\n",
    "\n",
    "    np.random.seed(42) # NumPy\n",
    "    random.seed(42) # Python\n",
    "    tf.random.set_seed(42) # Tensorflow\n",
    "\n",
    "    print ()\n",
    "    print ('------------------------------------------')\n",
    "    filename = 'KBFC_Hard_Tomek_2_alpha_target_gamma_5_0'\n",
    "    title = 'Focal $\\gamma = 5.0$'\n",
    "    print (filename)\n",
    "    gamma = 5.0\n",
    "    epochs=20\n",
    "    Keras_Binary_Focal_Crossentropy(X_train, X_test, y_train, y_test, r_target, alpha_target, gamma, epochs, filename, title)\n",
    "    \n",
    "    print ()\n",
    "    print ('------------------------------------------')\n",
    "    filename = 'LRC_Hard_Tomek_2_r_target'\n",
    "    title = 'LogReg'\n",
    "    Logistic_Regression_Classifier(X_train, X_test, y_train, y_test, r_target, filename, title)\n",
    "\n",
    "    print ()\n",
    "    print ('------------------------------------------')\n",
    "    filename = 'BRFC_Hard_Tomek_2_r_target'\n",
    "    title = 'BRForest'\n",
    "    Balanced_Random_Forest_Classifier(X_train, X_test, y_train, y_test, r_target, filename, title)\n",
    "\n",
    "    print ()\n",
    "    print ('------------------------------------------')\n",
    "    filename = 'AdaBoost_Hard_Tomek_2'\n",
    "    title = 'AdaBoost'\n",
    "    AdaBoost(X_train, X_test, y_train, y_test, r_target, filename, title)\n",
    "    print ()\n",
    "    print ('------------------------------------------')\n",
    "    filename = 'Bagging_Hard_Tomek_2'\n",
    "    title = 'BalBag'\n",
    "    Bagging(X_train, X_test, y_train, y_test, r_target, filename, title)\n",
    "\n",
    "    print ()\n",
    "    print ('------------------------------------------')\n",
    "    filename = 'RUSB_Hard_Tomek_2'\n",
    "    title = 'RUSBoost'\n",
    "    estimator = DecisionTreeClassifier(\n",
    "        max_depth=1,\n",
    "        class_weight={0:(1+r_target)/(2*r_target), 1:(1+r_target)/(2*1)},\n",
    "    )\n",
    "    RUSBoost_Classifier(X_train, X_test, y_train, y_test, estimator, r_target, filename, title)\n",
    "\n",
    "    print ()\n",
    "    print ('------------------------------------------')\n",
    "    filename = 'EEC_Hard_Tomek_2'\n",
    "    title = 'EasyEns'\n",
    "    Easy_Ensemble_Classifier(X_train, X_test, y_train, y_test, r_target, filename, title)\n",
    "\n",
    "\n",
    "    #####\n",
    "    #\n",
    "    # Really Thin Features\n",
    "    #\n",
    "    #####\n",
    "    \n",
    "    data = Get_Data()\n",
    "    data = data.astype('int64')\n",
    "    \n",
    "    data = Remove_Pedestrian_Crashes(data)\n",
    "    data = Feature_Engineering_Cross_Two(data)\n",
    "\n",
    "    N = len(data)\n",
    "    n = len(data[data[target]==1])\n",
    "    print ('%d samples, %d hospitalized, %d not hospitalized' % (N, n, N-n))\n",
    "    print ('%f percent of samples hospitalized' % (n/N*100))\n",
    "    print ('There are %f negative samples for each positive.' % ((N-n)/n))\n",
    "    print ()\n",
    "            \n",
    "#    data = Thin_Features(data)\n",
    "    data = Really_Thin_Features(data)\n",
    "#    data = Thin_to_Minimal_Features(data)\n",
    "    print ('Really_Thin_Features')\n",
    "    for feature in data:\n",
    "        print (feature)\n",
    "    print ()\n",
    "\n",
    "    data = Get_Dummies(data, target)\n",
    "    X_train, X_test, y_train, y_test = Split_Data(data, target, 0.30)\n",
    "    \n",
    "a    X_train = pd.read_csv('../../Big_Files/X_train_Thin_before_Tomek_v1.csv')\n",
    "    y_train = pd.read_csv('../../Big_Files/y_train_Thin_before_Tomek_v1.csv').squeeze()\n",
    "    X_test = pd.read_csv('../../Big_Files/X_test_Thin_before_Tomek_v1.csv')\n",
    "    y_test = pd.read_csv('../../Big_Files/y_test_Thin_before_Tomek_v1.csv').squeeze()\n",
    "\n",
    "    \n",
    "    print ()\n",
    "\n",
    "    print ()\n",
    "    print ('------------------------------------------')\n",
    "    filename = 'KBFC_Medium_Tomek_0_alpha_target_gamma_0_0'\n",
    "    title = 'Focal $\\gamma=0.0$'\n",
    "    print (filename)\n",
    "    gamma = 0.0\n",
    "    epochs=20\n",
    "    Keras_Binary_Focal_Crossentropy(X_train, X_test, y_train, y_test, r_target, alpha_target, gamma, epochs, filename, title)\n",
    "\n",
    "    \"\"\"\n",
    "    print ()\n",
    "    print ('------------------------------------------')\n",
    "    filename = 'KBFC_Medium_Tomek_0_alpha_target_gamma_0_5'\n",
    "    title = 'Focal $\\gamma = 0.5$'\n",
    "    print (filename)\n",
    "    gamma = 0.5\n",
    "    epochs=20\n",
    "    Keras_Binary_Focal_Crossentropy(X_train, X_test, y_train, y_test, r_target, alpha_target, gamma, epochs, filename, title)\n",
    "\n",
    "    print ()\n",
    "    print ('------------------------------------------')\n",
    "    filename = 'KBFC_Medium_Tomek_0_alpha_target_gamma_1_0'\n",
    "    title = 'Focal $\\gamma = 1.0$'\n",
    "    print (filename)\n",
    "    gamma = 1.0\n",
    "    epochs=20\n",
    "    Keras_Binary_Focal_Crossentropy(X_train, X_test, y_train, y_test, r_target, alpha_target, gamma, epochs, filename, title)\n",
    "\n",
    "    print ()\n",
    "    print ('------------------------------------------')\n",
    "    filename = 'KBFC_Medium_Tomek_0_alpha_target_gamma_2_0'\n",
    "    title = 'Focal $\\gamma = 2.0$'\n",
    "    print (filename)\n",
    "    gamma = 2.0\n",
    "    epochs=20\n",
    "    Keras_Binary_Focal_Crossentropy(X_train, X_test, y_train, y_test, r_target, alpha_target, gamma, epochs, filename, title)\n",
    "    \"\"\"\n",
    "\n",
    "    print ()\n",
    "    print ('------------------------------------------')\n",
    "    filename = 'LRC_Medium_Tomek_0_r_target'\n",
    "    title = 'LogReg'\n",
    "    Logistic_Regression_Classifier(X_train, X_test, y_train, y_test, r_target, filename, title)\n",
    "\n",
    "    print ()\n",
    "    print ('------------------------------------------')\n",
    "    filename = 'BRFC_Medium_Tomek_0_r_target'\n",
    "    title = 'BRForest'\n",
    "    Balanced_Random_Forest_Classifier(X_train, X_test, y_train, y_test, r_target, filename, title)\n",
    "\n",
    "    print ()\n",
    "    print ('------------------------------------------')\n",
    "    filename = 'AdaBoost_Medium_Tomek_0'\n",
    "    title = 'AdaBoost'\n",
    "    AdaBoost(X_train, X_test, y_train, y_test, r_target, filename, title)\n",
    "    print ()\n",
    "    print ('------------------------------------------')\n",
    "    filename = 'Bagging_Medium_Tomek_0'\n",
    "    title = 'BalBag'\n",
    "    Bagging(X_train, X_test, y_train, y_test, r_target, filename, title)\n",
    "\n",
    "    print ()\n",
    "    print ('------------------------------------------')\n",
    "    filename = 'RUSB_Medium_Tomek_0'\n",
    "    title = 'RUSBoost'\n",
    "    estimator = DecisionTreeClassifier(\n",
    "        max_depth=1,\n",
    "        class_weight={0:(1+r_target)/(2*r_target), 1:(1+r_target)/(2*1)},\n",
    "    )\n",
    "    RUSBoost_Classifier(X_train, X_test, y_train, y_test, estimator, r_target, filename, title)\n",
    "\n",
    "    print ()\n",
    "    print ('------------------------------------------')\n",
    "    filename = 'EEC_Medium_Tomek_0'\n",
    "    title = 'EasyEns'\n",
    "    Easy_Ensemble_Classifier(X_train, X_test, y_train, y_test, r_target, filename, title)\n",
    "\n",
    "\n",
    "    #####\n",
    "    #\n",
    "    # Thin_to_Minimal\n",
    "    #\n",
    "    #####\n",
    "    \n",
    "    data = Get_Data()\n",
    "    data = data.astype('int64')\n",
    "    \n",
    "    data = Remove_Pedestrian_Crashes(data)\n",
    "    data = Feature_Engineering_Cross_Two(data)\n",
    "\n",
    "    N = len(data)\n",
    "    n = len(data[data[target]==1])\n",
    "    print ('%d samples, %d hospitalized, %d not hospitalized' % (N, n, N-n))\n",
    "    print ('%f percent of samples hospitalized' % (n/N*100))\n",
    "    print ('There are %f negative samples for each positive.' % ((N-n)/n))\n",
    "    print ()\n",
    "            \n",
    "#    data = Thin_Features(data)\n",
    "#    data = Really_Thin_Features(data)\n",
    "    data = Thin_to_Minimal_Features(data)\n",
    "    print ('Thin to Minimal')\n",
    "    for feature in data:\n",
    "        print (feature)\n",
    "    print ()\n",
    "\n",
    "    data = Get_Dummies(data, target)\n",
    "    X_train, X_test, y_train, y_test = Split_Data(data, target, 0.30)\n",
    "    \n",
    "    print ()\n",
    "\n",
    "    print ()\n",
    "    print ('------------------------------------------')\n",
    "    filename = 'KBFC_Easy_Tomek_0_alpha_target_gamma_0_0'\n",
    "    title = 'Focal $\\gamma=0.0$'\n",
    "    print (filename)\n",
    "    gamma = 0.0\n",
    "    epochs=20\n",
    "    Keras_Binary_Focal_Crossentropy(X_train, X_test, y_train, y_test, r_target, alpha_target, gamma, epochs, filename, title)\n",
    "\n",
    "    \"\"\"\n",
    "    print ()\n",
    "    print ('------------------------------------------')\n",
    "    filename = 'KBFC_Easy_Tomek_0_alpha_target_gamma_0_5'\n",
    "    title = 'Focal $\\gamma = 0.5$'\n",
    "    print (filename)\n",
    "    gamma = 0.5\n",
    "    epochs=20\n",
    "    Keras_Binary_Focal_Crossentropy(X_train, X_test, y_train, y_test, r_target, alpha_target, gamma, epochs, filename, title)\n",
    "\n",
    "    print ()\n",
    "    print ('------------------------------------------')\n",
    "    filename = 'KBFC_Easy_Tomek_0_alpha_target_gamma_1_0'\n",
    "    title = 'Focal $\\gamma = 1.0$'\n",
    "    print (filename)\n",
    "    gamma = 1.0\n",
    "    epochs=20\n",
    "    Keras_Binary_Focal_Crossentropy(X_train, X_test, y_train, y_test, r_target, alpha_target, gamma, epochs, filename, title)\n",
    "\n",
    "    print ()\n",
    "    print ('------------------------------------------')\n",
    "    filename = 'KBFC_Easy_Tomek_0_alpha_target_gamma_2_0'\n",
    "    title = 'Focal $\\gamma = 2.0$'\n",
    "    print (filename)\n",
    "    gamma = 2.0\n",
    "    epochs=20\n",
    "    Keras_Binary_Focal_Crossentropy(X_train, X_test, y_train, y_test, r_target, alpha_target, gamma, epochs, filename, title)\n",
    "    \"\"\"\n",
    "\n",
    "    print ()\n",
    "    print ('------------------------------------------')\n",
    "    filename = 'LRC_Easy_Tomek_0_r_target'\n",
    "    title = 'LogReg'\n",
    "    Logistic_Regression_Classifier(X_train, X_test, y_train, y_test, r_target, filename, title)\n",
    "\n",
    "    print ()\n",
    "    print ('------------------------------------------')\n",
    "    filename = 'BRFC_Easy_Tomek_0_r_target'\n",
    "    title = 'BRForest'\n",
    "    Balanced_Random_Forest_Classifier(X_train, X_test, y_train, y_test, r_target, filename, title)\n",
    "\n",
    "    print ()\n",
    "    print ('------------------------------------------')\n",
    "    filename = 'AdaBoost_Easy_Tomek_0'\n",
    "    title = 'AdaBoost'\n",
    "    AdaBoost(X_train, X_test, y_train, y_test, r_target, filename, title)\n",
    "    print ()\n",
    "    print ('------------------------------------------')\n",
    "    filename = 'Bagging_Easy_Tomek_0'\n",
    "    title = 'BalBag'\n",
    "    Bagging(X_train, X_test, y_train, y_test, r_target, filename, title)\n",
    "\n",
    "    print ()\n",
    "    print ('------------------------------------------')\n",
    "    filename = 'RUSB_Easy_Tomek_0'\n",
    "    title = 'RUSBoost'\n",
    "    estimator = DecisionTreeClassifier(\n",
    "        max_depth=1,\n",
    "        class_weight={0:(1+r_target)/(2*r_target), 1:(1+r_target)/(2*1)},\n",
    "    )\n",
    "    RUSBoost_Classifier(X_train, X_test, y_train, y_test, estimator, r_target, filename, title)\n",
    "\n",
    "    print ()\n",
    "    print ('------------------------------------------')\n",
    "    filename = 'EEC_Easy_Tomek_0'\n",
    "    title = 'EasyEns'\n",
    "    Easy_Ensemble_Classifier(X_train, X_test, y_train, y_test, r_target, filename, title)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    return 0\n",
    "        \n",
    "#Main()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72178501",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow_2_11",
   "language": "python",
   "name": "tensorflow_2_11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
