%%%%%
\section{Cleaning Techniques Used in Crash Analysis Studies}


In ``A deep learning based traffic crash severity prediction framework'' by Rahim (LSU) \cite{RAHIM2021106090}, they just deleted any records with missing or inconsistent data.  The {\it Titanic} Kaggle sites you showed me use several other methods for filling in incomplete data.  Write a paper where I compare different methods for dealing with missing data, and their effect on different metrics (precision, recall, accuracy, sensitivity, f1, false alarm rate) of the classification of the test set.  

Rahim's article took out 37\% of the records for missing or inconsistent data, but only 21\% of the fatal crashes; could that imbalance in the data cleaning skew the model prediction?  It makes sense that police would be more meticulous in their record keeping for fatal crashes, but 21\% and 37\% are huge.  

Would we get a better model if we found a good way to fill in missing data?

